# app.py

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
import re
import json
from datetime import datetime, date, timedelta
import calendar

# ------------------------------------------------------------
# KÃ¼Ã§Ã¼k yardÄ±mcÄ±lar
# ------------------------------------------------------------
def _to_int_safe(val):
    try:
        if val is None or (isinstance(val, float) and np.isnan(val)):
            return None
        if isinstance(val, str):
            v = val.strip()
            if v == "":
                return None
            if "." in v:  # "16358.0" gibi
                v = v.split(".")[0]
            return int(v)
        if isinstance(val, float):
            return int(round(val))
        return int(val)
    except Exception:
        return None

def _to_float_safe(val):
    try:
        if val is None or (isinstance(val, float) and np.isnan(val)):
            return None
        return float(val)
    except Exception:
        return None

def normalize_roc(val):
    """
    ROC deÄŸerini gÃ¼venli biÃ§imde normalize eder.
    Ã–rnekler:
      16358.0 -> "16358"
      "OPET #16358" -> "16358"
      "16358" -> "16358"
    """
    if val is None or (isinstance(val, float) and np.isnan(val)):
        return None
    s = str(val).strip()
    # sonda .0 varsa at
    if s.endswith(".0"):
        s = s[:-2]
    # sadece ilk rakam blokunu al
    m = re.search(r"(\d+)", s)
    return m.group(1) if m else None


# ------------------------------------------------------------
# Supabase entegrasyonu
# ------------------------------------------------------------
try:
    from modules.supabase_client import get_supabase_client  # sadece client
    SUPABASE_ENABLED = True
except ImportError:
    SUPABASE_ENABLED = False
    print("Supabase modÃ¼lÃ¼ yÃ¼klenemedi. Lokal modda Ã§alÄ±ÅŸÄ±yor.")


# ------------------------------------------------------------
# âœ… CLOUD DEMO VERÄ° YÃœKLEME (GitHub RAW)
# ------------------------------------------------------------
def load_demo_data_from_cloud():
    """Cloud (GitHub Raw) Ã¼zerinden gerÃ§ek verileri yÃ¼kle"""
    try:
        TLAG_DEMO_URL = "https://raw.githubusercontent.com/okilicarslan/tlag-cloud-data/refs/heads/main/tlag_demo.csv"
        COMMENTS_DEMO_URL = "https://raw.githubusercontent.com/okilicarslan/tlag-cloud-data/refs/heads/main/comments_demo.csv"

        import requests
        from io import StringIO

        r1 = requests.get(TLAG_DEMO_URL, timeout=30)
        r1.raise_for_status()
        tlag_df = pd.read_csv(StringIO(r1.text), low_memory=False)

        for col in ["SKOR", "GEÃ‡EN SENE SKOR", "Fark", "TRANSACTION"]:
            if col in tlag_df.columns:
                tlag_df[col] = pd.to_numeric(tlag_df[col], errors="coerce")

        if "ROC_STR" not in tlag_df.columns and "ROC" in tlag_df.columns:
            tlag_df["ROC_STR"] = tlag_df["ROC"].astype(str).str.split(".").str[0]

        r2 = requests.get(COMMENTS_DEMO_URL, timeout=60)
        r2.raise_for_status()
        comments_df = pd.read_csv(
            StringIO(r2.text),
            low_memory=False,
            dtype={"station_code": "string"}  # baÅŸtaki sÄ±fÄ±rlarÄ± korur
        )

        if "categories" in comments_df.columns:
            def _to_list(x):
                if isinstance(x, str) and x.strip().startswith("["):
                    try:
                        return json.loads(x)
                    except Exception:
                        return ["GENEL"]
                return [x] if pd.notna(x) else ["GENEL"]
            comments_df["categories"] = comments_df["categories"].apply(_to_list)

        return tlag_df, comments_df, "Cloud verileri baÅŸarÄ±yla yÃ¼klendi!"
    except Exception as e:
        return None, None, f"Cloud veri yÃ¼kleme hatasÄ±: {str(e)}"


# ------------------------------------------------------------
# Demo verisi oluÅŸturma / export (opsiyonel)
# ------------------------------------------------------------
def create_demo_data_files():
    np.random.seed(42)

    stations_data = [
        # Ä°STANBUL BÃ–LGE
        {"ROC": 4001, "Ä°stasyon": "OPET KARTAL", "DISTRICT": "Ä°STANBUL BÃ–LGE", "NOR": "Ä°STANBUL ANADOLU", "Site Segment": "My Precious", "SKOR": 0.85, "GEÃ‡EN SENE SKOR": 0.78, "Fark": 7.0, "TRANSACTION": 25000},
        {"ROC": 4002, "Ä°stasyon": "SHELL KADIKÃ–Y", "DISTRICT": "Ä°STANBUL BÃ–LGE", "NOR": "Ä°STANBUL ANADOLU", "Site Segment": "My Precious", "SKOR": 0.82, "GEÃ‡EN SENE SKOR": 0.80, "Fark": 2.0, "TRANSACTION": 32000},
        {"ROC": 4003, "Ä°stasyon": "BP ÃœSKÃœDAR", "DISTRICT": "Ä°STANBUL BÃ–LGE", "NOR": "Ä°STANBUL ANADOLU", "Site Segment": "Wasted Talent", "SKOR": 0.68, "GEÃ‡EN SENE SKOR": 0.72, "Fark": -4.0, "TRANSACTION": 18000},
        {"ROC": 4004, "Ä°stasyon": "OPET BEÅÄ°KTAÅ", "DISTRICT": "Ä°STANBUL BÃ–LGE", "NOR": "Ä°STANBUL AVRUPA", "Site Segment": "My Precious", "SKOR": 0.88, "GEÃ‡EN SENE SKOR": 0.83, "Fark": 5.0, "TRANSACTION": 28000},
        {"ROC": 4005, "Ä°stasyon": "TOTAL ÅÄ°ÅLÄ°", "DISTRICT": "Ä°STANBUL BÃ–LGE", "NOR": "Ä°STANBUL AVRUPA", "Site Segment": "Primitive", "SKOR": 0.65, "GEÃ‡EN SENE SKOR": 0.70, "Fark": -5.0, "TRANSACTION": 15000},
        {"ROC": 4006, "Ä°stasyon": "SHELL BEYOÄLU", "DISTRICT": "Ä°STANBUL BÃ–LGE", "NOR": "Ä°STANBUL AVRUPA", "Site Segment": "Wasted Talent", "SKOR": 0.71, "GEÃ‡EN SENE SKOR": 0.68, "Fark": 3.0, "TRANSACTION": 22000},
        {"ROC": 4007, "Ä°stasyon": "OPET ATAÅEHÄ°R", "DISTRICT": "Ä°STANBUL BÃ–LGE", "NOR": "Ä°STANBUL ANADOLU", "Site Segment": "My Precious", "SKOR": 0.86, "GEÃ‡EN SENE SKOR": 0.81, "Fark": 5.0, "TRANSACTION": 35000},
        {"ROC": 4008, "Ä°stasyon": "BP MALTEPE", "DISTRICT": "Ä°STANBUL BÃ–LGE", "NOR": "Ä°STANBUL ANADOLU", "Site Segment": "Saboteur", "SKOR": 0.52, "GEÃ‡EN SENE SKOR": 0.58, "Fark": -6.0, "TRANSACTION": 12000},
        {"ROC": 4009, "Ä°stasyon": "SHELL PENDÄ°K", "DISTRICT": "Ä°STANBUL BÃ–LGE", "NOR": "Ä°STANBUL ANADOLU", "Site Segment": "Primitive", "SKOR": 0.61, "GEÃ‡EN SENE SKOR": 0.64, "Fark": -3.0, "TRANSACTION": 14000},
        {"ROC": 4010, "Ä°stasyon": "OPET BAÄCILAR", "DISTRICT": "Ä°STANBUL BÃ–LGE", "NOR": "Ä°STANBUL AVRUPA", "Site Segment": "Wasted Talent", "SKOR": 0.69, "GEÃ‡EN SENE SKOR": 0.66, "Fark": 3.0, "TRANSACTION": 19000},

        # ANKARA BÃ–LGE
        {"ROC": 5001, "Ä°stasyon": "OPET YENÄ°MAHALLE", "DISTRICT": "ANKARA BÃ–LGE", "NOR": "ANKARA KUZEY", "Site Segment": "My Precious", "SKOR": 0.84, "GEÃ‡EN SENE SKOR": 0.79, "Fark": 5.0, "TRANSACTION": 24000},
        {"ROC": 5002, "Ä°stasyon": "SHELL Ã‡ANKAYA", "DISTRICT": "ANKARA BÃ–LGE", "NOR": "ANKARA GÃœNEY", "Site Segment": "My Precious", "SKOR": 0.87, "GEÃ‡EN SENE SKOR": 0.85, "Fark": 2.0, "TRANSACTION": 30000},
        {"ROC": 5003, "Ä°stasyon": "BP KEÃ‡Ä°Ã–REN", "DISTRICT": "ANKARA BÃ–LGE", "NOR": "ANKARA KUZEY", "Site Segment": "Primitive", "SKOR": 0.63, "GEÃ‡EN SENE SKOR": 0.67, "Fark": -4.0, "TRANSACTION": 16000},
        {"ROC": 5004, "Ä°stasyon": "TOTAL MAMAK", "DISTRICT": "ANKARA BÃ–LGE", "NOR": "ANKARA DOÄU", "Site Segment": "Saboteur", "SKOR": 0.48, "GEÃ‡EN SENE SKOR": 0.55, "Fark": -7.0, "TRANSACTION": 11000},
        {"ROC": 5005, "Ä°stasyon": "OPET BATIKÃ–Y", "DISTRICT": "ANKARA BÃ–LGE", "NOR": "ANKARA BATI", "Site Segment": "Wasted Talent", "SKOR": 0.72, "GEÃ‡EN SENE SKOR": 0.69, "Fark": 3.0, "TRANSACTION": 20000},
        {"ROC": 5006, "Ä°stasyon": "SHELL GÃ–LBAÅI", "DISTRICT": "ANKARA BÃ–LGE", "NOR": "ANKARA GÃœNEY", "Site Segment": "Primitive", "SKOR": 0.66, "GEÃ‡EN SENE SKOR": 0.71, "Fark": -5.0, "TRANSACTION": 17000},
        {"ROC": 5007, "Ä°stasyon": "BP SÄ°NCAN", "DISTRICT": "ANKARA BÃ–LGE", "NOR": "ANKARA BATI", "Site Segment": "Saboteur", "SKOR": 0.51, "GEÃ‡EN SENE SKOR": 0.56, "Fark": -5.0, "TRANSACTION": 13000},
        {"ROC": 5008, "Ä°stasyon": "OPET ALTINDAÄ", "DISTRICT": "ANKARA BÃ–LGE", "NOR": "ANKARA DOÄU", "Site Segment": "Wasted Talent", "SKOR": 0.70, "GEÃ‡EN SENE SKOR": 0.67, "Fark": 3.0, "TRANSACTION": 18000},

        # Ä°ZMÄ°R BÃ–LGE
        {"ROC": 6001, "Ä°stasyon": "OPET BORNOVA", "DISTRICT": "Ä°ZMÄ°R BÃ–LGE", "NOR": "Ä°ZMÄ°R KUZEY", "Site Segment": "My Precious", "SKOR": 0.83, "GEÃ‡EN SENE SKOR": 0.80, "Fark": 3.0, "TRANSACTION": 26000},
        {"ROC": 6002, "Ä°stasyon": "SHELL KONAK", "DISTRICT": "Ä°ZMÄ°R BÃ–LGE", "NOR": "Ä°ZMÄ°R MERKEZ", "Site Segment": "My Precious", "SKOR": 0.89, "GEÃ‡EN SENE SKOR": 0.86, "Fark": 3.0, "TRANSACTION": 33000},
        {"ROC": 6003, "Ä°stasyon": "BP KARÅIYAKA", "DISTRICT": "Ä°ZMÄ°R BÃ–LGE", "NOR": "Ä°ZMÄ°R KUZEY", "Site Segment": "Wasted Talent", "SKOR": 0.74, "GEÃ‡EN SENE SKOR": 0.71, "Fark": 3.0, "TRANSACTION": 21000},
        {"ROC": 6004, "Ä°stasyon": "TOTAL BALÃ‡OVA", "DISTRICT": "Ä°ZMÄ°R BÃ–LGE", "NOR": "Ä°ZMÄ°R GÃœNEY", "Site Segment": "Primitive", "SKOR": 0.67, "GEÃ‡EN SENE SKOR": 0.72, "Fark": -5.0, "TRANSACTION": 16000},
        {"ROC": 6005, "Ä°stasyon": "OPET BAYRAKLI", "DISTRICT": "Ä°ZMÄ°R BÃ–LGE", "NOR": "Ä°ZMÄ°R KUZEY", "Site Segment": "Saboteur", "SKOR": 0.53, "GEÃ‡EN SENE SKOR": 0.59, "Fark": -6.0, "TRANSACTION": 12500},
        {"ROC": 6006, "Ä°stasyon": "SHELL GÃœZELBAHÃ‡E", "DISTRICT": "Ä°ZMÄ°R BÃ–LGE", "NOR": "Ä°ZMÄ°R GÃœNEY", "Site Segment": "Wasted Talent", "SKOR": 0.73, "GEÃ‡EN SENE SKOR": 0.70, "Fark": 3.0, "TRANSACTION": 19500},
        {"ROC": 6007, "Ä°stasyon": "BP Ã‡IÄLI", "DISTRICT": "Ä°ZMÄ°R BÃ–LGE", "NOR": "Ä°ZMÄ°R KUZEY", "Site Segment": "Primitive", "SKOR": 0.64, "GEÃ‡EN SENE SKOR": 0.68, "Fark": -4.0, "TRANSACTION": 15500},

        # BURSA BÃ–LGE
        {"ROC": 7001, "Ä°stasyon": "OPET NÄ°LÃœFER", "DISTRICT": "BURSA BÃ–LGE", "NOR": "BURSA MERKEZ", "Site Segment": "My Precious", "SKOR": 0.81, "GEÃ‡EN SENE SKOR": 0.78, "Fark": 3.0, "TRANSACTION": 23000},
        {"ROC": 7002, "Ä°stasyon": "SHELL OSMANGAZÄ°", "DISTRICT": "BURSA BÃ–LGE", "NOR": "BURSA MERKEZ", "Site Segment": "Primitive", "SKOR": 0.62, "GEÃ‡EN SENE SKOR": 0.66, "Fark": -4.0, "TRANSACTION": 14500},
        {"ROC": 7003, "Ä°stasyon": "BP YILDIRIM", "DISTRICT": "BURSA BÃ–LGE", "NOR": "BURSA MERKEZ", "Site Segment": "Saboteur", "SKOR": 0.49, "GEÃ‡EN SENE SKOR": 0.54, "Fark": -5.0, "TRANSACTION": 10500},
        {"ROC": 7004, "Ä°stasyon": "TOTAL GEMLÄ°K", "DISTRICT": "BURSA BÃ–LGE", "NOR": "BURSA GÃœNEY", "Site Segment": "Wasted Talent", "SKOR": 0.75, "GEÃ‡EN SENE SKOR": 0.72, "Fark": 3.0, "TRANSACTION": 18500},

        # ANTALYA BÃ–LGE
        {"ROC": 8001, "Ä°stasyon": "OPET MURATPAÅA", "DISTRICT": "ANTALYA BÃ–LGE", "NOR": "ANTALYA MERKEZ", "Site Segment": "My Precious", "SKOR": 0.86, "GEÃ‡EN SENE SKOR": 0.82, "Fark": 4.0, "TRANSACTION": 27000},
        {"ROC": 8002, "Ä°stasyon": "SHELL KEPEZ", "DISTRICT": "ANTALYA BÃ–LGE", "NOR": "ANTALYA MERKEZ", "Site Segment": "Wasted Talent", "SKOR": 0.71, "GEÃ‡EN SENE SKOR": 0.68, "Fark": 3.0, "TRANSACTION": 20500},
        {"ROC": 8003, "Ä°stasyon": "BP ALANYA", "DISTRICT": "ANTALYA BÃ–LGE", "NOR": "ANTALYA DOÄU", "Site Segment": "Primitive", "SKOR": 0.65, "GEÃ‡EN SENE SKOR": 0.69, "Fark": -4.0, "TRANSACTION": 17000},
        {"ROC": 8004, "Ä°stasyon": "TOTAL KAÅ", "DISTRICT": "ANTALYA BÃ–LGE", "NOR": "ANTALYA BATI", "Site Segment": "Saboteur", "SKOR": 0.50, "GEÃ‡EN SENE SKOR": 0.57, "Fark": -7.0, "TRANSACTION": 11500},
    ]

    tlag_df = pd.DataFrame(stations_data)
    tlag_df["ROC_STR"] = tlag_df["ROC"].astype(str)

    comments_data = []
    comment_templates = {
        "PERSONEL": [
            ("Personel Ã§ok yardÄ±msever ve gÃ¼leryÃ¼zlÃ¼", 5),
            ("Ã‡alÄ±ÅŸanlar ilgisiz davrandÄ±", 2),
            ("PompacÄ± Ã§ok kibar ve hÄ±zlÄ±ydÄ±", 5),
            ("Kasiyer muameleyi kaba", 1),
            ("Personel profesyonel", 4),
        ],
        "TEMÄ°ZLÄ°K": [
            ("Ä°stasyon Ã§ok temiz ve bakÄ±mlÄ±", 5),
            ("Tuvaletler pis ve bakÄ±msÄ±z", 1),
            ("Genel hijyen kÃ¶tÃ¼", 2),
            ("Her yer tertemiz", 5),
            ("Pompalar kirli", 2),
        ],
        "MARKET": [
            ("Market Ã¼rÃ¼n Ã§eÅŸidi bol", 4),
            ("Fiyatlar Ã§ok pahalÄ±", 2),
            ("Taze Ã¼rÃ¼nler mevcut", 4),
            ("Market kÄ±smÄ± kÃ¼Ã§Ã¼k", 3),
            ("Kaliteli Ã¼rÃ¼nler", 5),
        ],
        "HIZ": [
            ("Ã‡ok hÄ±zlÄ± servis", 5),
            ("Bekleme sÃ¼resi uzun", 2),
            ("Kuyruk Ã§ok yavaÅŸ ilerliyor", 1),
            ("HÄ±zlÄ± ve etkili", 5),
            ("Servis hÄ±zÄ± orta", 3),
        ],
        "YAKIT": [
            ("YakÄ±t kalitesi Ã§ok iyi", 5),
            ("Pompa arÄ±zalÄ±", 1),
            ("Dolum hÄ±zÄ± iyi", 4),
            ("YakÄ±t problemi yaÅŸadÄ±m", 2),
            ("Kaliteli benzin", 5),
        ],
        "GENEL": [
            ("Genel olarak memnunum", 4),
            ("Berbat bir deneyim", 1),
            ("Ä°yi bir istasyon", 4),
            ("Ortalama", 3),
            ("Ã‡ok beÄŸendim", 5),
        ],
    }

    for station in stations_data:
        roc = station["ROC"]
        district = station["DISTRICT"]
        nor = station["NOR"]
        num_comments = np.random.randint(3, 9)
        for _ in range(num_comments):
            category = np.random.choice(list(comment_templates.keys()))
            comment_text, score = np.random.choice(comment_templates[category])
            comments_data.append({
                "station_code": str(roc),
                "station_info": f"{station['Ä°stasyon']} #{roc}",
                "comment": comment_text,
                "score": score,
                "categories": json.dumps([category]),
                "dealer": station["Ä°stasyon"].split()[0],
                "territory": nor,
                "district": district,
                "visit_date": pd.date_range("2024-01-01", "2024-12-31", freq="D")[np.random.randint(0, 365)].strftime("%Y-%m-%d"),
            })

    comments_df = pd.DataFrame(comments_data)
    return tlag_df, comments_df

def export_demo_data_files():
    tlag_df, comments_df = create_demo_data_files()
    tlag_df.to_csv("tlag_demo.csv", index=False)
    comments_df.to_csv("comments_demo.csv", index=False)
    st.success("âœ… Demo data dosyalarÄ± oluÅŸturuldu: tlag_demo.csv, comments_demo.csv")
    st.info("Bu dosyalarÄ± GitHub repository'nize yÃ¼kleyin ve raw URL'lerini kodda gÃ¼ncelleyin.")


# ------------------------------------------------------------
# Sayfa ayarlarÄ±
# ------------------------------------------------------------
st.set_page_config(
    page_title="TLAG Performance Analytics",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ------------------------------------------------------------
# CSS
# ------------------------------------------------------------
st.markdown("""
<style>
    .main-header { font-size: clamp(2rem, 5vw, 3rem); font-weight: bold; text-align: center;
        background: linear-gradient(90deg, #FF6B6B, #4ECDC4); -webkit-background-clip: text; -webkit-text-fill-color: transparent; margin-bottom: 2rem; }
    .metric-card { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 1.5rem; border-radius: 15px; color: white; text-align: center; margin: 0.5rem 0;
        box-shadow: 0 8px 32px rgba(0,0,0,0.1); cursor: pointer; transition: transform 0.3s; }
    .metric-card:hover { transform: translateY(-5px); }
    .nav-button { background: linear-gradient(135deg, #4ECDC4 0%, #44A08D 100%); color: white; padding: 1rem 2rem; border: none; border-radius: 10px;
        font-size: 1.1rem; font-weight: bold; margin: 0.5rem; cursor: pointer; transition: all 0.3s; }
    .nav-button:hover { transform: translateY(-2px); box-shadow: 0 4px 15px rgba(0,0,0,0.2); }
    .nav-button.active { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); }
    .chat-container { max-height: 400px; overflow-y: auto; padding: 1rem; border-radius: 10px; background: #f8f9fa; margin: 1rem 0; }
    .quick-action-btn { background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%); color: #2c3e50; padding: 0.5rem 1rem; border: none; border-radius: 20px; font-size: 0.9rem; margin: 0.2rem; cursor: pointer; transition: all 0.3s; }
    .quick-action-btn:hover { transform: translateY(-1px); box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
    .comment-card { background: #f8f9fa; padding: 1rem; border-radius: 10px; margin: 0.5rem 0; border-left: 4px solid #4ECDC4; }
    .category-badge { display: inline-block; padding: 0.25rem 0.75rem; border-radius: 15px; margin: 0.25rem; font-size: 0.85rem; font-weight: bold; }
    .category-personel { background: #FF6B6B; color: white; }
    .category-temizlik { background: #4ECDC4; color: white; }
    .category-market { background: #95E1D3; color: dark; }
    .category-hiz { background: #FFA502; color: white; }
    .category-yakit { background: #3742FA; color: white; }
    .category-genel { background: #747D8C; color: white; }
    .performance-excellent { background: linear-gradient(135deg, #56ab2f 0%, #a8e6cf 100%); padding: 1rem; border-radius: 10px; color: white; margin: 1rem 0; }
    .performance-good { background: linear-gradient(135deg, #f7971e 0%, #ffd200 100%); padding: 1rem; border-radius: 10px; color: white; margin: 1rem 0; }
    .performance-needs-improvement { background: linear-gradient(135deg, #ff512f 0%, #dd2476 100%); padding: 1rem; border-radius: 10px; color: white; margin: 1rem 0; }
    .station-card { background: #f8f9fa; padding: 1rem; border-radius: 8px; border-left: 4px solid #667eea; margin: 0.5rem 0; }
    .improvement-card { background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%); padding: 1.5rem; border-radius: 15px; color: #2c3e50; margin: 1rem 0; box-shadow: 0 8px 32px rgba(0,0,0,0.1); }
    .priority-high { border-left: 5px solid #e74c3c; }
    .priority-medium { border-left: 5px solid #f39c12; }
    .priority-low { border-left: 5px solid #27ae60; }
    @media (max-width: 768px) { .main-header { font-size: 1.5rem; } .metric-card { padding: 1rem; } }
</style>
""", unsafe_allow_html=True)

# ------------------------------------------------------------
# Session state
# ------------------------------------------------------------
if "tlag_data" not in st.session_state: st.session_state.tlag_data = None
if "comments_data" not in st.session_state: st.session_state.comments_data = None
if "analyzed_comments" not in st.session_state: st.session_state.analyzed_comments = None
if "current_view" not in st.session_state: st.session_state.current_view = "main"
if "chat_history" not in st.session_state: st.session_state.chat_history = []
if "demo_data_loaded" not in st.session_state: st.session_state.demo_data_loaded = False


# ------------------------------------------------------------
# Period yardÄ±mcÄ±larÄ±
# ------------------------------------------------------------
def _iso_week_bounds(year: int, week: int):
    d = datetime.fromisocalendar(year, week, 1).date()
    return d, d + timedelta(days=6)

def _month_bounds(year: int, month: int):
    start = date(year, month, 1)
    last_day = calendar.monthrange(year, month)[1]
    return start, date(year, month, last_day)

def _quarter_of_month(m: int): return ((m - 1) // 3) + 1

def _quarter_bounds(year: int, q: int):
    m1 = (q - 1) * 3 + 1
    start = date(year, m1, 1)
    m3 = m1 + 2
    last_day = calendar.monthrange(year, m3)[1]
    return start, date(year, m3, last_day)

def _half_of_month(m: int): return 1 if m <= 6 else 2

def _half_bounds(year: int, h: int):
    if h == 1: return date(year, 1, 1), date(year, 6, 30)
    else:      return date(year, 7, 1), date(year, 12, 31)

def infer_period_from_filename(filename: str):
    name = filename.lower()
    y = re.search(r"(20\d{2})", name)
    year = int(y.group(1)) if y else date.today().year

    m = re.search(r"w(\d{1,2})", name)
    if m:
        week = int(m.group(1))
        ps, pe = _iso_week_bounds(year, week)
        return dict(period_type="WEEK", year=year, week=week, period_start=ps, period_end=pe)

    m = re.search(r"[-_\.](1[0-2]|0?[1-9])(?=\D|$)", name)
    if m:
        month = int(m.group(1))
        ps, pe = _month_bounds(year, month)
        return dict(period_type="MONTH", year=year, month=month, quarter=_quarter_of_month(month),
                    half=_half_of_month(month), period_start=ps, period_end=pe)

    m = re.search(r"q([1-4])", name)
    if m:
        q = int(m.group(1))
        ps, pe = _quarter_bounds(year, q)
        return dict(period_type="QUARTER", year=year, quarter=q, half=1 if q <= 2 else 2, period_start=ps, period_end=pe)

    m = re.search(r"h([12])", name)
    if m:
        h = int(m.group(1))
        ps, pe = _half_bounds(year, h)
        return dict(period_type="HALF", year=year, half=h, period_start=ps, period_end=pe)

    ps, pe = date(year, 1, 1), date(year, 12, 31)
    return dict(period_type="YEAR", year=year, period_start=ps, period_end=pe)

def attach_period_columns(df: pd.DataFrame, filename: str):
    meta = infer_period_from_filename(filename or "unknown.xlsx")
    for k, v in meta.items():
        df[f"__{k}"] = v
    return df, meta


# ------------------------------------------------------------
# Supabase yardÄ±mcÄ±larÄ± (period, tlag_data, customer_comments)
# ------------------------------------------------------------
def supabase_upsert_period(meta: dict, source_filename: str):
    if not SUPABASE_ENABLED:
        return None
    client = get_supabase_client()

    sel = (
        client.table("periods")
        .select("id")
        .eq("period_type", meta["period_type"])
        .eq("year", meta["year"])
    )
    if meta.get("week")    is not None: sel = sel.eq("week", meta["week"])
    if meta.get("month")   is not None: sel = sel.eq("month", meta["month"])
    if meta.get("quarter") is not None: sel = sel.eq("quarter", meta["quarter"])
    if meta.get("half")    is not None: sel = sel.eq("half", meta["half"])

    res = sel.limit(1).execute()
    if res.data:
        return res.data[0]["id"]

    payload = {
        "source_filename": source_filename,
        "period_type": meta["period_type"],
        "year": meta["year"],
        "week": meta.get("week"),
        "month": meta.get("month"),
        "quarter": meta.get("quarter"),
        "half": meta.get("half"),
        "period_start": meta["period_start"].isoformat(),
        "period_end": meta["period_end"].isoformat(),
    }
    ins = client.table("periods").insert(payload).select("id").single().execute()
    return ins.data["id"]

def supabase_save_tlag(df: pd.DataFrame, period_id):
    if not SUPABASE_ENABLED or not period_id or df is None or df.empty:
        return
    client = get_supabase_client()
    rows = []
    for _, r in df.iterrows():
        def _num(x): return float(x) if (x is not None and not pd.isna(x)) else None
        roc_val = normalize_roc(r.get("ROC_STR") or r.get("ROC"))
        rows.append(dict(
            roc=roc_val,
            istasyon=r.get("Ä°stasyon"),
            district=r.get("DISTRICT"),
            nor=r.get("NOR"),
            site_segment=r.get("Site Segment"),
            skor=_num(r.get("SKOR")),
            gecen_sene_skor=_num(r.get("GEÃ‡EN SENE SKOR")),
            fark=_num(r.get("Fark")),
            transaction=_num(r.get("TRANSACTION")),
            period_id=period_id
        ))
    if rows:
        client.table("tlag_data").upsert(rows, on_conflict="roc,period_id").execute()

def fetch_tlag_by_period(period_type, year, gran_val=None):
    if not SUPABASE_ENABLED:
        return pd.DataFrame()
    client = get_supabase_client()

    sel = (
        client.table("periods")
        .select("id,period_type,year,week,month,quarter,half,period_start,period_end")
        .eq("period_type", period_type)
        .eq("year", year)
    )
    if period_type == 'WEEK' and gran_val:    sel = sel.eq("week", gran_val)
    if period_type == 'MONTH' and gran_val:   sel = sel.eq("month", gran_val)
    if period_type == 'QUARTER' and gran_val: sel = sel.eq("quarter", gran_val)
    if period_type == 'HALF' and gran_val:    sel = sel.eq("half", gran_val)

    pr = sel.limit(50).execute()
    periods = pr.data or []
    if not periods:
        return pd.DataFrame()

    ids = [p["id"] for p in periods]
    periods_by_id = {p["id"]: p for p in periods}

    res = (
        client.table("tlag_data")
        .select("*")
        .in_("period_id", ids)
        .limit(10000)
        .execute()
    )

    rows = []
    for r in (res.data or []):
        p = periods_by_id.get(r["period_id"], {})
        rows.append({
            'ROC': r.get('roc'),
            'ROC_STR': str(r.get('roc')) if r.get('roc') is not None else None,
            'Ä°stasyon': r.get('istasyon'),
            'DISTRICT': r.get('district'),
            'NOR': r.get('nor'),
            'Site Segment': r.get('site_segment'),
            'SKOR': r.get('skor'),
            'GEÃ‡EN SENE SKOR': r.get('gecen_sene_skor'),
            'Fark': r.get('fark'),
            'TRANSACTION': r.get('transaction'),
            '__period_type': p.get('period_type'),
            '__year': p.get('year'),
            '__week': p.get('week'),
            '__month': p.get('month'),
            '__quarter': p.get('quarter'),
            '__half': p.get('half'),
            '__period_start': p.get('period_start'),
            '__period_end': p.get('period_end'),
        })
    return pd.DataFrame(rows)

def fetch_comments_by_period(period_type, year, gran_val=None):
    if not SUPABASE_ENABLED:
        return pd.DataFrame()
    client = get_supabase_client()

    sel = (
        client.table("periods")
        .select("id")
        .eq("period_type", period_type)
        .eq("year", year)
    )
    if period_type == 'WEEK' and gran_val:    sel = sel.eq("week", gran_val)
    if period_type == 'MONTH' and gran_val:   sel = sel.eq("month", gran_val)
    if period_type == 'QUARTER' and gran_val: sel = sel.eq("quarter", gran_val)
    if period_type == 'HALF' and gran_val:    sel = sel.eq("half", gran_val)

    pr = sel.limit(50).execute()
    ids = [p["id"] for p in (pr.data or [])]
    if not ids:
        return pd.DataFrame()

    res = (
        client.table("customer_comments")
        .select("*")
        .in_("period_id", ids)
        .limit(50000)
        .execute()
    )

    rows = []
    for r in (res.data or []):
        cats = r.get('categories')
        if isinstance(cats, str):
            try:
                cats = json.loads(cats)
            except Exception:
                cats = []
        rows.append({
            'station_code': r.get('roc'),
            'comment': r.get('comment'),
            'score': r.get('score'),
            'categories': cats,
            'dealer': r.get('dealer'),
            'territory': r.get('territory'),
            'district': r.get('district'),
            'visit_date': r.get('visit_date'),
        })
    return pd.DataFrame(rows)

def supabase_save_comments(df: pd.DataFrame, period_id):
    """customer_comments tablosuna yazar (roc=normalize, period_id=uuid)."""
    if not SUPABASE_ENABLED or period_id is None or df is None or df.empty:
        return
    client = get_supabase_client()

    rows = []
    for _, r in df.iterrows():
        cats = r.get("categories")
        if isinstance(cats, list):
            cats_json = json.dumps(cats, ensure_ascii=False)
        else:
            cats_json = json.dumps([cats] if pd.notna(cats) else [], ensure_ascii=False)

        roc_val = normalize_roc(r.get("station_code"))  # â† merkezi ROC normalize
        rows.append(dict(
            roc=roc_val,
            comment=r.get("comment"),
            score=_to_int_safe(r.get("score")),
            categories=cats_json,
            dealer=r.get("dealer"),
            territory=r.get("territory"),
            district=r.get("district"),
            visit_date=str(r.get("visit_date")) if pd.notna(r.get("visit_date")) else None,
            period_id=period_id
        ))

    if rows:
        client.table("customer_comments").insert(rows).execute()


# ------------------------------------------------------------
# YardÄ±mcÄ± fonksiyonlar (temizlik/analiz)
# ------------------------------------------------------------
def clean_data_for_json(df):
    df_clean = df.copy()
    df_clean = df_clean.replace([np.inf, -np.inf], np.nan)
    df_clean = df_clean.fillna(0)
    for col in df_clean.columns:
        if df_clean[col].dtype == "object":
            df_clean[col] = df_clean[col].astype(str)
    return df_clean

def format_percentage(value):
    if pd.isna(value) or value is None:
        return "N/A"
    return f"{value * 100:.1f}%"

def format_percentage_change(value):
    if pd.isna(value) or value is None:
        return "N/A"
    sign = "+" if value > 0 else ""
    return f"{sign}{value:.1f}%"

def get_performance_category(score):
    if pd.isna(score): return "Bilinmeyen", "#95a5a6"
    elif score >= 0.80: return "MÃ¼kemmel", "#27ae60"
    elif score >= 0.70: return "Ä°yi", "#f39c12"
    elif score >= 0.60: return "Orta", "#e67e22"
    else: return "GeliÅŸim Gerekli", "#e74c3c"

def extract_station_code(station_info):
    if pd.isna(station_info): return None
    match = re.search(r"#(\d+)$", str(station_info))
    return match.group(1) if match else None

def categorize_comment(comment_text):
    if pd.isna(comment_text): return ["GENEL"]
    comment_lower = str(comment_text).lower()
    categories = []
    category_keywords = {
        "PERSONEL": ["personel", "Ã§alÄ±ÅŸan", "pompacÄ±", "kasiyer", "gÃ¶revli", "mÃ¼dÃ¼r", "yardÄ±msever", "ilgili", "gÃ¼leryÃ¼zlÃ¼", "kaba", "ilgisiz", "saygÄ±lÄ±"],
        "TEMÄ°ZLÄ°K": ["temiz", "kirli", "hijyen", "tuvalet", "pis", "bakÄ±m", "tertip", "dÃ¼zen"],
        "MARKET": ["market", "Ã¼rÃ¼n", "fiyat", "pahalÄ±", "ucuz", "Ã§eÅŸit", "kalite", "taze"],
        "HIZ": ["hÄ±zlÄ±", "yavaÅŸ", "bekleme", "kuyruk", "sÃ¼re", "geÃ§", "Ã§abuk", "acele"],
        "YAKIT": ["benzin", "motorin", "lpg", "yakÄ±t", "pompa", "dolum", "depo"],
        "GENEL": ["genel", "gÃ¼zel", "kÃ¶tÃ¼", "memnun", "beÄŸen", "hoÅŸ"]
    }
    for category, keywords in category_keywords.items():
        if any(keyword in comment_lower for keyword in keywords):
            categories.append(category)
    return categories if categories else ["GENEL"]

def enforce_real_districts(df: pd.DataFrame) -> pd.DataFrame:
    if "DISTRICT" not in df.columns:
        return df
    valid = set(df["DISTRICT"].dropna().astype(str).str.strip().unique())
    df["DISTRICT"] = df["DISTRICT"].apply(lambda x: x if (pd.notna(x) and str(x).strip() in valid) else np.nan)
    return df

def load_tlag_data(uploaded_file):
    try:
        df = pd.read_excel(uploaded_file, sheet_name="TLAG DOKUNMA (2)", engine="openpyxl")
        df.columns = df.columns.str.strip()
        df = df.dropna(subset=["ROC", "Ä°stasyon"], how="any")
        numeric_columns = ["ROC", "SKOR", "GEÃ‡EN SENE SKOR", "Fark", "TRANSACTION", "NOR HEDEF", "DISTRICT HEDEF", "GeÃ§erli"]
        for col in numeric_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors="coerce")
        text_columns = ["Ä°stasyon", "NOR", "DISTRICT", "Site Segment"]
        for col in text_columns:
            if col in df.columns:
                df[col] = df[col].astype(str).str.strip()
                df[col] = df[col].replace("nan", np.nan)
        # ROC_STR ve normalize edilmiÅŸ ROC_TEXT ekle
        df["ROC_STR"] = df["ROC"].astype(str).str.split(".").str[0]
        df["ROC_TEXT"] = df["ROC_STR"].apply(normalize_roc)
        df = enforce_real_districts(df)
        df_clean = clean_data_for_json(df)
        return df_clean
    except Exception as e:
        st.error(f"Dosya okuma hatasÄ±: {str(e)}")
        return None

def load_comments_data(uploaded_file):
    try:
        df = pd.read_excel(uploaded_file, header=1)
        df = df[df.iloc[:, 0] != "65000 yorum sÄ±nÄ±rÄ±nÄ± aÅŸtÄ±nÄ±z."]
        df = df[df.iloc[:, 0] != "birim"]
        column_names = {
            df.columns[0]: "station_info",
            df.columns[1]: "survey_item",
            df.columns[2]: "comment",
            df.columns[3]: "score",
            df.columns[4]: "visit_date",
            df.columns[5]: "hospitality_score",
            df.columns[6]: "dealer",
            df.columns[7]: "territory",
            df.columns[8]: "district",
            df.columns[9]: "country" if len(df.columns) > 9 else "country"
        }
        df = df.rename(columns=column_names)
        # station_code -> normalize
        df["station_code"] = df["station_info"].apply(extract_station_code)
        df["station_code"] = df["station_code"].apply(normalize_roc)
        df["score"] = pd.to_numeric(df["score"], errors="coerce")
        df["categories"] = df["comment"].apply(categorize_comment)
        df_clean = clean_data_for_json(df)
        return df_clean
    except Exception as e:
        st.error(f"Yorum dosyasÄ± okuma hatasÄ±: {str(e)}")
        return None

def merge_comments_with_stations(comments_df, tlag_df):
    try:
        merged = pd.merge(
            comments_df,
            tlag_df[["ROC_STR", "ROC_TEXT", "Ä°stasyon", "NOR", "DISTRICT"]],
            left_on="station_code",
            right_on="ROC_STR",
            how="left"
        )
        merged["NOR_FINAL"] = merged["NOR"].fillna(merged["territory"])
        merged["DISTRICT_FINAL"] = merged["DISTRICT"].fillna(merged["district"])
        return merged
    except Exception as e:
        st.error(f"Veri birleÅŸtirme hatasÄ±: {str(e)}")
        return comments_df


def analyze_comments_by_category(df, level="district"):
    if df is None or df.empty:
        return {}
    group_col = f"{level.upper()}_FINAL" if f"{level.upper()}_FINAL" in df.columns else level.upper()
    if group_col not in df.columns:
        return {}
    results = {}
    for name, group in df.groupby(group_col):
        if pd.isna(name) or name == "nan" or name == "0":
            continue
        score_dist = group["score"].value_counts().to_dict()
        low_score_comments = group[group["score"] <= 4]
        category_counts = {}
        for cats in low_score_comments["categories"]:
            if isinstance(cats, list):
                for cat in cats:
                    category_counts[cat] = category_counts.get(cat, 0) + 1
        category_samples = {}
        for category in category_counts.keys():
            samples = []
            for _, row in low_score_comments.iterrows():
                if isinstance(row["categories"], list) and category in row["categories"]:
                    samples.append({
                        "comment": row["comment"],
                        "score": row["score"],
                        "station": row.get("station_info", "")
                    })
                    if len(samples) >= 3:
                        break
            category_samples[category] = samples
        results[name] = {
            "total_comments": len(group),
            "avg_score": group["score"].mean(),
            "score_distribution": score_dist,
            "low_score_categories": category_counts,
            "category_samples": category_samples,
            "critical_count": len(group[group["score"] <= 2])
        }
    return results

def display_comment_analysis(analysis_data, title="Yorum Analizi"):
    st.markdown(f"### ğŸ’¬ {title}")
    if not analysis_data:
        st.info("Yorum verisi bulunamadÄ±")
        return
    for idx, (name, data) in enumerate(analysis_data.items()):
        with st.expander(f"ğŸ“ {name} - {data['total_comments']} yorum, Ort: {data['avg_score']:.1f}"):
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**Puan DaÄŸÄ±lÄ±mÄ±:**")
                score_df = pd.DataFrame(list(data["score_distribution"].items()), columns=["Puan", "SayÄ±"]).sort_values("Puan")
                fig = px.bar(score_df, x="Puan", y="SayÄ±", color="Puan", color_continuous_scale="RdYlGn")
                st.plotly_chart(fig, use_container_width=True, key=f"score_dist_{title}_{idx}_{name}")
            with col2:
                st.markdown("**4 ve AltÄ± Puan Kategorileri:**")
                if data["low_score_categories"]:
                    cat_df = pd.DataFrame(list(data["low_score_categories"].items()), columns=["Kategori", "SayÄ±"]).sort_values("SayÄ±", ascending=False)
                    for _, row in cat_df.iterrows():
                        cat_class = f"category-{row['Kategori'].lower()}"
                        st.markdown(f"""
                        <span class="category-badge {cat_class}">
                            {row['Kategori']}: {row['SayÄ±']}
                        </span>
                        """, unsafe_allow_html=True)
                else:
                    st.info("DÃ¼ÅŸÃ¼k puan kategorisi yok")
            if data["category_samples"]:
                st.markdown("**ğŸ“ Kategori DetaylarÄ± (TÄ±klayÄ±n):**")
                for category, samples in data["category_samples"].items():
                    if samples:
                        with st.expander(f"{category} ({len(samples)} Ã¶rnek)"):
                            for sample in samples:
                                st.markdown(f"""
                                <div class="comment-card">
                                    <strong>Puan: {sample['score']}</strong><br>
                                    <em>{sample['comment']}</em><br>
                                    <small>{sample['station']}</small>
                                </div>
                                """, unsafe_allow_html=True)

def create_clickable_metric(col, title, value, key, df=None):
    with col:
        st.markdown(f"""
        <div class="metric-card">
            <h2>{value}</h2>
            <p>{title}</p>
        </div>
        """, unsafe_allow_html=True)
        if st.button("ğŸ“Š Detay", key=f"btn_{key}", use_container_width=True):
            st.session_state[f"show_{key}"] = not st.session_state.get(f"show_{key}", False)
    if st.session_state.get(f"show_{key}", False):
        with st.container():
            st.markdown(f"### ğŸ“Š {title} DetaylarÄ±")
            if key == "total_stations" and df is not None:
                display_df = df[["ROC", "Ä°stasyon", "SKOR", "DISTRICT", "Site Segment"]].copy()
                display_df["SKOR"] = display_df["SKOR"].apply(format_percentage)
                st.dataframe(display_df.sort_values("Ä°stasyon"), use_container_width=True, height=400)
            elif key == "avg_score" and df is not None:
                st.write("**ğŸ¯ OrtalamayÄ± En HÄ±zlÄ± ArtÄ±racak Ä°stasyonlar:**")
                impact_df = df[df["SKOR"] < 0.7].copy()
                if "TRANSACTION" in impact_df.columns:
                    impact_df["potential_impact"] = (0.7 - impact_df["SKOR"]) * impact_df.get("TRANSACTION", 1)
                    top_impact = impact_df.nlargest(10, "potential_impact")
                    for _, row in top_impact.iterrows():
                        potential_increase = (0.7 - row["SKOR"]) * 100
                        st.write(f"â€¢ **{row['Ä°stasyon']}**: {format_percentage(row['SKOR'])} â†’ 70% (+{potential_increase:.1f}%)")
            elif key == "saboteur" and df is not None:
                saboteur_df = df[df["Site Segment"] == "Saboteur"][["Ä°stasyon", "SKOR", "DISTRICT", "NOR"]].copy()
                saboteur_df["SKOR"] = saboteur_df["SKOR"].apply(format_percentage)
                st.dataframe(saboteur_df, use_container_width=True)
            elif key == "precious" and df is not None:
                precious_df = df[df["Site Segment"] == "My Precious"][["Ä°stasyon", "SKOR", "DISTRICT", "NOR"]].copy()
                precious_df["SKOR"] = precious_df["SKOR"].apply(format_percentage)
                st.dataframe(precious_df, use_container_width=True)
            if st.button("âŒ Kapat", key=f"close_{key}"):
                st.session_state[f"show_{key}"] = False
                st.rerun()


def calculate_tlag_score(comments_df, group_by="DISTRICT"):
    if comments_df is None or comments_df.empty:
        return pd.DataFrame()
    group_col = f"{group_by}_FINAL" if f"{group_by}_FINAL" in comments_df.columns else group_by
    if group_col not in comments_df.columns:
        return pd.DataFrame()
    results = []
    for name, group in comments_df.groupby(group_col):
        if pd.notna(name) and name != "nan" and name != "0":
            total_responses = len(group)
            five_star_count = len(group[group["score"] == 5])
            tlag_score = (five_star_count / total_responses * 100) if total_responses > 0 else 0
            results.append({
                group_by: name,
                "Toplam_YanÄ±t": total_responses,
                "5_Puan_SayÄ±sÄ±": five_star_count,
                "TLAG_Skoru_%": round(tlag_score, 1)
            })
    return pd.DataFrame(results)


# ------------------------------------------------------------
# (AI) Ã¶neriler & chat
# ------------------------------------------------------------
def ai_recommendations_for_scope(scope_name: str, df_scope: pd.DataFrame, comments_scope: pd.DataFrame):
    try:
        try:
            import openai
        except ImportError:
            return (
                "### ğŸ“¦ OpenAI ModÃ¼lÃ¼ Gerekli\n\n"
                "AI Ã¶nerileri iÃ§in `pip install openai` kurun veya secretsâ€™a anahtar ekleyin."
            )
        import os
        api_key = os.getenv("OPENAI_API_KEY") or (st.secrets.get("openai", {}).get("api_key") if hasattr(st, "secrets") else None)
        if not api_key:
            return (
                "### ğŸ”‘ OpenAI API AnahtarÄ± Gerekli\n\n"
                "ENV: `OPENAI_API_KEY` ya da `.streamlit/secrets.toml` iÃ§inde `[openai].api_key`."
            )
        openai.api_key = api_key

        summary = df_scope.assign(SkorY=(df_scope["SKOR"]*100).round(1) if "SKOR" in df_scope.columns else 0).to_dict(orient="records")[:200]
        probs = comments_scope[comments_scope.get("score", 5) <= 4][["comment", "score", "categories"]].head(300).to_dict(orient="records") if not comments_scope.empty else []

        prompt = f"""
        You are an ops analyst. Analyze performance for {scope_name}.
        1) Key drivers dragging score down
        2) Quick wins per category (PERSONEL, TEMÄ°ZLÄ°K, MARKET, HIZ, YAKIT, GENEL)
        3) 2-week action plan and expected impact in %.
        Data (stations): {summary}
        Low-score comments: {probs}
        Produce concise, bullet-point Turkish output.
        """
        try:
            client = openai.OpenAI(api_key=api_key)
            resp = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
            )
            return resp.choices[0].message.content.strip()
        except Exception:
            resp = openai.ChatCompletion.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
            )
            return resp.choices[0].message.content.strip()
    except Exception as e:
        return f"### âŒ AI Ã‡aÄŸrÄ±sÄ± BaÅŸarÄ±sÄ±z\n\nHata: {str(e)}"


def ai_chat_response(user_message: str, tlag_df=None, comments_df=None):
    try:
        try:
            import openai
        except ImportError:
            return "âŒ OpenAI modÃ¼lÃ¼ yÃ¼klÃ¼ deÄŸil. `pip install openai` komutunu Ã§alÄ±ÅŸtÄ±rÄ±n."

        import os
        api_key = os.getenv("OPENAI_API_KEY") or (st.secrets.get("openai", {}).get("api_key") if hasattr(st, "secrets") else None)
        if not api_key:
            return "âŒ OpenAI API anahtarÄ± bulunamadÄ±. LÃ¼tfen API anahtarÄ±nÄ±zÄ± ayarlayÄ±n."

        data_context = ""
        if tlag_df is not None and not tlag_df.empty:
            total_stations = len(tlag_df)
            avg_score = tlag_df["SKOR"].mean() if "SKOR" in tlag_df.columns else 0
            districts = list(tlag_df["DISTRICT"].dropna().unique()) if "DISTRICT" in tlag_df.columns else []
            segments = list(tlag_df["Site Segment"].dropna().unique()) if "Site Segment" in tlag_df.columns else []
            if "SKOR" in tlag_df.columns:
                top5 = tlag_df.nlargest(5, "SKOR")[["Ä°stasyon", "SKOR", "DISTRICT"]].to_dict("records")
                bottom5 = tlag_df.nsmallest(5, "SKOR")[["Ä°stasyon", "SKOR", "DISTRICT"]].to_dict("records")
            else:
                top5, bottom5 = [], []
            data_context += f"""
            TLAG VERÄ° Ã–ZETÄ°:
            - Toplam Ä°stasyon: {total_stations}
            - Ortalama Skor: {avg_score:.1%}
            - District'ler: {', '.join(districts[:10])}
            - Segmentler: {', '.join(segments)}
            - En Ä°yi 5 Ä°stasyon: {top5}
            - En DÃ¼ÅŸÃ¼k 5 Ä°stasyon: {bottom5}
            """

        if comments_df is not None and not comments_df.empty:
            total_comments = len(comments_df)
            avg_comment_score = comments_df["score"].mean() if "score" in comments_df.columns else 0
            low_scores = len(comments_df[comments_df["score"] <= 2]) if "score" in comments_df.columns else 0
            all_categories = {}
            if "categories" in comments_df.columns:
                for cats in comments_df["categories"]:
                    if isinstance(cats, list):
                        for cat in cats:
                            all_categories[cat] = all_categories.get(cat, 0) + 1
            data_context += f"""
            YORUM VERÄ° Ã–ZETÄ°:
            - Toplam Yorum: {total_comments}
            - Ortalama Puan: {avg_comment_score:.1f}
            - DÃ¼ÅŸÃ¼k Puan (â‰¤2): {low_scores}
            - En Ã‡ok Bahsedilen Kategoriler: {dict(sorted(all_categories.items(), key=lambda x: x[1], reverse=True)[:5])}
            """

        system_prompt = f"""Sen TLAG Performans Analitik asistanÄ±sÄ±n. TÃ¼rk Petrol istasyonlarÄ± hakkÄ±nda data analizi yapan, TÃ¼rkÃ§e konuÅŸan uzman bir analistsin.

GÃ¶revlerin:
1. TLAG verileri ve mÃ¼ÅŸteri yorumlarÄ±nÄ± analiz etmek
2. Performance Ã¶nerileri vermek
3. KullanÄ±cÄ±nÄ±n sorularÄ±na veri tabanlÄ± cevaplar vermek
4. Grafik ve analiz Ã¶nerileri sunmak
5. Ä°ÅŸ kararlarÄ±na destek olmak

Mevcut veri durumu:
{data_context if data_context else "HenÃ¼z veri yÃ¼klenmemiÅŸ."}

KURALLAR:
- Her zaman TÃ¼rkÃ§e yanÄ±t ver
- Somut veriler kullan
- EÄŸer grafik/analiz Ã¶nerirsen, hangi verilerin kullanÄ±lacaÄŸÄ±nÄ± belirt
- KÄ±sa ve Ã¶z cevaplar ver
- Business odaklÄ± dÃ¼ÅŸÃ¼n"""

        messages = [{"role": "system", "content": system_prompt}]
        for msg in st.session_state.chat_history[-10:]:
            messages.append(msg)
        messages.append({"role": "user", "content": user_message})

        try:
            import openai
            client = openai.OpenAI(api_key=api_key)
            resp = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                temperature=0.7,
                max_tokens=1500
            )
            return resp.choices[0].message.content.strip()
        except Exception:
            openai.api_key = api_key
            resp = openai.ChatCompletion.create(
                model="gpt-4o-mini",
                messages=messages,
                temperature=0.7,
                max_tokens=1500
            )
            return resp.choices[0].message.content.strip()
    except Exception as e:
        return f"âŒ AI hatasÄ±: {str(e)}"


def generate_ai_chart(user_request: str, tlag_df=None, comments_df=None):
    try:
        if tlag_df is None or tlag_df.empty:
            return None, "Grafik oluÅŸturmak iÃ§in TLAG verisi gerekli."
        request_lower = user_request.lower()

        if any(word in request_lower for word in ["district", "bÃ¶lge", "performans daÄŸÄ±lÄ±m"]):
            if "DISTRICT" in tlag_df.columns and "SKOR" in tlag_df.columns:
                district_avg = tlag_df.groupby("DISTRICT")["SKOR"].mean().reset_index()
                district_avg["Skor_YÃ¼zde"] = district_avg["SKOR"] * 100
                district_avg = district_avg.sort_values("Skor_YÃ¼zde", ascending=False)
                fig = px.bar(
                    district_avg, x="DISTRICT", y="Skor_YÃ¼zde",
                    title="District BazÄ±nda Ortalama Performans",
                    labels={"Skor_YÃ¼zde": "Ortalama Skor (%)", "DISTRICT": "District"},
                    color="Skor_YÃ¼zde", color_continuous_scale="RdYlGn"
                )
                fig.add_hline(y=70, line_dash="dash", line_color="orange", annotation_text="Hedef: 70%")
                return fig, "District bazÄ±nda performans analizi oluÅŸturuldu."

        elif any(word in request_lower for word in ["segment", "saboteur", "precious"]):
            if "Site Segment" in tlag_df.columns and "SKOR" in tlag_df.columns:
                segment_counts = tlag_df["Site Segment"].value_counts()
                fig = px.pie(values=segment_counts.values, names=segment_counts.index, title="Ä°stasyon Segment DaÄŸÄ±lÄ±mÄ±")
                return fig, "Segment daÄŸÄ±lÄ±mÄ± grafiÄŸi oluÅŸturuldu."

        elif any(word in request_lower for word in ["skor daÄŸÄ±lÄ±m", "histogram", "puan daÄŸÄ±lÄ±m"]):
            if "SKOR" in tlag_df.columns:
                tlag_viz = tlag_df.copy()
                tlag_viz["Skor_YÃ¼zde"] = tlag_viz["SKOR"] * 100
                fig = px.histogram(
                    tlag_viz, x="Skor_YÃ¼zde", nbins=20, title="Performans Skor DaÄŸÄ±lÄ±mÄ±",
                    labels={"Skor_YÃ¼zde": "Skor (%)", "count": "Ä°stasyon SayÄ±sÄ±"}
                )
                fig.add_vline(x=70, line_dash="dash", line_color="orange", annotation_text="Hedef: 70%")
                return fig, "Skor daÄŸÄ±lÄ±mÄ± histogramÄ± oluÅŸturuldu."

        elif any(word in request_lower for word in ["yorum", "comment", "mÃ¼ÅŸteri puan"]):
            if comments_df is not None and not comments_df.empty and "score" in comments_df.columns:
                score_counts = comments_df["score"].value_counts().sort_index()
                fig = px.bar(
                    x=score_counts.index, y=score_counts.values,
                    title="MÃ¼ÅŸteri YorumlarÄ± Puan DaÄŸÄ±lÄ±mÄ±",
                    labels={"x": "Puan", "y": "Yorum SayÄ±sÄ±"},
                    color=score_counts.index, color_continuous_scale="RdYlGn"
                )
                return fig, "MÃ¼ÅŸteri yorum puanlarÄ± grafiÄŸi oluÅŸturuldu."

        elif any(word in request_lower for word in ["nor", "bÃ¶lgesel"]):
            if "NOR" in tlag_df.columns and "SKOR" in tlag_df.columns:
                nor_avg = tlag_df.groupby("NOR")["SKOR"].agg(["mean", "count"]).reset_index()
                nor_avg["Skor_YÃ¼zde"] = nor_avg["mean"] * 100
                nor_avg = nor_avg.sort_values("Skor_YÃ¼zde", ascending=False)
                fig = px.scatter(
                    nor_avg, x="count", y="Skor_YÃ¼zde", size="count", hover_name="NOR",
                    title="NOR BazÄ±nda Performans (BÃ¼yÃ¼klÃ¼k: Ä°stasyon SayÄ±sÄ±)",
                    labels={"count": "Ä°stasyon SayÄ±sÄ±", "Skor_YÃ¼zde": "Ortalama Skor (%)"}
                )
                return fig, "NOR bazÄ±nda performans analizi oluÅŸturuldu."

        return None, "Bu tÃ¼r grafik iÃ§in uygun veri bulunamadÄ± veya istek anlaÅŸÄ±lamadÄ±."
    except Exception as e:
        return None, f"Grafik oluÅŸturma hatasÄ±: {str(e)}"


# ------------------------------------------------------------
# MAIN UI
# ------------------------------------------------------------
def main():
    st.markdown('<h1 class="main-header">ğŸ“Š TLAG PERFORMANS ANALÄ°TÄ°K</h1>', unsafe_allow_html=True)

    # Sidebar period selector
    st.sidebar.markdown("## ğŸ“… DÃ–NEM SEÃ‡Ä°MÄ°")
    period_types = ["WEEK", "MONTH", "QUARTER", "HALF", "YEAR"]
    selected_period_type = st.sidebar.selectbox("DÃ¶nem TÃ¼rÃ¼:", period_types, index=1)
    selected_year = st.sidebar.selectbox("YÄ±l:", [2024, 2025], index=1)

    gran_val = None
    if selected_period_type == "WEEK":
        gran_val = st.sidebar.selectbox("Hafta No:", range(1, 54))
    elif selected_period_type == "MONTH":
        months = {1: "Ocak", 2: "Åubat", 3: "Mart", 4: "Nisan", 5: "MayÄ±s", 6: "Haziran", 7: "Temmuz", 8: "AÄŸustos", 9: "EylÃ¼l", 10: "Ekim", 11: "KasÄ±m", 12: "AralÄ±k"}
        gran_val = st.sidebar.selectbox("Ay:", list(months.keys()), format_func=lambda x: months[x])
    elif selected_period_type == "QUARTER":
        quarters = {1: "Q1", 2: "Q2", 3: "Q3", 4: "Q4"}
        gran_val = st.sidebar.selectbox("Ã‡eyrek:", list(quarters.keys()), format_func=lambda x: quarters[x])
    elif selected_period_type == "HALF":
        halfs = {1: "Ä°lk YarÄ±", 2: "Ä°kinci YarÄ±"}
        gran_val = st.sidebar.selectbox("YarÄ±yÄ±l:", list(halfs.keys()), format_func=lambda x: halfs[x])

    # DÃ¶nemsel veri (Supabase) â€“ seÃ§ilen dÃ¶nemi DB'den oku
    if SUPABASE_ENABLED and st.sidebar.button("ğŸ”„ DÃ¶nemsel Veri YÃ¼kle"):
        try:
            df_from_db = fetch_tlag_by_period(selected_period_type, selected_year, gran_val)
            comments_from_db = fetch_comments_by_period(selected_period_type, selected_year, gran_val)

            if not df_from_db.empty:
                st.session_state.tlag_data = df_from_db
                st.sidebar.success(f"âœ… {len(df_from_db)} istasyon verisi yÃ¼klendi!")
            else:
                st.sidebar.warning("âŒ SeÃ§ili dÃ¶nem iÃ§in istasyon verisi bulunamadÄ±")

            if not comments_from_db.empty:
                merged_comments = merge_comments_with_stations(
                    comments_from_db, st.session_state.tlag_data or pd.DataFrame()
                )
                st.session_state.comments_data = merged_comments
                district_comments = analyze_comments_by_category(merged_comments, "district")
                nor_comments = analyze_comments_by_category(merged_comments, "nor")
                st.session_state.analyzed_comments = {"district": district_comments, "nor": nor_comments}
                st.sidebar.success(f"âœ… {len(comments_from_db)} yorum yÃ¼klendi!")
            elif st.session_state.get("comments_data") is None:
                st.sidebar.info("â„¹ï¸ SeÃ§ili dÃ¶nem iÃ§in yorum bulunamadÄ±")
        except Exception as e:
            st.sidebar.error(f"Veri yÃ¼kleme hatasÄ±: {str(e)}")

    # Dosya yÃ¼kleme
    st.sidebar.markdown("## ğŸ“ VERÄ° YÃ–NETÄ°MÄ°")
    uploaded_file = st.sidebar.file_uploader("TLAG Excel dosyasÄ±:", type=["xlsx", "xls"], help="satis_veri_clean.xlsx dosyanÄ±zÄ± yÃ¼kleyin")

    st.sidebar.markdown("## ğŸ’¬ MÃœÅTERÄ° YORUMLARI")
    comments_file = st.sidebar.file_uploader("Yorum dosyasÄ± (Excel):", type=["xlsx", "xls"], key="comments_uploader", help="Comment YTD All.xlsx dosyanÄ±zÄ± yÃ¼kleyin")

    # Demo veri seÃ§enekleri
    st.sidebar.markdown("## ğŸš€ DEMO VERÄ°LERÄ°")
    col1, col2 = st.sidebar.columns(2)
    with col1:
        if st.button("â˜ï¸ Cloud'dan YÃ¼kle", key="load_cloud_demo", use_container_width=True):
            with st.spinner("â˜ï¸ Cloud'dan demo veriler yÃ¼kleniyor..."):
                tlag_df, comments_df, message = load_demo_data_from_cloud()
                if tlag_df is not None:
                    st.session_state.tlag_data = tlag_df
                    st.session_state.demo_data_loaded = True
                    if comments_df is not None:
                        merged_comments = merge_comments_with_stations(comments_df, tlag_df)
                        st.session_state.comments_data = merged_comments
                        district_comments = analyze_comments_by_category(merged_comments, "district")
                        nor_comments = analyze_comments_by_category(merged_comments, "nor")
                        st.session_state.analyzed_comments = {"district": district_comments, "nor": nor_comments}
                    st.sidebar.success(message)
                else:
                    st.sidebar.error(message)

    with col2:
        if st.button("ğŸ“Š Lokal Demo", key="load_local_demo", use_container_width=True):
            tlag_df, comments_df = create_demo_data_files()
            st.session_state.tlag_data = tlag_df
            st.session_state.demo_data_loaded = True
            merged_comments = merge_comments_with_stations(comments_df, tlag_df)
            st.session_state.comments_data = merged_comments
            district_comments = analyze_comments_by_category(merged_comments, "district")
            nor_comments = analyze_comments_by_category(merged_comments, "nor")
            st.session_state.analyzed_comments = {"district": district_comments, "nor": nor_comments}
            st.sidebar.success("âœ… Lokal demo verisi yÃ¼klendi!")

    if st.sidebar.button("ğŸ“¥ Demo DosyalarÄ±nÄ± Export Et", key="export_demo"):
        export_demo_data_files()

    if st.session_state.demo_data_loaded or st.session_state.tlag_data is not None:
        with st.sidebar.expander("ğŸ“Š YÃ¼klÃ¼ Veri Durumu"):
            if st.session_state.tlag_data is not None:
                st.write(f"âœ… **TLAG:** {len(st.session_state.tlag_data)} istasyon")
            if st.session_state.comments_data is not None:
                st.write(f"âœ… **Yorumlar:** {len(st.session_state.comments_data)} yorum")
            if st.session_state.demo_data_loaded:
                st.info("ğŸš€ Demo verisi aktif")

    with st.sidebar.expander("â˜ï¸ Cloud Setup Rehberi"):
        st.markdown("""
        **GitHub Raw URL YÃ¶ntemi:**
        1. GitHub'da public repo oluÅŸturun
        2. `tlag_demo.csv` ve `comments_demo.csv` yÃ¼kleyin
        3. Raw URL'leri alÄ±n ve kodda gÃ¼ncelleyin

        **Google Sheets YÃ¶ntemi:**
        1. Google Sheets'te veri oluÅŸturun
        2. "PaylaÅŸ" â†’ "BaÄŸlantÄ± alan herkes gÃ¶rÃ¼ntÃ¼leyebilir"
        3. URL: `/export?format=csv&gid=SHEET_ID`

        **Ã–rnek Raw URL:**
        `https://raw.githubusercontent.com/username/repo/main/tlag_demo.csv`
        """)

    if st.session_state.demo_data_loaded:
        st.sidebar.markdown("""
        <div style="background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%); padding: 0.5rem; border-radius: 10px; text-align: center; margin: 1rem 0;">
            <strong>ğŸš€ DEMO MODU AKTÄ°F</strong><br>
            <small>GerÃ§ekÃ§i Ã¶rnek veriler yÃ¼klÃ¼</small>
        </div>
        """, unsafe_allow_html=True)

    # TLAG dosyasÄ± yÃ¼klendiyse iÅŸle
    if uploaded_file is not None:
        with st.spinner("ğŸ“Š Veriler iÅŸleniyor..."):
            df = load_tlag_data(uploaded_file)
        if df is not None and not df.empty:
            df, meta = attach_period_columns(df, uploaded_file.name)
            st.session_state.tlag_data = df
            st.sidebar.success(f"âœ… {len(df)} istasyon verisi yÃ¼klendi!")
            st.sidebar.info(f"ğŸ“… DÃ¶nem: {meta.get('period_type', 'UNKNOWN')} {meta.get('year', '')}")

            if SUPABASE_ENABLED:
                try:
                    period_id = supabase_upsert_period(meta, uploaded_file.name)
                    supabase_save_tlag(df, period_id)  # â† normalize_roc kullanÄ±r
                    st.sidebar.success("âœ… Veriler Supabase'e kaydedildi!")
                except Exception as e:
                    st.sidebar.warning(f"âš ï¸ Supabase kayÄ±t baÅŸarÄ±sÄ±z: {str(e)}")

            with st.sidebar.expander("ğŸ“‹ Veri Ã–zeti"):
                st.write(f"**Toplam Ä°stasyon:** {len(df)}")
                if "SKOR" in df.columns:
                    avg_score = df["SKOR"].mean()
                    st.write(f"**Ortalama Skor:** {format_percentage(avg_score)}")
                    st.write(f"**En YÃ¼ksek:** {format_percentage(df['SKOR'].max())}")
                    st.write(f"**En DÃ¼ÅŸÃ¼k:** {format_percentage(df['SKOR'].min())}")
                if "Site Segment" in df.columns:
                    segments = df["Site Segment"].value_counts()
                    st.write("**Segment DaÄŸÄ±lÄ±mÄ±:**")
                    for segment, count in segments.items():
                        if pd.notna(segment):
                            st.write(f"- {segment}: {count}")

    # Yorum dosyasÄ± yÃ¼klendiyse iÅŸle
    if comments_file and st.session_state.tlag_data is not None:
        with st.spinner("ğŸ’¬ Yorumlar iÅŸleniyor..."):
            comments_df = load_comments_data(comments_file)
            if comments_df is not None:
                comments_df, meta2 = attach_period_columns(comments_df, comments_file.name)
                merged_comments = merge_comments_with_stations(comments_df, st.session_state.tlag_data)
                st.session_state.comments_data = merged_comments
                district_comments = analyze_comments_by_category(merged_comments, "district")
                nor_comments = analyze_comments_by_category(merged_comments, "nor")
                st.session_state.analyzed_comments = {"district": district_comments, "nor": nor_comments}
                st.sidebar.success(f"âœ… {len(comments_df)} yorum yÃ¼klendi ve analiz edildi!")

                if SUPABASE_ENABLED:
                    try:
                        period_id2 = supabase_upsert_period(meta2, comments_file.name)
                        supabase_save_comments(comments_df, period_id2)  # â† normalize_roc kullanÄ±r
                        st.sidebar.success("âœ… Yorumlar Supabase'e kaydedildi!")
                    except Exception as e:
                        st.sidebar.warning(f"âš ï¸ Yorum Supabase kayÄ±t baÅŸarÄ±sÄ±z: {str(e)}")

                with st.sidebar.expander("ğŸ’¬ Yorum Ã–zeti"):
                    st.write(f"**Toplam Yorum:** {len(comments_df)}")
                    if "score" in comments_df.columns:
                        avg_score = comments_df["score"].mean()
                        st.write(f"**Ortalama Puan:** {avg_score:.1f}")
                        score_dist = comments_df["score"].value_counts().sort_index()
                        st.write("**Puan DaÄŸÄ±lÄ±mÄ±:**")
                        for score, count in score_dist.items():
                            if pd.notna(score) and score <= 5:
                                st.write(f"- {int(score)} puan: {count}")

    # Navigation
    st.markdown("### ğŸ¯ ANALÄ°Z ALANINA GÄ°T")
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        if st.button("ğŸ¢ District Analiz", key="nav_district", use_container_width=True):
            st.session_state.current_view = "district"
            st.rerun()
    with col2:
        if st.button("ğŸ“ NOR Analiz", key="nav_nor", use_container_width=True):
            st.session_state.current_view = "nor"
            st.rerun()
    with col3:
        if st.button("ğŸª Ä°stasyon Analiz", key="nav_station", use_container_width=True):
            st.session_state.current_view = "station"
            st.rerun()
    with col4:
        if st.button("ğŸ¤– AI Asistan", key="nav_ai", use_container_width=True):
            st.session_state.current_view = "ai_chat"
            st.rerun()

    # Views
    if st.session_state.current_view == "main":
        if st.session_state.tlag_data is not None:
            df = st.session_state.tlag_data
            analyzed_comments = st.session_state.get("analyzed_comments") or {}
            district_comments = analyzed_comments.get("district", {}) if isinstance(analyzed_comments, dict) else {}

            st.markdown("## ğŸ“Š ANA METRÄ°KLER")
            col1, col2, col3, col4 = st.columns(4)
            create_clickable_metric(col1, "Toplam Ä°stasyon", len(df), "total_stations", df)
            if "SKOR" in df.columns:
                create_clickable_metric(col2, "Ortalama Skor", format_percentage(df["SKOR"].mean()), "avg_score", df)
            if "Site Segment" in df.columns:
                saboteur_count = len(df[df["Site Segment"] == "Saboteur"])
                precious_count = len(df[df["Site Segment"] == "My Precious"])
                create_clickable_metric(col3, "Saboteur", saboteur_count, "saboteur", df)
                create_clickable_metric(col4, "My Precious", precious_count, "precious", df)

            if "SKOR" in df.columns:
                st.markdown("## ğŸ“ˆ PERFORMANS DAÄILIMI")
                df_viz = df.copy()
                df_viz["Skor_YÃ¼zde"] = df_viz["SKOR"] * 100
                fig_dist = px.histogram(
                    df_viz, x="Skor_YÃ¼zde", nbins=20,
                    title="Performans Skor DaÄŸÄ±lÄ±mÄ± (%)",
                    labels={"Skor_YÃ¼zde": "Performans Skoru (%)", "count": "Ä°stasyon SayÄ±sÄ±"}
                )
                fig_dist.add_vline(x=70, line_dash="dash", line_color="orange", annotation_text="Hedef: 70%")
                fig_dist.update_layout(height=400)
                st.plotly_chart(fig_dist, use_container_width=True, key="main_perf_distribution")

            if st.session_state.comments_data is not None:
                st.markdown("## ğŸ“Š BÃ–LGESEL TLAG SKORLARI (MÃ¼ÅŸteri YorumlarÄ±ndan)")
                valid_districts = set(df["DISTRICT"].dropna().astype(str).unique())
                district_tlag = calculate_tlag_score(st.session_state.comments_data, "DISTRICT")
                if not district_tlag.empty:
                    district_tlag = district_tlag[district_tlag["DISTRICT"].astype(str).isin(valid_districts)]
                    district_tlag = district_tlag.sort_values("TLAG_Skoru_%", ascending=False)
                    fig_district_tlag = px.bar(
                        district_tlag, x="DISTRICT", y="TLAG_Skoru_%", text="TLAG_Skoru_%",
                        title="District BazÄ±nda TLAG SkorlarÄ± (%)",
                        labels={"TLAG_Skoru_%": "TLAG Skoru (%)", "DISTRICT": "District"},
                        color="TLAG_Skoru_%", color_continuous_scale="RdYlGn"
                    )
                    fig_district_tlag.update_traces(texttemplate="%{text:.1f}%", textposition="outside")
                    fig_district_tlag.add_hline(y=70, line_dash="dash", line_color="orange", annotation_text="Hedef: 70%")
                    st.plotly_chart(fig_district_tlag, use_container_width=True, key="main_district_tlag_scores")

                    c1, c2 = st.columns(2)
                    with c1:
                        st.markdown("### District DetaylarÄ±")
                        st.dataframe(district_tlag, use_container_width=True)
                    with c2:
                        nor_tlag = calculate_tlag_score(st.session_state.comments_data, "NOR")
                        if not nor_tlag.empty:
                            st.markdown("### NOR DetaylarÄ±")
                            nor_tlag = nor_tlag.sort_values("TLAG_Skoru_%", ascending=False)
                            st.dataframe(nor_tlag.head(10), use_container_width=True)
        else:
            st.markdown("## ğŸ¯ TLAG PERFORMANS ANALÄ°TÄ°K'E HOÅGELDÄ°NÄ°Z")
            st.info("ğŸ‘ˆ Sol panelden Excel dosyalarÄ±nÄ±zÄ± yÃ¼kleyin veya demo verilerini deneyin")
            c1, c2 = st.columns(2)
            with c1:
                st.markdown("""
                ### ğŸ“Š ANALÄ°Z Ã–ZELLÄ°KLERÄ°
                - âœ… TÄ±klanabilir metrikler
                - âœ… MÃ¼ÅŸteri yorumlarÄ± analizi
                - âœ… Kategori bazlÄ± yorum gruplandÄ±rma
                - âœ… District/NOR/Ä°stasyon analizi
                - âœ… AI-powered Ã¶neriler
                """)
            with c2:
                st.markdown("""
                ### ğŸ’¬ YORUM ANALÄ°ZÄ°
                - âœ… Otomatik kategorizasyon
                - âœ… DÃ¼ÅŸÃ¼k puan analizi
                - âœ… FÄ±rsat istasyonlarÄ± tespiti
                - âœ… GerÃ§ek yorum Ã¶rnekleri
                - âœ… Trend analizi
                """)

    elif st.session_state.current_view == "district":
        if st.session_state.tlag_data is not None:
            df = st.session_state.tlag_data
            analyzed_comments = st.session_state.get("analyzed_comments") or {}
            district_comments = analyzed_comments.get("district", {}) if isinstance(analyzed_comments, dict) else {}
            if st.button("ğŸ  Ana Sayfaya DÃ¶n", key="back_to_main_from_district"):
                st.session_state.current_view = "main"; st.rerun()
            st.markdown("## ğŸ¢ DISTRICT BAZLI ANALÄ°Z")
            if "DISTRICT" in df.columns:
                districts = sorted(df["DISTRICT"].dropna().unique())
                selected_district = st.selectbox("District SeÃ§in:", districts, key="district_selector")
                if selected_district:
                    district_data = df[df["DISTRICT"] == selected_district]
                    col1, col2, col3, col4 = st.columns(4)
                    with col1: st.metric("Ä°stasyon SayÄ±sÄ±", len(district_data))
                    with col2: st.metric("Ortalama Skor", format_percentage(district_data["SKOR"].mean()))
                    with col3:
                        if "Site Segment" in district_data.columns:
                            segments = district_data["Site Segment"].value_counts()
                            st.markdown("**Segment DaÄŸÄ±lÄ±mÄ±:**")
                            for seg, count in segments.head(3).items():
                                st.write(f"â€¢ {seg}: {count}")
                    with col4: st.metric("En DÃ¼ÅŸÃ¼k Skor", format_percentage(district_data["SKOR"].min()))
                    c1, c2 = st.columns(2)
                    with c1:
                        st.markdown("### ğŸ† En Ä°yi 5 Ä°stasyon")
                        top5 = district_data.nlargest(5, "SKOR")[["Ä°stasyon", "SKOR", "Site Segment"]].copy()
                        top5["SKOR"] = top5["SKOR"].apply(format_percentage)
                        st.dataframe(top5, use_container_width=True)
                    with c2:
                        st.markdown("### âš ï¸ En KÃ¶tÃ¼ 5 Ä°stasyon")
                        bottom5 = district_data.nsmallest(5, "SKOR")[["Ä°stasyon", "SKOR", "Site Segment"]].copy()
                        bottom5["SKOR"] = bottom5["SKOR"].apply(format_percentage)
                        st.dataframe(bottom5, use_container_width=True)
                    if st.button(f"ğŸ¤– {selected_district} iÃ§in AI Ã–nerisi OluÅŸtur", key=f"ai_district_{selected_district}"):
                        with st.spinner("AI analizi yapÄ±lÄ±yor..."):
                            district_comments_df = st.session_state.comments_data[
                                st.session_state.comments_data["DISTRICT_FINAL"] == selected_district
                            ] if st.session_state.comments_data is not None else pd.DataFrame()
                            ai_result = ai_recommendations_for_scope(selected_district, district_data, district_comments_df)
                            st.markdown("### ğŸ¤– AI Ã–nerileri"); st.markdown(ai_result)
                    if district_comments and selected_district in district_comments:
                        display_comment_analysis({selected_district: district_comments[selected_district]}, title=f"{selected_district} MÃ¼ÅŸteri YorumlarÄ±")

    elif st.session_state.current_view == "nor":
        if st.session_state.tlag_data is not None:
            df = st.session_state.tlag_data
            analyzed_comments = st.session_state.get("analyzed_comments") or {}
            nor_comments = analyzed_comments.get("nor", {}) if isinstance(analyzed_comments, dict) else {}
            if st.button("ğŸ  Ana Sayfaya DÃ¶n", key="back_to_main_from_nor"):
                st.session_state.current_view = "main"; st.rerun()
            st.markdown("## ğŸ“ NOR BAZLI ANALÄ°Z")
            if "NOR" in df.columns:
                nors = sorted(df["NOR"].dropna().unique())
                selected_nor = st.selectbox("NOR SeÃ§in:", nors, key="nor_selector")
                if selected_nor:
                    nor_data = df[df["NOR"] == selected_nor]
                    col1, col2, col3, col4 = st.columns(4)
                    with col1: st.metric("Ä°stasyon SayÄ±sÄ±", len(nor_data))
                    with col2: st.metric("Ortalama Skor", format_percentage(nor_data["SKOR"].mean()))
                    with col3:
                        if "Site Segment" in nor_data.columns:
                            st.metric("En YaygÄ±n Segment", nor_data["Site Segment"].mode().iloc[0] if len(nor_data["Site Segment"].mode()) > 0 else "N/A")
                    with col4: st.metric("Skor AralÄ±ÄŸÄ±", f"{format_percentage(nor_data['SKOR'].min())} - {format_percentage(nor_data['SKOR'].max())}")
                    c1, c2 = st.columns(2)
                    with c1:
                        st.markdown("### ğŸ† En Ä°yi 5 Ä°stasyon")
                        top5 = nor_data.nlargest(5, "SKOR")[["Ä°stasyon", "SKOR", "Site Segment", "DISTRICT"]].copy()
                        top5["SKOR"] = top5["SKOR"].apply(format_percentage)
                        st.dataframe(top5, use_container_width=True)
                    with c2:
                        st.markdown("### âš ï¸ En KÃ¶tÃ¼ 5 Ä°stasyon")
                        bottom5 = nor_data.nsmallest(5, "SKOR")[["Ä°stasyon", "SKOR", "Site Segment", "DISTRICT"]].copy()
                        bottom5["SKOR"] = bottom5["SKOR"].apply(format_percentage)
                        st.dataframe(bottom5, use_container_width=True)
                    st.markdown("### ğŸ“Š NOR Performans DaÄŸÄ±lÄ±mÄ±")
                    nor_viz = nor_data.copy(); nor_viz["Skor_YÃ¼zde"] = nor_viz["SKOR"] * 100
                    fig_nor = px.box(nor_viz, y="Skor_YÃ¼zde", x="Site Segment", title=f"{selected_nor} - Segment BazÄ±nda Performans", labels={"Skor_YÃ¼zde": "Performans Skoru (%)"})
                    st.plotly_chart(fig_nor, use_container_width=True, key=f"nor_perf_{selected_nor}")
                    if st.button(f"ğŸ¤– {selected_nor} iÃ§in AI Ã–nerisi OluÅŸtur", key=f"ai_nor_{selected_nor}"):
                        with st.spinner("AI analizi yapÄ±lÄ±yor..."):
                            nor_comments_df = st.session_state.comments_data[
                                st.session_state.comments_data["NOR_FINAL"] == selected_nor
                            ] if st.session_state.comments_data is not None else pd.DataFrame()
                            ai_result = ai_recommendations_for_scope(selected_nor, nor_data, nor_comments_df)
                            st.markdown("### ğŸ¤– AI Ã–nerileri"); st.markdown(ai_result)
                    if nor_comments and selected_nor in nor_comments:
                        display_comment_analysis({selected_nor: nor_comments[selected_nor]}, title=f"{selected_nor} MÃ¼ÅŸteri YorumlarÄ±")

    elif st.session_state.current_view == "station":
        if st.session_state.tlag_data is not None:
            df = st.session_state.tlag_data
            if st.button("ğŸ  Ana Sayfaya DÃ¶n", key="back_to_main_from_station"):
                st.session_state.current_view = "main"; st.rerun()
            st.markdown("## ğŸª Ä°STASYON DETAY ANALÄ°ZÄ°")
            station_search = st.text_input("ğŸ” Ä°stasyon ara:", placeholder="Ä°stasyon adÄ± yazÄ±n...", key="station_search")
            if station_search:
                filtered_stations = df[df["Ä°stasyon"].str.contains(station_search, case=False, na=False)]["Ä°stasyon"].tolist()
            else:
                filtered_stations = sorted(df["Ä°stasyon"].unique())
            if filtered_stations:
                selected_station = st.selectbox("Ä°stasyon seÃ§in:", filtered_stations, key="station_selector")
                if selected_station:
                    station_row = df[df["Ä°stasyon"] == selected_station].iloc[0]
                    station_data = station_row.to_dict()
                    col1, col2, col3 = st.columns([2, 1, 1])
                    with col1:
                        st.markdown(f"### ğŸ¢ {selected_station}")
                        st.markdown(f"**ROC:** {station_data.get('ROC_TEXT') or station_data.get('ROC') or 'N/A'}")
                        st.markdown(f"**BÃ¶lge:** {station_data.get('DISTRICT', 'N/A')}")
                        st.markdown(f"**NOR:** {station_data.get('NOR', 'N/A')}")
                        st.markdown(f"**Segment:** {station_data.get('Site Segment', 'N/A')}")
                    with col2:
                        current_score = station_data.get("SKOR", 0)
                        previous_score = station_data.get("GEÃ‡EN SENE SKOR", 0)
                        change_percent = (current_score - previous_score) * 100 if previous_score and current_score else 0
                        st.metric("Mevcut Skor", format_percentage(current_score), delta=format_percentage_change(change_percent))
                        st.metric("GeÃ§en YÄ±l", format_percentage(previous_score))
                    with col3:
                        category, color = get_performance_category(current_score)
                        st.markdown(f"""
                        <div style="background-color: {color}; color: white; padding: 1rem; border-radius: 10px; text-align: center; font-weight: bold;">
                            {category}
                        </div>
                        """, unsafe_allow_html=True)
                    if st.session_state.comments_data is not None:
                        station_code = normalize_roc(station_data.get("ROC_TEXT") or station_data.get("ROC_STR") or station_data.get("ROC"))
                        station_comments = st.session_state.comments_data[
                            st.session_state.comments_data["station_code"].astype(str) == str(station_code)
                        ]
                        if not station_comments.empty:
                            st.markdown("### ğŸ’¬ MÃ¼ÅŸteri YorumlarÄ±")
                            c1, c2 = st.columns(2)
                            with c1:
                                st.metric("Toplam Yorum", len(station_comments))
                                st.metric("Ortalama Puan", f"{station_comments['score'].mean():.1f}")
                            with c2:
                                score_counts = station_comments["score"].value_counts().sort_index()
                                fig_score = px.bar(x=score_counts.index, y=score_counts.values, title="Puan DaÄŸÄ±lÄ±mÄ±", labels={"x": "Puan", "y": "SayÄ±"})
                                st.plotly_chart(fig_score, use_container_width=True, key=f"station_score_{selected_station}")
                            st.markdown("### Son Yorumlar")
                            recent_comments = station_comments.head(5)
                            for _, comment in recent_comments.iterrows():
                                cats = comment["categories"] if isinstance(comment["categories"], list) else ["GENEL"]
                                cat_badges = " ".join([f'<span class="category-badge category-{cat.lower()}">{cat}</span>' for cat in cats])
                                st.markdown(f"""
                                <div class="comment-card">
                                    <strong>Puan: {comment['score']}</strong> {cat_badges}<br>
                                    <em>{comment['comment']}</em>
                                </div>
                                """, unsafe_allow_html=True)
                    if st.button(f"ğŸ¤– {selected_station} iÃ§in AI Ã–nerisi OluÅŸtur", key=f"ai_station_{selected_station}"):
                        with st.spinner("AI analizi yapÄ±lÄ±yor..."):
                            station_code = normalize_roc(station_data.get("ROC_TEXT") or station_data.get("ROC_STR") or station_data.get("ROC"))
                            station_comments_df = st.session_state.comments_data[
                                st.session_state.comments_data["station_code"].astype(str) == str(station_code)
                            ] if st.session_state.comments_data is not None else pd.DataFrame()
                            station_df = pd.DataFrame([station_data])
                            ai_result = ai_recommendations_for_scope(selected_station, station_df, station_comments_df)
                            st.markdown("### ğŸ¤– AI Ã–nerileri"); st.markdown(ai_result)

    elif st.session_state.current_view == "ai_chat":
        if st.button("ğŸ  Ana Sayfaya DÃ¶n", key="back_to_main_from_ai"):
            st.session_state.current_view = "main"; st.rerun()
        st.markdown("## ğŸ¤– AI ASISTAN")
        st.markdown("*TLAG verilerinizi analiz edebilen akÄ±llÄ± asistanÄ±nÄ±z*")
        c1, c2, c3 = st.columns(3)
        with c1:
            if st.button("ğŸ“Š Genel Ã–zet", key="quick_summary"):
                st.session_state.chat_history.append({"role": "user", "content": "TLAG verilerimin genel Ã¶zetini ver. En Ã¶nemli bulgularÄ± listele."})
        with c2:
            if st.button("âš ï¸ Problem AlanlarÄ±", key="quick_problems"):
                st.session_state.chat_history.append({"role": "user", "content": "En dÃ¼ÅŸÃ¼k performanslÄ± district'ler ve istasyonlar hangileri? SorunlarÄ± analiz et."})
        with c3:
            if st.button("ğŸ¯ Ä°yileÅŸtirme FÄ±rsatlarÄ±", key="quick_opportunities"):
                st.session_state.chat_history.append({"role": "user", "content": "Hangi alanlarda hÄ±zlÄ± kazanÄ±mlar elde edebilirim? Ã–ncelikli aksiyonlarÄ± listele."})
        st.markdown("### ğŸ’¬ Sohbet GeÃ§miÅŸi")
        chat_container = st.container()
        with chat_container:
            for message in st.session_state.chat_history:
                if message["role"] == "user":
                    with st.chat_message("user", avatar="ğŸ‘¤"): st.markdown(message["content"])
                else:
                    with st.chat_message("assistant", avatar="ğŸ¤–"): st.markdown(message["content"])
        user_input = st.chat_input("TLAG verileriniz hakkÄ±nda soru sorun veya analiz isteyin...")
        if user_input:
            st.session_state.chat_history.append({"role": "user", "content": user_input})
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                with st.spinner("ğŸ¤” DÃ¼ÅŸÃ¼nÃ¼yor..."):
                    ai_response = ai_chat_response(user_input, st.session_state.tlag_data, st.session_state.comments_data)
                    st.markdown(ai_response)
                    if any(word in user_input.lower() for word in ["grafik", "chart", "gÃ¶rselleÅŸtir", "plot", "diagram"]):
                        chart_fig, chart_msg = generate_ai_chart(user_input, st.session_state.tlag_data, st.session_state.comments_data)
                        if chart_fig:
                            st.plotly_chart(chart_fig, use_container_width=True, key=f"ai_chart_{len(st.session_state.chat_history)}")
                            st.info(f"ğŸ“ˆ {chart_msg}")
                        else:
                            st.warning(f"âš ï¸ {chart_msg}")
            st.session_state.chat_history.append({"role": "assistant", "content": ai_response})
            if len(st.session_state.chat_history) > 50:
                st.session_state.chat_history = st.session_state.chat_history[-50:]
            st.rerun()
        c1, c2, c3 = st.columns([1, 1, 2])
        with c1:
            if st.button("ğŸ—‘ï¸ Sohbeti Temizle", key="clear_chat"):
                st.session_state.chat_history = []; st.rerun()
        with c2:
            st.info(f"ğŸ’¬ {len(st.session_state.chat_history)} mesaj")
        with c3:
            if st.session_state.tlag_data is None:
                st.warning("âš ï¸ TLAG verisi yok - Sol panelden veri yÃ¼kleyin")
            else:
                station_count = len(st.session_state.tlag_data)
                comment_count = len(st.session_state.comments_data) if st.session_state.comments_data is not None else 0
                st.success(f"âœ… {station_count} istasyon, {comment_count} yorum yÃ¼klÃ¼")
        with st.expander("ğŸ’¡ Ã–rnek Sorular"):
            st.markdown("""
            **Genel Analiz:**
            - "En kÃ¶tÃ¼ performans gÃ¶steren 5 district'i listele"
            - "Saboteur segmentindeki istasyonlarÄ± analiz et"
            - "MÃ¼ÅŸteri yorumlarÄ±ndaki en bÃ¼yÃ¼k problemler neler?"

            **Grafik Ä°stekleri:**
            - "District bazÄ±nda performans grafiÄŸi oluÅŸtur"
            - "Segment daÄŸÄ±lÄ±mÄ± pasta grafiÄŸi gÃ¶ster"
            - "Skor daÄŸÄ±lÄ±mÄ± histogramÄ± Ã§iz"
            - "MÃ¼ÅŸteri yorumlarÄ± puan daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶rselleÅŸtir"

            **Aksiyonel Ã–neriler:**
            - "Hangi istasyonlara Ã¶ncelik vermeliyim?"
            - "PERSONEL kategorisindeki ÅŸikayetler nasÄ±l azaltÄ±lÄ±r?"
            - "Bu ay hangi district'e odaklanmalÄ±yÄ±m?"

            **KarÅŸÄ±laÅŸtÄ±rma:**
            - "Ankara ve Ä°stanbul bÃ¶lgelerini karÅŸÄ±laÅŸtÄ±r"
            - "My Precious ile Saboteur arasÄ±ndaki farklar neler?"
            """)

if __name__ == "__main__":
    main()
