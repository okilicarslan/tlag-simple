# app.py - Enhanced TLAG Performance Analytics

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
import re
import json
from datetime import datetime, date, timedelta
import calendar

# ------------------------------------------------------------
# KÃ¼Ã§Ã¼k yardÄ±mcÄ±lar
# ------------------------------------------------------------
def _to_int_safe(val):
    try:
        if val is None or (isinstance(val, float) and np.isnan(val)):
            return None
        if isinstance(val, str):
            v = val.strip()
            if v == "":
                return None
            if "." in v:
                v = v.split(".")[0]
            return int(v)
        if isinstance(val, float):
            return int(round(val))
        return int(val)
    except Exception:
        return None

def _to_float_safe(val):
    try:
        if val is None or (isinstance(val, float) and np.isnan(val)):
            return None
        return float(val)
    except Exception:
        return None

def normalize_roc(val):
    """ROC deÄŸerini gÃ¼venli biÃ§imde normalize eder."""
    if val is None or (isinstance(val, float) and np.isnan(val)):
        return None
    s = str(val).strip()
    if s.endswith(".0"):
        s = s[:-2]
    # Son 4 haneyi al (mÃ¼ÅŸteri yorumlarÄ± iÃ§in)
    m = re.search(r"#(\d{4})$", s)
    if m:
        return m.group(1)
    # Sadece rakam varsa al
    m = re.search(r"(\d+)", s)
    return m.group(1) if m else None

def extract_station_code(station_info):
    """Station info'dan son 4 haneli kodu Ã§Ä±karÄ±r"""
    if pd.isna(station_info):
        return None
    s = str(station_info)
    # #5789 formatÄ±
    m = re.search(r"#(\d{4})$", s)
    if m:
        return m.group(1)
    # Son 4 rakamÄ± al
    m = re.search(r"(\d{4})(?=\D*$)", s)
    return m.group(1) if m else None

# ------------------------------------------------------------
# Supabase entegrasyonu
# ------------------------------------------------------------
try:
    from modules.supabase_client import get_supabase_client
    SUPABASE_ENABLED = True
except ImportError:
    SUPABASE_ENABLED = False
    print("Supabase modÃ¼lÃ¼ yÃ¼klenemedi. Lokal modda Ã§alÄ±ÅŸÄ±yor.")

# ------------------------------------------------------------
# Demo veri yÃ¼kleme
# ------------------------------------------------------------
def load_demo_data_from_cloud():
    """Cloud'dan gerÃ§ek veriler"""
    try:
        TLAG_DEMO_URL = "https://raw.githubusercontent.com/okilicarslan/tlag-cloud-data/refs/heads/main/tlag_demo.csv"
        COMMENTS_DEMO_URL = "https://raw.githubusercontent.com/okilicarslan/tlag-cloud-data/refs/heads/main/comments_demo.csv"

        import requests
        from io import StringIO

        r1 = requests.get(TLAG_DEMO_URL, timeout=30)
        r1.raise_for_status()
        tlag_df = pd.read_csv(StringIO(r1.text), low_memory=False)

        for col in ["SKOR", "GEÃ‡EN SENE SKOR", "Fark", "TRANSACTION"]:
            if col in tlag_df.columns:
                tlag_df[col] = pd.to_numeric(tlag_df[col], errors="coerce")

        if "ROC_STR" not in tlag_df.columns and "ROC" in tlag_df.columns:
            tlag_df["ROC_STR"] = tlag_df["ROC"].astype(str).str.split(".").str[0]

        r2 = requests.get(COMMENTS_DEMO_URL, timeout=60)
        r2.raise_for_status()
        comments_df = pd.read_csv(
            StringIO(r2.text),
            low_memory=False,
            dtype={"station_code": "string"}
        )

        if "categories" in comments_df.columns:
            def _to_list(x):
                if isinstance(x, str) and x.strip().startswith("["):
                    try:
                        return json.loads(x)
                    except Exception:
                        return ["GENEL"]
                return [x] if pd.notna(x) else ["GENEL"]
            comments_df["categories"] = comments_df["categories"].apply(_to_list)

        return tlag_df, comments_df, "Cloud verileri baÅŸarÄ±yla yÃ¼klendi!"
    except Exception as e:
        return None, None, f"Cloud veri yÃ¼kleme hatasÄ±: {str(e)}"

# ------------------------------------------------------------
# Yorum kategorileri
# ------------------------------------------------------------
def categorize_comment_enhanced(comment_text):
    """GeliÅŸmiÅŸ yorum kategorileme"""
    if pd.isna(comment_text):
        return ["GENEL"]
    
    comment_lower = str(comment_text).lower()
    categories = []
    
    category_keywords = {
        "PERSONEL": [
            "personel", "Ã§alÄ±ÅŸan", "gÃ¶revli", "mÃ¼dÃ¼r", "yardÄ±msever", 
            "gÃ¼leryÃ¼zlÃ¼", "kaba", "ilgisiz", "saygÄ±lÄ±", "nazik", "kibar"
        ],
        "POMPACI": [
            "pompacÄ±", "yakÄ±t dolu", "benzin dolu", "motorin dolu",
            "cam sil", "kontrol et", "yaÄŸ kontrol", "su kontrol"
        ],
        "TEMÄ°ZLÄ°K": [
            "temiz", "kirli", "hijyen", "tuvalet", "pis", "bakÄ±m", 
            "tertip", "dÃ¼zen", "leke", "koku"
        ],
        "MARKET": [
            "market", "Ã¼rÃ¼n", "fiyat", "pahalÄ±", "ucuz", "Ã§eÅŸit", 
            "kalite", "taze", "kafe", "restoran"
        ],
        "HIZ": [
            "hÄ±zlÄ±", "yavaÅŸ", "bekleme", "kuyruk", "sÃ¼re", "geÃ§", 
            "Ã§abuk", "acele", "bekle", "zaman"
        ],
        "YAKIT": [
            "benzin", "motorin", "lpg", "yakÄ±t", "pompa", "dolum", 
            "depo", "kalite", "verim"
        ],
        "BANKA_KAMPANYA": [
            "kampanya", "indirim", "kart", "bonus", "puan", "fÄ±rsat",
            "promosyon", "taksit", "Ã¶deme"
        ],
        "GENEL": [
            "genel", "gÃ¼zel", "kÃ¶tÃ¼", "memnun", "beÄŸen", "hoÅŸ",
            "berbat", "sÃ¼per", "harika", "mÃ¼kemmel"
        ]
    }
    
    for category, keywords in category_keywords.items():
        if any(keyword in comment_lower for keyword in keywords):
            categories.append(category)
    
    return categories if categories else ["GENEL"]

# ------------------------------------------------------------
# Veri yÃ¼kleme fonksiyonlarÄ±
# ------------------------------------------------------------
def load_tlag_data(uploaded_file):
    """TLAG Excel dosyasÄ±nÄ± yÃ¼kler"""
    try:
        df = pd.read_excel(uploaded_file, sheet_name="TLAG DOKUNMA (2)", engine="openpyxl")
        df.columns = df.columns.str.strip()
        df = df.dropna(subset=["ROC", "Ä°stasyon"], how="any")
        
        # Numeric columns
        numeric_columns = ["ROC", "SKOR", "GEÃ‡EN SENE SKOR", "Fark", "TRANSACTION"]
        for col in numeric_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors="coerce")
        
        # Text columns
        text_columns = ["Ä°stasyon", "NOR", "DISTRICT", "Site Segment"]
        for col in text_columns:
            if col in df.columns:
                df[col] = df[col].astype(str).str.strip()
                df[col] = df[col].replace("nan", np.nan)
        
        # ROC normalizasyonu
        df["ROC_STR"] = df["ROC"].astype(str).str.split(".").str[0]
        df["ROC_NORMALIZED"] = df["ROC_STR"].apply(normalize_roc)
        
        return df
    except Exception as e:
        st.error(f"TLAG dosya okuma hatasÄ±: {str(e)}")
        return None

def load_comments_data(uploaded_file):
    """MÃ¼ÅŸteri yorum dosyasÄ±nÄ± yÃ¼kler"""
    try:
        df = pd.read_excel(uploaded_file, header=1, engine="openpyxl")
        
        # Ä°lk satÄ±rlarÄ± temizle
        df = df[df.iloc[:, 0] != "65000 yorum sÄ±nÄ±rÄ±nÄ± aÅŸtÄ±nÄ±z."]
        df = df[df.iloc[:, 0] != "birim"]
        df = df.dropna(subset=[df.columns[0]], how="all")
        
        # Kolon adlandÄ±rmasÄ±
        column_names = {}
        if len(df.columns) >= 9:
            column_names = {
                df.columns[0]: "station_info",
                df.columns[1]: "survey_item", 
                df.columns[2]: "comment",
                df.columns[3]: "score",
                df.columns[4]: "visit_date",
                df.columns[5]: "hospitality_score",
                df.columns[6]: "dealer",
                df.columns[7]: "territory",
                df.columns[8]: "district"
            }
        
        df = df.rename(columns=column_names)
        
        # Station code Ã§Ä±karÄ±mÄ±
        df["station_code"] = df["station_info"].apply(extract_station_code)
        df["score"] = pd.to_numeric(df["score"], errors="coerce")
        
        # GeliÅŸmiÅŸ kategorizasyon
        df["categories"] = df["comment"].apply(categorize_comment_enhanced)
        
        # 4 puan ama olumlu yorum tespiti
        df["positive_but_4star"] = df.apply(
            lambda row: (
                row["score"] == 4 and 
                isinstance(row["comment"], str) and
                any(word in str(row["comment"]).lower() for word in 
                    ["gÃ¼zel", "iyi", "memnun", "beÄŸen", "sÃ¼per", "harika"])
            ), axis=1
        )
        
        return df
    except Exception as e:
        st.error(f"Yorum dosyasÄ± okuma hatasÄ±: {str(e)}")
        return None

# ------------------------------------------------------------
# Analiz fonksiyonlarÄ±
# ------------------------------------------------------------
def get_opportunity_stations(df):
    """FÄ±rsat istasyonlarÄ±nÄ± bulur (My Precious/Primitive <80%)"""
    if df is None or df.empty or "SKOR" not in df.columns:
        return pd.DataFrame()
    
    opportunity_mask = (
        (df["Site Segment"].isin(["My Precious", "Primitive"])) & 
        (df["SKOR"] < 0.80)
    )
    
    return df[opportunity_mask].copy()

def analyze_comments_by_scope(comments_df, scope_col="DISTRICT"):
    """KapsamlÄ± yorum analizi"""
    if comments_df is None or comments_df.empty:
        return {}
    
    # Scope column belirleme
    if scope_col == "DISTRICT":
        group_col = "DISTRICT_FINAL" if "DISTRICT_FINAL" in comments_df.columns else "district"
    elif scope_col == "NOR":
        group_col = "NOR_FINAL" if "NOR_FINAL" in comments_df.columns else "territory"
    else:
        group_col = scope_col
        
    if group_col not in comments_df.columns:
        return {}
    
    results = {}
    
    for name, group in comments_df.groupby(group_col):
        if pd.isna(name) or name == "nan" or name == "0":
            continue
            
        total_comments = len(group)
        avg_score = group["score"].mean()
        
        # Puan daÄŸÄ±lÄ±mÄ±
        score_dist = group["score"].value_counts().to_dict()
        
        # DÃ¼ÅŸÃ¼k puan yorumlarÄ± (1-3 puan)
        low_score_comments = group[group["score"] <= 3]
        
        # Kategori analizi
        category_counts = {}
        category_scores = {}
        
        for _, row in group.iterrows():
            if isinstance(row["categories"], list):
                for cat in row["categories"]:
                    if cat not in category_counts:
                        category_counts[cat] = 0
                        category_scores[cat] = []
                    category_counts[cat] += 1
                    category_scores[cat].append(row["score"])
        
        # Kategori ortalama puanlarÄ±
        category_avg_scores = {
            cat: np.mean(scores) for cat, scores in category_scores.items()
        }
        
        # En problemli kategoriler (dÃ¼ÅŸÃ¼k puan + yÃ¼ksek frekans)
        problem_categories = {}
        for cat in category_counts:
            if category_avg_scores[cat] < 4.0 and category_counts[cat] >= 3:
                problem_categories[cat] = {
                    "count": category_counts[cat],
                    "avg_score": category_avg_scores[cat],
                    "problem_level": (5 - category_avg_scores[cat]) * category_counts[cat]
                }
        
        # Olumlu ama 4 puan verenler
        positive_4star = group[group.get("positive_but_4star", False) == True]
        
        results[name] = {
            "total_comments": total_comments,
            "avg_score": avg_score,
            "score_distribution": score_dist,
            "category_counts": category_counts,
            "category_avg_scores": category_avg_scores,
            "problem_categories": sorted(
                problem_categories.items(), 
                key=lambda x: x[1]["problem_level"], 
                reverse=True
            )[:3],
            "positive_4star_count": len(positive_4star),
            "critical_issues": len(group[group["score"] <= 2])
        }
    
    return results

def get_top_focus_areas(comments_analysis, top_n=3):
    """En Ã§ok odaklanÄ±lmasÄ± gereken alanlarÄ± dÃ¶ndÃ¼rÃ¼r"""
    all_problems = {}
    
    for scope_data in comments_analysis.values():
        for cat, data in scope_data.get("problem_categories", []):
            if cat not in all_problems:
                all_problems[cat] = {"total_impact": 0, "instances": 0}
            all_problems[cat]["total_impact"] += data["problem_level"]
            all_problems[cat]["instances"] += 1
    
    # En yÃ¼ksek impact'li kategoriler
    sorted_problems = sorted(
        all_problems.items(),
        key=lambda x: x[1]["total_impact"],
        reverse=True
    )
    
    return [item[0] for item in sorted_problems[:top_n]]

# ------------------------------------------------------------
# UI Components
# ------------------------------------------------------------
def create_enhanced_metric_card(col, title, value, key, click_data=None):
    """GeliÅŸmiÅŸ metrik kartlarÄ±"""
    with col:
        st.markdown(f"""
        <div class="metric-card" onclick="toggleDetails('{key}')">
            <h2>{value}</h2>
            <p>{title}</p>
            <small>ğŸ“Š Detay iÃ§in tÄ±klayÄ±n</small>
        </div>
        """, unsafe_allow_html=True)
        
        if st.button("ğŸ“Š DetaylarÄ± GÃ¶ster", key=f"btn_{key}", use_container_width=True):
            st.session_state[f"show_{key}"] = not st.session_state.get(f"show_{key}", False)
    
    # Detay gÃ¶sterimi
    if st.session_state.get(f"show_{key}", False) and click_data is not None:
        with st.expander(f"ğŸ“‹ {title} DetaylarÄ±", expanded=True):
            if key == "total_stations":
                display_station_list(click_data)
            elif key == "avg_score": 
                display_score_improvement_analysis(click_data)
            elif key.startswith("segment_"):
                segment_name = key.replace("segment_", "").replace("_", " ")
                display_segment_analysis(click_data, segment_name)
            
            if st.button("âŒ Kapat", key=f"close_{key}"):
                st.session_state[f"show_{key}"] = False
                st.rerun()

def display_station_list(df):
    """Ä°stasyon listesi gÃ¶sterimi"""
    if df is None or df.empty:
        st.info("Veri bulunamadÄ±")
        return
    
    display_cols = ["ROC_STR", "Ä°stasyon", "SKOR", "DISTRICT", "NOR", "Site Segment"]
    available_cols = [col for col in display_cols if col in df.columns]
    
    display_df = df[available_cols].copy()
    
    if "SKOR" in display_df.columns:
        display_df["SKOR_FORMATTED"] = display_df["SKOR"].apply(
            lambda x: f"{x*100:.1f}%" if pd.notna(x) else "N/A"
        )
        display_df = display_df.drop(columns=["SKOR"])
        display_df = display_df.rename(columns={"SKOR_FORMATTED": "SKOR"})
    
    # Ä°stasyon seÃ§imi iÃ§in selectbox
    st.markdown("### ğŸª Ä°stasyon SeÃ§in:")
    selected_station = st.selectbox(
        "Ä°stasyon:", 
        df["Ä°stasyon"].tolist(),
        key="station_detail_selector"
    )
    
    if selected_station:
        station_data = df[df["Ä°stasyon"] == selected_station].iloc[0]
        display_station_detail(station_data)
    
    # Tablo gÃ¶sterimi
    st.markdown("### ğŸ“Š TÃ¼m Ä°stasyonlar:")
    st.dataframe(display_df, use_container_width=True, height=400)

def display_station_detail(station_data):
    """DetaylÄ± istasyon bilgileri"""
    st.markdown(f"### ğŸª {station_data['Ä°stasyon']} DetaylarÄ±")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Mevcut Skor", f"{station_data.get('SKOR', 0)*100:.1f}%")
        st.metric("ROC Kodu", station_data.get('ROC_STR', 'N/A'))
    
    with col2:
        st.metric("District", station_data.get('DISTRICT', 'N/A'))
        st.metric("NOR", station_data.get('NOR', 'N/A'))
    
    with col3:
        st.metric("Site Segment", station_data.get('Site Segment', 'N/A'))
        if pd.notna(station_data.get('TRANSACTION')):
            st.metric("Transaction", f"{station_data['TRANSACTION']:,.0f}")
    
    # Yorum analizi (eÄŸer varsa)
    if st.session_state.get("comments_data") is not None:
        station_code = station_data.get("ROC_NORMALIZED") or station_data.get("ROC_STR")
        station_comments = st.session_state.comments_data[
            st.session_state.comments_data["station_code"] == str(station_code)
        ]
        
        if not station_comments.empty:
            display_station_comments(station_comments)

def display_station_comments(comments_df):
    """Ä°stasyon yorumlarÄ±nÄ± gÃ¶ster"""
    st.markdown("### ğŸ’¬ MÃ¼ÅŸteri YorumlarÄ±")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric("Toplam Yorum", len(comments_df))
        st.metric("Ortalama Puan", f"{comments_df['score'].mean():.1f}")
    
    with col2:
        # Puan daÄŸÄ±lÄ±mÄ± grafiÄŸi
        score_counts = comments_df['score'].value_counts().sort_index()
        fig = px.bar(
            x=score_counts.index, 
            y=score_counts.values,
            title="Puan DaÄŸÄ±lÄ±mÄ±",
            labels={"x": "Puan", "y": "Yorum SayÄ±sÄ±"}
        )
        st.plotly_chart(fig, use_container_width=True)
    
    # Kategori analizi
    st.markdown("#### ğŸ“Š Kategori BazlÄ± Analiz")
    category_scores = {}
    
    for _, row in comments_df.iterrows():
        if isinstance(row["categories"], list):
            for cat in row["categories"]:
                if cat not in category_scores:
                    category_scores[cat] = []
                category_scores[cat].append(row["score"])
    
    # Kategori performansÄ± tablosu
    cat_data = []
    for cat, scores in category_scores.items():
        cat_data.append({
            "Kategori": cat,
            "Yorum SayÄ±sÄ±": len(scores),
            "Ortalama Puan": f"{np.mean(scores):.1f}",
            "Problem Seviyesi": "ğŸ”´ YÃ¼ksek" if np.mean(scores) < 3.5 else "ğŸŸ¡ Orta" if np.mean(scores) < 4.0 else "ğŸŸ¢ DÃ¼ÅŸÃ¼k"
        })
    
    cat_df = pd.DataFrame(cat_data).sort_values("Ortalama Puan")
    st.dataframe(cat_df, use_container_width=True)
    
    # Son yorumlar
    st.markdown("#### ğŸ’­ Son Yorumlar")
    for _, comment in comments_df.head(5).iterrows():
        with st.container():
            cats = comment["categories"] if isinstance(comment["categories"], list) else ["GENEL"]
            cat_tags = " ".join([f"`{cat}`" for cat in cats])
            
            st.markdown(f"""
            **Puan: {comment['score']}/5** | {cat_tags}
            
            _{comment['comment']}_
            
            ---
            """)

def display_score_improvement_analysis(df):
    """Skor iyileÅŸtirme analizi"""
    st.markdown("### ğŸ¯ Skor Ä°yileÅŸtirme Stratejisi")
    
    if df is None or df.empty or "SKOR" not in df.columns:
        st.info("Skor verisi bulunamadÄ±")
        return
    
    # Potansiyel impact hesaplama
    improvement_opportunities = df[df["SKOR"] < 0.80].copy()
    
    if "TRANSACTION" in improvement_opportunities.columns:
        improvement_opportunities["potential_impact"] = (
            (0.80 - improvement_opportunities["SKOR"]) * 
            improvement_opportunities["TRANSACTION"] / 1000
        )
        improvement_opportunities = improvement_opportunities.sort_values(
            "potential_impact", ascending=False
        )
    else:
        improvement_opportunities["potential_impact"] = 0.80 - improvement_opportunities["SKOR"]
        improvement_opportunities = improvement_opportunities.sort_values(
            "SKOR", ascending=True
        )
    
    st.markdown("#### ğŸ”¥ En YÃ¼ksek Impact Ä°stasyonlar (Top 10)")
    
    top_impact = improvement_opportunities.head(10)
    
    for idx, (_, row) in enumerate(top_impact.iterrows(), 1):
        current_score = row["SKOR"] * 100
        target_score = 80
        potential_gain = target_score - current_score
        
        st.markdown(f"""
        **{idx}. {row['Ä°stasyon']}**
        - Mevcut: {current_score:.1f}% â†’ Hedef: {target_score}% (+{potential_gain:.1f} puan)
        - District: {row.get('DISTRICT', 'N/A')} | Segment: {row.get('Site Segment', 'N/A')}
        """)
    
    # Segment bazlÄ± fÄ±rsatlar
    st.markdown("#### ğŸª Segment BazlÄ± FÄ±rsatlar")
    
    segment_opps = improvement_opportunities.groupby("Site Segment").agg({
        "Ä°stasyon": "count",
        "SKOR": "mean",
        "potential_impact": "sum"
    }).reset_index()
    
    segment_opps = segment_opps.sort_values("potential_impact", ascending=False)
    
    for _, row in segment_opps.iterrows():
        avg_score = row["SKOR"] * 100
        st.markdown(f"""
        **{row['Site Segment']}**: {row['Ä°stasyon']} istasyon | Ort: {avg_score:.1f}%
        """)

def display_segment_analysis(df, segment_name):
    """Segment analizi"""
    st.markdown(f"### ğŸ¯ {segment_name} Segment Analizi")
    
    if df is None or df.empty:
        st.info("Veri bulunamadÄ±")
        return
    
    segment_data = df[df["Site Segment"] == segment_name] if "Site Segment" in df.columns else df
    
    if segment_data.empty:
        st.info(f"{segment_name} segmentinde istasyon bulunamadÄ±")
        return
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Toplam Ä°stasyon", len(segment_data))
    
    with col2:
        if "SKOR" in segment_data.columns:
            avg_score = segment_data["SKOR"].mean() * 100
            st.metric("Ortalama Skor", f"{avg_score:.1f}%")
    
    with col3:
        if "DISTRICT" in segment_data.columns:
            district_count = segment_data["DISTRICT"].nunique()
            st.metric("District SayÄ±sÄ±", district_count)
    
    # En iyi ve en kÃ¶tÃ¼ istasyonlar
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### ğŸ† En Ä°yi 5 Ä°stasyon")
        if "SKOR" in segment_data.columns:
            top5 = segment_data.nlargest(5, "SKOR")[["Ä°stasyon", "SKOR", "DISTRICT"]].copy()
            top5["SKOR"] = top5["SKOR"].apply(lambda x: f"{x*100:.1f}%")
            st.dataframe(top5, use_container_width=True)
    
    with col2:
        st.markdown("#### âš ï¸ En KÃ¶tÃ¼ 5 Ä°stasyon")
        if "SKOR" in segment_data.columns:
            bottom5 = segment_data.nsmallest(5, "SKOR")[["Ä°stasyon", "SKOR", "DISTRICT"]].copy()
            bottom5["SKOR"] = bottom5["SKOR"].apply(lambda x: f"{x*100:.1f}%")
            st.dataframe(bottom5, use_container_width=True)

# ------------------------------------------------------------
# Supabase veri kaydetme
# ------------------------------------------------------------
def save_data_to_supabase(df, comments_df=None, period_meta=None):
    """Veriyi Supabase'e kalÄ±cÄ± olarak kaydeder"""
    if not SUPABASE_ENABLED:
        st.info("Supabase baÄŸlantÄ±sÄ± yok - veri geÃ§ici olarak hafÄ±zada tutulacak")
        return
    
    try:
        client = get_supabase_client()
        
        # Period kaydÄ±
        if period_meta:
            period_id = save_period(client, period_meta)
        else:
            period_id = None
        
        # TLAG verileri kaydet
        if df is not None and not df.empty:
            save_tlag_data(client, df, period_id)
            st.success("âœ… TLAG verileri kaydedildi")
        
        # Yorum verileri kaydet
        if comments_df is not None and not comments_df.empty:
            save_comment_data(client, comments_df, period_id)
            st.success("âœ… Yorum verileri kaydedildi")
            
    except Exception as e:
        st.error(f"Veri kaydetme hatasÄ±: {str(e)}")

# ------------------------------------------------------------
# CSS ve sayfa yapÄ±landÄ±rmasÄ±
# ------------------------------------------------------------
st.set_page_config(
    page_title="TLAG Performance Analytics",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    .main-header { 
        font-size: clamp(2rem, 5vw, 3rem); 
        font-weight: bold; 
        text-align: center;
        background: linear-gradient(90deg, #FF6B6B, #4ECDC4); 
        -webkit-background-clip: text; 
        -webkit-text-fill-color: transparent; 
        margin-bottom: 2rem; 
    }
    
    .metric-card { 
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
        padding: 1.5rem; 
        border-radius: 15px; 
        color: white; 
        text-align: center; 
        margin: 0.5rem 0;
        box-shadow: 0 8px 32px rgba(0,0,0,0.1); 
        cursor: pointer; 
        transition: transform 0.3s; 
    }
    
    .metric-card:hover { 
        transform: translateY(-5px); 
    }
    
    .nav-section {
        background: linear-gradient(135deg, #4ECDC4 0%, #44A08D 100%);
        padding: 1rem;
        border-radius: 15px;
        margin: 1rem 0;
        text-align: center;
    }
    
    .nav-button { 
        background: linear-gradient(135deg, #4ECDC4 0%, #44A08D 100%); 
        color: white; 
        padding: 1rem 2rem; 
        border: none; 
        border-radius: 10px;
        font-size: 1.1rem; 
        font-weight: bold; 
        margin: 0.5rem; 
        cursor: pointer; 
        transition: all 0.3s; 
        width: 100%;
    }
    
    .nav-button:hover { 
        transform: translateY(-2px); 
        box-shadow: 0 4px 15px rgba(0,0,0,0.2); 
    }
    
    .opportunity-card {
        background: linear-gradient(135deg, #FFA502 0%, #FF6B6B 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        margin: 0.5rem 0;
    }
    
    .category-badge { 
        display: inline-block; 
        padding: 0.25rem 0.75rem; 
        border-radius: 15px; 
        margin: 0.25rem; 
        font-size: 0.85rem; 
        font-weight: bold; 
    }
    
    .category-personel { background: #FF6B6B; color: white; }
    .category-pompaci { background: #3742FA; color: white; }
    .category-temizlik { background: #4ECDC4; color: white; }
    .category-market { background: #95E1D3; color: white; }
    .category-hiz { background: #FFA502; color: white; }
    .category-yakit { background: #2F3542; color: white; }
    .category-banka-kampanya { background: #1e90ff; color: white; }
    .category-genel { background: #747D8C; color: white; }
</style>
""", unsafe_allow_html=True)

# ------------------------------------------------------------
# Session State
# ------------------------------------------------------------
if "tlag_data" not in st.session_state:
    st.session_state.tlag_data = None
if "comments_data" not in st.session_state:
    st.session_state.comments_data = None
if "analyzed_comments" not in st.session_state:
    st.session_state.analyzed_comments = None
if "current_view" not in st.session_state:
    st.session_state.current_view = "main"

# ------------------------------------------------------------
# ANA UYGULAMA
# ------------------------------------------------------------
def main():
    st.markdown('<h1 class="main-header">ğŸ“Š TLAG PERFORMANS ANALÄ°TÄ°K</h1>', unsafe_allow_html=True)
    
    # SIDEBAR - Veri YÃ¼kleme
    st.sidebar.markdown("## ğŸ“ VERÄ° YÃ–NETÄ°MÄ°")
    
    # TLAG dosyasÄ± yÃ¼kleme
    uploaded_tlag = st.sidebar.file_uploader(
        "TLAG Excel dosyasÄ±:", 
        type=["xlsx", "xls"], 
        help="Ä°stasyon performans verilerini iÃ§eren Excel dosyasÄ±"
    )
    
    # Yorum dosyasÄ± yÃ¼kleme
    uploaded_comments = st.sidebar.file_uploader(
        "MÃ¼ÅŸteri YorumlarÄ± Excel dosyasÄ±:", 
        type=["xlsx", "xls"], 
        key="comments_uploader",
        help="MÃ¼ÅŸteri yorum anket sonuÃ§larÄ±nÄ± iÃ§eren Excel dosyasÄ±"
    )
    
    # Demo data yÃ¼kleme
    st.sidebar.markdown("## ğŸš€ DEMO VERÄ°LERÄ°")
    col1, col2 = st.sidebar.columns(2)
    
    with col1:
        if st.button("â˜ï¸ Cloud Demo", use_container_width=True):
            with st.spinner("Veriler yÃ¼kleniyor..."):
                tlag_df, comments_df, message = load_demo_data_from_cloud()
                if tlag_df is not None:
                    st.session_state.tlag_data = tlag_df
                    st.sidebar.success("âœ… TLAG demo verisi yÃ¼klendi")
                    
                    if comments_df is not None:
                        # Yorum verilerini TLAG ile birleÅŸtir
                        merged_comments = merge_comments_with_tlag(comments_df, tlag_df)
                        st.session_state.comments_data = merged_comments
                        
                        # Yorum analizini yap
                        district_analysis = analyze_comments_by_scope(merged_comments, "DISTRICT")
                        nor_analysis = analyze_comments_by_scope(merged_comments, "NOR")
                        
                        st.session_state.analyzed_comments = {
                            "district": district_analysis,
                            "nor": nor_analysis
                        }
                        st.sidebar.success("âœ… Yorum demo verisi yÃ¼klendi")
                else:
                    st.sidebar.error(message)
    
    # Dosya yÃ¼kleme iÅŸlemi
    if uploaded_tlag is not None:
        with st.spinner("TLAG verileri iÅŸleniyor..."):
            df = load_tlag_data(uploaded_tlag)
            if df is not None:
                st.session_state.tlag_data = df
                st.sidebar.success(f"âœ… {len(df)} istasyon verisi yÃ¼klendi")
                
                # Supabase'e kaydet
                save_data_to_supabase(df)
    
    if uploaded_comments is not None and st.session_state.tlag_data is not None:
        with st.spinner("Yorum verileri iÅŸleniyor..."):
            comments_df = load_comments_data(uploaded_comments)
            if comments_df is not None:
                # TLAG verisi ile birleÅŸtir
                merged_comments = merge_comments_with_tlag(comments_df, st.session_state.tlag_data)
                st.session_state.comments_data = merged_comments
                
                # Analiz yap
                district_analysis = analyze_comments_by_scope(merged_comments, "DISTRICT")
                nor_analysis = analyze_comments_by_scope(merged_comments, "NOR")
                
                st.session_state.analyzed_comments = {
                    "district": district_analysis,
                    "nor": nor_analysis
                }
                
                st.sidebar.success(f"âœ… {len(comments_df)} yorum yÃ¼klendi ve analiz edildi")
                
                # Supabase'e kaydet
                save_data_to_supabase(None, merged_comments)
    
    # MAIN CONTENT
    if st.session_state.current_view == "main":
        display_main_dashboard()
    elif st.session_state.current_view == "district":
        display_district_analysis()
    elif st.session_state.current_view == "nor":
        display_nor_analysis() 
    elif st.session_state.current_view == "segmentation":
        display_segmentation_analysis()

def merge_comments_with_tlag(comments_df, tlag_df):
    """Yorum verilerini TLAG verisi ile birleÅŸtirir"""
    try:
        # ROC kodlarÄ± Ã¼zerinden birleÅŸtir
        merged = pd.merge(
            comments_df,
            tlag_df[["ROC_NORMALIZED", "Ä°stasyon", "NOR", "DISTRICT", "Site Segment"]],
            left_on="station_code",
            right_on="ROC_NORMALIZED", 
            how="left"
        )
        
        # BoÅŸ alanlarÄ± doldur
        merged["NOR_FINAL"] = merged["NOR"].fillna(merged["territory"])
        merged["DISTRICT_FINAL"] = merged["DISTRICT"].fillna(merged["district"])
        
        return merged
    except Exception as e:
        st.error(f"Veri birleÅŸtirme hatasÄ±: {str(e)}")
        return comments_df

def display_main_dashboard():
    """Ana dashboard gÃ¶rÃ¼nÃ¼mÃ¼"""
    
    if st.session_state.tlag_data is None:
        st.markdown("## ğŸ¯ TLAG PERFORMANS ANALÄ°TÄ°K'E HOÅGELDÄ°NÄ°Z")
        st.info("ğŸ‘ˆ Sol panelden Excel dosyalarÄ±nÄ±zÄ± yÃ¼kleyin veya demo verilerini deneyin")
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("""
            ### ğŸ“Š YENÄ° Ã–ZELLÄ°KLER
            - âœ… KalÄ±cÄ± veri saklama
            - âœ… TÄ±klanabilir metrikler
            - âœ… DetaylÄ± istasyon analizi
            - âœ… GeliÅŸmiÅŸ yorum kategorileme
            - âœ… FÄ±rsat istasyonu tespiti
            """)
        
        with col2:
            st.markdown("""
            ### ğŸ¯ ANALIZ ALANLARI
            - ğŸ¢ District bazlÄ± performans
            - ğŸ“ NOR bazlÄ± analiz
            - ğŸª Site segmentasyon
            - ğŸ’¬ MÃ¼ÅŸteri yorum analizi
            - ğŸ¤– AI destekli Ã¶neriler
            """)
        return
    
    df = st.session_state.tlag_data
    
    # Ana metrikler
    st.markdown("## ğŸ“Š ANA METRÄ°KLER")
    col1, col2, col3, col4 = st.columns(4)
    
    # Toplam istasyon sayÄ±sÄ±
    create_enhanced_metric_card(
        col1, "Toplam Ä°stasyon", len(df), "total_stations", df
    )
    
    # Ortalama skor
    if "SKOR" in df.columns:
        avg_score = df["SKOR"].mean() * 100
        create_enhanced_metric_card(
            col2, "Ortalama Skor", f"{avg_score:.1f}%", "avg_score", df
        )
    
    # Segment daÄŸÄ±lÄ±mÄ±
    if "Site Segment" in df.columns:
        segments = df["Site Segment"].value_counts()
        for idx, (segment, count) in enumerate(segments.head(2).items()):
            if idx == 0:
                create_enhanced_metric_card(
                    col3, segment, count, f"segment_{segment.replace(' ', '_')}", 
                    df[df["Site Segment"] == segment]
                )
            elif idx == 1:
                create_enhanced_metric_card(
                    col4, segment, count, f"segment_{segment.replace(' ', '_')}", 
                    df[df["Site Segment"] == segment]
                )
    
    # Performans daÄŸÄ±lÄ±mÄ± - District tablosu
    if "DISTRICT" in df.columns and "SKOR" in df.columns:
        st.markdown("## ğŸ“ˆ DISTRICT PERFORMANS TABLOSU")
        
        district_performance = df.groupby("DISTRICT").agg({
            "SKOR": "mean",
            "Ä°stasyon": "count"
        }).reset_index()
        
        district_performance["SKOR_FORMATTED"] = district_performance["SKOR"].apply(
            lambda x: f"{x*100:.1f}%"
        )
        
        district_performance = district_performance.sort_values("SKOR", ascending=False)
        district_performance = district_performance.rename(columns={
            "DISTRICT": "District",
            "Ä°stasyon": "Ä°stasyon SayÄ±sÄ±", 
            "SKOR_FORMATTED": "Ortalama Skor"
        })
        
        # District tablosu ile grafik
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.dataframe(
                district_performance[["District", "Ä°stasyon SayÄ±sÄ±", "Ortalama Skor"]], 
                use_container_width=True,
                height=400
            )
        
        with col2:
            fig_district = px.bar(
                district_performance,
                x="District", 
                y="SKOR",
                title="District BazÄ±nda Ortalama Performans",
                labels={"SKOR": "Ortalama Skor", "District": "District"}
            )
            fig_district.update_layout(xaxis_tickangle=-45)
            st.plotly_chart(fig_district, use_container_width=True)
    
    # FÄ±rsat istasyonlarÄ±
    opportunity_stations = get_opportunity_stations(df)
    if not opportunity_stations.empty:
        st.markdown("## ğŸ¯ FIRSAT Ä°STASYONLARI")
        st.markdown("*My Precious veya Primitive segment, 80% altÄ± skor*")
        
        st.markdown(f"**Toplam {len(opportunity_stations)} fÄ±rsat istasyonu tespit edildi**")
        
        # En yÃ¼ksek potansiyelli ilk 10
        if "TRANSACTION" in opportunity_stations.columns:
            opportunity_stations["potential"] = (
                (0.80 - opportunity_stations["SKOR"]) * 
                opportunity_stations["TRANSACTION"] / 1000
            )
            top_opportunities = opportunity_stations.nlargest(10, "potential")
        else:
            top_opportunities = opportunity_stations.nsmallest(10, "SKOR")
        
        for idx, (_, station) in enumerate(top_opportunities.iterrows(), 1):
            current_score = station["SKOR"] * 100
            potential_gain = 80 - current_score
            
            st.markdown(f"""
            <div class="opportunity-card">
                <strong>{idx}. {station['Ä°stasyon']}</strong><br>
                Mevcut: {current_score:.1f}% â†’ Hedef: 80% (+{potential_gain:.1f} puan)<br>
                <small>{station['DISTRICT']} | {station['Site Segment']}</small>
            </div>
            """, unsafe_allow_html=True)
    
    # Navigasyon
    st.markdown("## ğŸ¯ HANGÄ° ANALÄ°ZÄ° YAPMAK Ä°STÄ°YORSUNUZ?")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div class="nav-section">
            <h3>ğŸ¢ DISTRICT</h3>
            <p>BÃ¶lgesel performans analizi</p>
        </div>
        """, unsafe_allow_html=True)
        
        if st.button("District Analizine Git", key="nav_district", use_container_width=True, type="primary"):
            st.session_state.current_view = "district"
            st.rerun()
    
    with col2:
        st.markdown("""
        <div class="nav-section">
            <h3>ğŸ“ NOR</h3>
            <p>Operasyon bÃ¶lgesi analizi</p>
        </div>
        """, unsafe_allow_html=True)
        
        if st.button("NOR Analizine Git", key="nav_nor", use_container_width=True, type="primary"):
            st.session_state.current_view = "nor"
            st.rerun()
    
    with col3:
        st.markdown("""
        <div class="nav-section">
            <h3>ğŸª SÄ°TE SEGMENTASYON</h3>
            <p>Segment bazlÄ± performans</p>
        </div>
        """, unsafe_allow_html=True)
        
        if st.button("Segmentasyon Analizine Git", key="nav_segmentation", use_container_width=True, type="primary"):
            st.session_state.current_view = "segmentation"
            st.rerun()

def display_district_analysis():
    """District analiz sayfasÄ±"""
    if st.button("ğŸ  Ana Sayfaya DÃ¶n", key="back_from_district"):
        st.session_state.current_view = "main"
        st.rerun()
    
    st.markdown("## ğŸ¢ DISTRICT BAZLI ANALÄ°Z")
    
    df = st.session_state.tlag_data
    if df is None or "DISTRICT" not in df.columns:
        st.error("District verisi bulunamadÄ±")
        return
    
    districts = sorted(df["DISTRICT"].dropna().unique())
    selected_district = st.selectbox("District SeÃ§in:", districts, key="district_selector")
    
    if selected_district:
        display_detailed_district_analysis(selected_district, df)

def display_detailed_district_analysis(district_name, df):
    """DetaylÄ± district analizi"""
    district_data = df[df["DISTRICT"] == district_name].copy()
    
    # Temel metrikler
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Ä°stasyon SayÄ±sÄ±", len(district_data))
    
    with col2:
        if "SKOR" in district_data.columns:
            avg_score = district_data["SKOR"].mean() * 100
            st.metric("Ortalama Skor", f"{avg_score:.1f}%")
    
    with col3:
        if "Site Segment" in district_data.columns:
            dominant_segment = district_data["Site Segment"].mode().iloc[0]
            st.metric("BaskÄ±n Segment", dominant_segment)
    
    with col4:
        opportunity_count = len(get_opportunity_stations(district_data))
        st.metric("FÄ±rsat Ä°stasyonu", opportunity_count)
    
    # Segment daÄŸÄ±lÄ±mÄ±
    if "Site Segment" in district_data.columns:
        st.markdown("### ğŸª Segment DaÄŸÄ±lÄ±mÄ±")
        segment_counts = district_data["Site Segment"].value_counts()
        
        col1, col2 = st.columns(2)
        with col1:
            st.dataframe(segment_counts.reset_index(), use_container_width=True)
        with col2:
            fig_segments = px.pie(
                values=segment_counts.values, 
                names=segment_counts.index,
                title=f"{district_name} Segment DaÄŸÄ±lÄ±mÄ±"
            )
            st.plotly_chart(fig_segments, use_container_width=True)
    
    # En Ã§ok odaklanÄ±lmasÄ± gereken 3 konu
    comments_analysis = st.session_state.get("analyzed_comments", {}).get("district", {})
    if district_name in comments_analysis:
        district_comment_data = comments_analysis[district_name]
        
        st.markdown("### ğŸ¯ En Ã‡ok OdaklanÄ±lmasÄ± Gereken 3 Konu")
        
        problem_categories = district_comment_data.get("problem_categories", [])
        if problem_categories:
            for idx, (category, data) in enumerate(problem_categories, 1):
                severity = "ğŸ”´ Kritik" if data["avg_score"] < 3.0 else "ğŸŸ¡ Orta" if data["avg_score"] < 4.0 else "ğŸŸ¢ DÃ¼ÅŸÃ¼k"
                st.markdown(f"""
                **{idx}. {category}**
                - Ortalama Puan: {data['avg_score']:.1f}
                - Yorum SayÄ±sÄ±: {data['count']}
                - Ã–nem Seviyesi: {severity}
                """)
        else:
            st.info("Yorum verisi bulunamadÄ±")
    
    # En iyi ve en kÃ¶tÃ¼ istasyonlar
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### ğŸ† En Ä°yi Ä°stasyonlar")
        if "SKOR" in district_data.columns:
            top_stations = district_data.nlargest(5, "SKOR")[["Ä°stasyon", "SKOR", "Site Segment"]].copy()
            top_stations["SKOR"] = top_stations["SKOR"].apply(lambda x: f"{x*100:.1f}%")
            st.dataframe(top_stations, use_container_width=True)
    
    with col2:
        st.markdown("### âš ï¸ En KÃ¶tÃ¼ Ä°stasyonlar") 
        if "SKOR" in district_data.columns:
            bottom_stations = district_data.nsmallest(5, "SKOR")[["Ä°stasyon", "SKOR", "Site Segment"]].copy()
            bottom_stations["SKOR"] = bottom_stations["SKOR"].apply(lambda x: f"{x*100:.1f}%")
            st.dataframe(bottom_stations, use_container_width=True)
    
    # FÄ±rsat istasyonlarÄ±
    opportunity_stations = get_opportunity_stations(district_data)
    if not opportunity_stations.empty:
        st.markdown("### ğŸ¯ FÄ±rsat Ä°stasyonlarÄ±")
        st.markdown("*My Precious veya Primitive segment, 80% altÄ± skor*")
        
        opp_display = opportunity_stations[["Ä°stasyon", "SKOR", "Site Segment"]].copy()
        opp_display["SKOR"] = opp_display["SKOR"].apply(lambda x: f"{x*100:.1f}%")
        opp_display["Potansiyel KazanÄ±m"] = opportunity_stations["SKOR"].apply(
            lambda x: f"+{(0.80-x)*100:.1f}%" if x < 0.80 else "0%"
        )
        
        st.dataframe(opp_display, use_container_width=True)
    
    # AI Ã–nerileri - Dropdown
    with st.expander("ğŸ¤– AI Destekli Ä°yileÅŸtirme Ã–nerileri"):
        if st.button(f"ğŸ¤– {district_name} iÃ§in AI Analizi OluÅŸtur", key=f"ai_district_{district_name}"):
            with st.spinner("AI analizi yapÄ±lÄ±yor..."):
                # Burada AI analizi yapÄ±labilir
                st.markdown(f"""
                ### ğŸ“Š {district_name} AI Analizi
                
                **Temel Bulgular:**
                - Toplam {len(district_data)} istasyon
                - Ortalama skor: {district_data["SKOR"].mean()*100:.1f}%
                - FÄ±rsat istasyonu: {len(opportunity_stations)} adet
                
                **Ã–ncelikli Aksiyonlar:**
                1. En dÃ¼ÅŸÃ¼k skorlu istasyonlara odaklan
                2. FÄ±rsat istasyonlarÄ±nÄ± deÄŸerlendir
                3. BaÅŸarÄ±lÄ± istasyonlarÄ±n best practice'lerini kopyala
                
                **Beklenen Ä°yileÅŸtirme:** +{(len(opportunity_stations) * 5):.0f} puan
                """)

def display_nor_analysis():
    """NOR analiz sayfasÄ±"""
    if st.button("ğŸ  Ana Sayfaya DÃ¶n", key="back_from_nor"):
        st.session_state.current_view = "main"
        st.rerun()
    
    st.markdown("## ğŸ“ NOR BAZLI ANALÄ°Z")
    
    df = st.session_state.tlag_data
    if df is None or "NOR" not in df.columns:
        st.error("NOR verisi bulunamadÄ±")
        return
    
    nors = sorted(df["NOR"].dropna().unique())
    selected_nor = st.selectbox("NOR SeÃ§in:", nors, key="nor_selector")
    
    if selected_nor:
        display_detailed_nor_analysis(selected_nor, df)

def display_detailed_nor_analysis(nor_name, df):
    """DetaylÄ± NOR analizi"""
    nor_data = df[df["NOR"] == nor_name].copy()
    
    # Temel metrikler
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Ä°stasyon SayÄ±sÄ±", len(nor_data))
    
    with col2:
        if "SKOR" in nor_data.columns:
            avg_score = nor_data["SKOR"].mean() * 100
            st.metric("Ortalama Skor", f"{avg_score:.1f}%")
    
    with col3:
        if "DISTRICT" in nor_data.columns:
            district_count = nor_data["DISTRICT"].nunique()
            st.metric("District SayÄ±sÄ±", district_count)
    
    with col4:
        opportunity_count = len(get_opportunity_stations(nor_data))
        st.metric("FÄ±rsat Ä°stasyonu", opportunity_count)
    
    # District daÄŸÄ±lÄ±mÄ±
    if "DISTRICT" in nor_data.columns:
        st.markdown("### ğŸ¢ District DaÄŸÄ±lÄ±mÄ±")
        district_performance = nor_data.groupby("DISTRICT").agg({
            "SKOR": "mean",
            "Ä°stasyon": "count"
        }).reset_index()
        
        district_performance["SKOR_FORMATTED"] = district_performance["SKOR"].apply(
            lambda x: f"{x*100:.1f}%"
        )
        
        st.dataframe(district_performance[["DISTRICT", "Ä°stasyon", "SKOR_FORMATTED"]], use_container_width=True)
    
    # Performans daÄŸÄ±lÄ±m grafiÄŸi
    if "SKOR" in nor_data.columns:
        st.markdown("### ğŸ“Š Performans DaÄŸÄ±lÄ±mÄ±")
        
        nor_viz = nor_data.copy()
        nor_viz["Skor_YÃ¼zde"] = nor_viz["SKOR"] * 100
        
        fig_dist = px.histogram(
            nor_viz,
            x="Skor_YÃ¼zde",
            nbins=15,
            title=f"{nor_name} - Performans DaÄŸÄ±lÄ±mÄ±",
            labels={"Skor_YÃ¼zde": "Skor (%)", "count": "Ä°stasyon SayÄ±sÄ±"}
        )
        fig_dist.add_vline(x=80, line_dash="dash", line_color="orange", annotation_text="Hedef: 80%")
        
        st.plotly_chart(fig_dist, use_container_width=True)
    
    # FÄ±rsat istasyonlarÄ± detayÄ±
    opportunity_stations = get_opportunity_stations(nor_data)
    if not opportunity_stations.empty:
        st.markdown("### ğŸ¯ FÄ±rsat Ä°stasyonlarÄ± DetayÄ±")
        
        opp_detail = opportunity_stations[["Ä°stasyon", "SKOR", "DISTRICT", "Site Segment"]].copy()
        opp_detail["SKOR"] = opp_detail["SKOR"].apply(lambda x: f"{x*100:.1f}%")
        opp_detail["Potansiyel"] = opportunity_stations["SKOR"].apply(
            lambda x: f"+{(0.80-x)*100:.1f}%" 
        )
        
        st.dataframe(opp_detail, use_container_width=True)

def display_segmentation_analysis():
    """Segmentasyon analiz sayfasÄ±"""
    if st.button("ğŸ  Ana Sayfaya DÃ¶n", key="back_from_segmentation"):
        st.session_state.current_view = "main"
        st.rerun()
    
    st.markdown("## ğŸª SÄ°TE SEGMENTASYON ANALÄ°ZÄ°")
    
    df = st.session_state.tlag_data
    if df is None or "Site Segment" not in df.columns:
        st.error("Site Segment verisi bulunamadÄ±")
        return
    
    # Segment genel bakÄ±ÅŸ
    st.markdown("### ğŸ“Š Segment Genel BakÄ±ÅŸ")
    
    segment_summary = df.groupby("Site Segment").agg({
        "Ä°stasyon": "count",
        "SKOR": ["mean", "min", "max"]
    }).round(3)
    
    segment_summary.columns = ["Ä°stasyon SayÄ±sÄ±", "Ort. Skor", "Min Skor", "Max Skor"]
    segment_summary["Ort. Skor %"] = (segment_summary["Ort. Skor"] * 100).round(1).astype(str) + "%"
    segment_summary["Min Skor %"] = (segment_summary["Min Skor"] * 100).round(1).astype(str) + "%"
    segment_summary["Max Skor %"] = (segment_summary["Max Skor"] * 100).round(1).astype(str) + "%"
    
    st.dataframe(segment_summary, use_container_width=True)
    
    # Segment seÃ§imi
    segments = sorted(df["Site Segment"].dropna().unique())
    selected_segment = st.selectbox("Segment SeÃ§in:", segments, key="segment_selector")
    
    if selected_segment:
        display_detailed_segment_analysis(selected_segment, df)

def display_detailed_segment_analysis(segment_name, df):
    """DetaylÄ± segment analizi"""
    segment_data = df[df["Site Segment"] == segment_name].copy()
    
    st.markdown(f"### ğŸ¯ {segment_name} DetaylÄ± Analizi")
    
    # Segment metrikleri
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Toplam Ä°stasyon", len(segment_data))
    
    with col2:
        if "SKOR" in segment_data.columns:
            avg_score = segment_data["SKOR"].mean() * 100
            st.metric("Ortalama Skor", f"{avg_score:.1f}%")
    
    with col3:
        if "DISTRICT" in segment_data.columns:
            district_count = segment_data["DISTRICT"].nunique()
            st.metric("District SayÄ±sÄ±", district_count)
    
    with col4:
        if "SKOR" in segment_data.columns:
            below_target = len(segment_data[segment_data["SKOR"] < 0.80])
            st.metric("80% AltÄ± Ä°stasyon", below_target)
    
    # District bazlÄ± daÄŸÄ±lÄ±m
    if "DISTRICT" in segment_data.columns:
        st.markdown("#### ğŸ¢ District BazlÄ± DaÄŸÄ±lÄ±m")
        
        district_breakdown = segment_data.groupby("DISTRICT").agg({
            "Ä°stasyon": "count",
            "SKOR": "mean"
        }).reset_index()
        
        district_breakdown["SKOR"] = district_breakdown["SKOR"].apply(lambda x: f"{x*100:.1f}%")
        district_breakdown = district_breakdown.sort_values("Ä°stasyon", ascending=False)
        
        st.dataframe(district_breakdown, use_container_width=True)
    
    # Performans grafiÄŸi
    if "SKOR" in segment_data.columns:
        st.markdown("#### ğŸ“ˆ Performans Analizi")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Box plot
            segment_viz = segment_data.copy()
            segment_viz["Skor_YÃ¼zde"] = segment_viz["SKOR"] * 100
            
            fig_box = px.box(
                segment_viz,
                x="DISTRICT",
                y="Skor_YÃ¼zde",
                title=f"{segment_name} - District BazlÄ± Performans",
                labels={"Skor_YÃ¼zde": "Skor (%)"}
            )
            fig_box.update_layout(xaxis_tickangle=-45)
            st.plotly_chart(fig_box, use_container_width=True)
        
        with col2:
            # Histogram
            fig_hist = px.histogram(
                segment_viz,
                x="Skor_YÃ¼zde",
                nbins=15,
                title=f"{segment_name} - Skor DaÄŸÄ±lÄ±mÄ±",
                labels={"Skor_YÃ¼zde": "Skor (%)", "count": "Ä°stasyon SayÄ±sÄ±"}
            )
            fig_hist.add_vline(x=80, line_dash="dash", line_color="red", annotation_text="Hedef: 80%")
            st.plotly_chart(fig_hist, use_container_width=True)
    
    # En iyi ve en kÃ¶tÃ¼ performans
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### ğŸ† En Ä°yi Performans")
        if "SKOR" in segment_data.columns:
            top_performers = segment_data.nlargest(10, "SKOR")[["Ä°stasyon", "SKOR", "DISTRICT"]].copy()
            top_performers["SKOR"] = top_performers["SKOR"].apply(lambda x: f"{x*100:.1f}%")
            st.dataframe(top_performers, use_container_width=True)
    
    with col2:
        st.markdown("#### âš ï¸ GeliÅŸim Gereken Ä°stasyonlar")
        if "SKOR" in segment_data.columns:
            low_performers = segment_data.nsmallest(10, "SKOR")[["Ä°stasyon", "SKOR", "DISTRICT"]].copy()
            low_performers["SKOR"] = low_performers["SKOR"].apply(lambda x: f"{x*100:.1f}%")
            st.dataframe(low_performers, use_container_width=True)

if __name__ == "__main__":
    main()
