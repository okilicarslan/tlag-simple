# app.py - Enhanced TLAG Performance Analytics with AI

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
import re
import json
from datetime import datetime, date, timedelta
import calendar
import os

# ------------------------------------------------------------
# KÃ¼Ã§Ã¼k yardÄ±mcÄ±lar
# ------------------------------------------------------------
def _to_int_safe(val):
    try:
        if val is None or (isinstance(val, float) and np.isnan(val)):
            return None
        if isinstance(val, str):
            v = val.strip()
            if v == "":
                return None
            if "." in v:
                v = v.split(".")[0]
            return int(v)
        if isinstance(val, float):
            return int(round(val))
        return int(val)
    except Exception:
        return None

def _to_float_safe(val):
    try:
        if val is None or (isinstance(val, float) and np.isnan(val)):
            return None
        return float(val)
    except Exception:
        return None

def normalize_roc(val):
    """ROC deÄŸerini gÃ¼venli biÃ§imde normalize eder."""
    if val is None or (isinstance(val, float) and np.isnan(val)):
        return None
    s = str(val).strip()
    if s.endswith(".0"):
        s = s[:-2]
    # Son 4 haneyi al (mÃ¼ÅŸteri yorumlarÄ± iÃ§in)
    m = re.search(r"#(\d{4})$", s)
    if m:
        return m.group(1)
    # Sadece rakam varsa al
    m = re.search(r"(\d+)", s)
    return m.group(1) if m else None

def extract_station_code(station_info):
    """Station info'dan son 4 haneli kodu Ã§Ä±karÄ±r"""
    if pd.isna(station_info):
        return None
    s = str(station_info)
    # #5789 formatÄ±
    m = re.search(r"#(\d{4})$", s)
    if m:
        return m.group(1)
    # Son 4 rakamÄ± al
    m = re.search(r"(\d{4})(?=\D*$)", s)
    return m.group(1) if m else None

# ------------------------------------------------------------
# Supabase entegrasyonu - GEÃ‡Ä°CÄ° OLARAK KAPALI
# ------------------------------------------------------------
SUPABASE_ENABLED = False  # GeÃ§ici olarak kapalÄ±

# ------------------------------------------------------------
# OpenAI AI Analiz FonksiyonlarÄ±
# ------------------------------------------------------------
def get_openai_api_key():
    """OpenAI API anahtarÄ±nÄ± al"""
    try:
        # Ã–nce environment variable'dan dene
        api_key = os.getenv("OPENAI_API_KEY")
        if api_key:
            return api_key
        
        # Sonra Streamlit secrets'tan dene
        if hasattr(st, 'secrets') and 'openai' in st.secrets:
            return st.secrets.openai.api_key
        
        return None
    except:
        return None

def ai_recommendations_for_scope(scope_name, df_scope, comments_scope=None):
    """Belirli bir scope (District/NOR/Ä°stasyon) iÃ§in AI analizi"""
    try:
        try:
            import openai
        except ImportError:
            return "### ğŸ“¦ OpenAI ModÃ¼lÃ¼ Gerekli\n\nAI Ã¶nerileri iÃ§in `pip install openai` kurun."
        
        api_key = get_openai_api_key()
        if not api_key:
            return "### ğŸ”‘ OpenAI API AnahtarÄ± Gerekli\n\nSecrets'a OpenAI API anahtarÄ±nÄ±zÄ± ekleyin."
        
        # Data Ã¶zeti hazÄ±rla
        if df_scope is not None and not df_scope.empty:
            station_count = len(df_scope)
            avg_score = df_scope["SKOR"].mean() * 100 if "SKOR" in df_scope.columns else 0
            
            # En iyi ve en kÃ¶tÃ¼ istasyonlar
            if "SKOR" in df_scope.columns:
                best_stations = df_scope.nlargest(3, "SKOR")[["Ä°stasyon", "SKOR"]].to_dict('records')
                worst_stations = df_scope.nsmallest(3, "SKOR")[["Ä°stasyon", "SKOR"]].to_dict('records')
            else:
                best_stations = worst_stations = []
            
            # Segment daÄŸÄ±lÄ±mÄ±
            if "Site Segment" in df_scope.columns:
                segments = df_scope["Site Segment"].value_counts().to_dict()
            else:
                segments = {}
        else:
            station_count = avg_score = 0
            best_stations = worst_stations = []
            segments = {}
        
        # Yorum analizi Ã¶zeti
        comment_summary = ""
        if comments_scope is not None and not comments_scope.empty:
            total_comments = len(comments_scope)
            avg_comment_score = comments_scope["score"].mean() if "score" in comments_scope.columns else 0
            
            # Kategori analizi
            category_problems = {}
            if "categories" in comments_scope.columns:
                for _, row in comments_scope.iterrows():
                    if isinstance(row["categories"], list):
                        for cat in row["categories"]:
                            if cat not in category_problems:
                                category_problems[cat] = []
                            category_problems[cat].append(row.get("score", 5))
            
            # Problem kategorileri (dÃ¼ÅŸÃ¼k puan alan)
            problem_cats = {}
            for cat, scores in category_problems.items():
                avg_cat_score = np.mean(scores)
                if avg_cat_score < 4.0:
                    problem_cats[cat] = {
                        "avg_score": avg_cat_score,
                        "count": len(scores)
                    }
            
            # DÃ¼ÅŸÃ¼k puan yorumlarÄ± Ã¶rnekleri
            low_score_comments = comments_scope[comments_scope["score"] <= 3]["comment"].head(5).tolist()
            
            comment_summary = f"""
            YORUM ANALÄ°ZÄ°:
            - Toplam yorum: {total_comments}
            - Ortalama puan: {avg_comment_score:.1f}/5
            - Problem kategorileri: {problem_cats}
            - DÃ¼ÅŸÃ¼k puan yorum Ã¶rnekleri: {low_score_comments[:3]}
            """
        
        # AI prompt hazÄ±rla
        prompt = f"""Sen bir petrol istasyonu performans analisti olan uzman bir AI'sÄ±n. {scope_name} bÃ¶lgesi iÃ§in detaylÄ± analiz yapmanÄ± istiyorum.

VERÄ° Ã–ZETÄ°:
- Ä°stasyon sayÄ±sÄ±: {station_count}
- Ortalama performans skoru: {avg_score:.1f}%
- Segment daÄŸÄ±lÄ±mÄ±: {segments}
- En iyi 3 istasyon: {best_stations}
- En kÃ¶tÃ¼ 3 istasyon: {worst_stations}

{comment_summary}

GÃ–REV:
1. Bu verilere dayanarak {scope_name} bÃ¶lgesi iÃ§in kapsamlÄ± bir performans analizi yap
2. Ana sorun alanlarÄ±nÄ± tespit et
3. Her sorun alanÄ± iÃ§in spesifik, uygulanabilir Ã§Ã¶zÃ¼m Ã¶nerileri ver
4. Ã–ncelik sÄ±ralamasÄ± yap (yÃ¼ksek/orta/dÃ¼ÅŸÃ¼k)
5. Beklenen iyileÅŸtirme yÃ¼zdesini tahmin et

Ã‡IKTI FORMATI:
### ğŸ“Š {scope_name} Performans Analizi

**Ana Bulgular:**
- [Temel performans durumu]
- [Kritik sorun alanlarÄ±]
- [FÄ±rsat alanlarÄ±]

**Ã–ncelikli Aksiyon PlanÄ±:**

ğŸ”´ **YÃ¼ksek Ã–ncelik:**
1. [Spesifik aksiyon] - Beklenen iyileÅŸtirme: X%
2. [Spesifik aksiyon] - Beklenen iyileÅŸtirme: X%

ğŸŸ¡ **Orta Ã–ncelik:**
1. [Spesifik aksiyon]
2. [Spesifik aksiyon]

**DetaylÄ± Ã–neriler:**
- [Her kategori iÃ§in spesifik Ã¶neriler]

**Beklenen Toplam Ä°yileÅŸtirme:** +X puan

TÃ¼rkÃ§e yanÄ±t ver ve pratik, uygulanabilir Ã¶neriler sun."""

        # OpenAI API Ã§aÄŸrÄ±sÄ±
        try:
            client = openai.OpenAI(api_key=api_key)
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=1500
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            # Eski API syntax'Ä±nÄ± dene
            openai.api_key = api_key
            response = openai.ChatCompletion.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=1500
            )
            return response.choices[0].message.content.strip()
            
    except Exception as e:
        return f"### âŒ AI Analiz HatasÄ±\n\nHata: {str(e)}\n\nLÃ¼tfen OpenAI API anahtarÄ±nÄ±zÄ± kontrol edin."

# ------------------------------------------------------------
# Demo veri yÃ¼kleme
# ------------------------------------------------------------
def load_demo_data_from_cloud():
    """Cloud'dan gerÃ§ek veriler"""
    try:
        TLAG_DEMO_URL = "https://raw.githubusercontent.com/okilicarslan/tlag-cloud-data/refs/heads/main/tlag_demo.csv"
        COMMENTS_DEMO_URL = "https://raw.githubusercontent.com/okilicarslan/tlag-cloud-data/refs/heads/main/comments_demo.csv"

        import requests
        from io import StringIO

        r1 = requests.get(TLAG_DEMO_URL, timeout=30)
        r1.raise_for_status()
        tlag_df = pd.read_csv(StringIO(r1.text), low_memory=False)

        for col in ["SKOR", "GEÃ‡EN SENE SKOR", "Fark", "TRANSACTION"]:
            if col in tlag_df.columns:
                tlag_df[col] = pd.to_numeric(tlag_df[col], errors="coerce")

        if "ROC_STR" not in tlag_df.columns and "ROC" in tlag_df.columns:
            tlag_df["ROC_STR"] = tlag_df["ROC"].astype(str).str.split(".").str[0]

        r2 = requests.get(COMMENTS_DEMO_URL, timeout=60)
        r2.raise_for_status()
        comments_df = pd.read_csv(
            StringIO(r2.text),
            low_memory=False,
            dtype={"station_code": "string"}
        )

        if "categories" in comments_df.columns:
            def _to_list(x):
                if isinstance(x, str) and x.strip().startswith("["):
                    try:
                        return json.loads(x)
                    except Exception:
                        return ["GENEL"]
                return [x] if pd.notna(x) else ["GENEL"]
            comments_df["categories"] = comments_df["categories"].apply(_to_list)

        return tlag_df, comments_df, "Cloud verileri baÅŸarÄ±yla yÃ¼klendi!"
    except Exception as e:
        return None, None, f"Cloud veri yÃ¼kleme hatasÄ±: {str(e)}"

# ------------------------------------------------------------
# Yorum kategorileri
# ------------------------------------------------------------
def categorize_comment_enhanced(comment_text):
    """GeliÅŸmiÅŸ yorum kategorileme"""
    if pd.isna(comment_text):
        return ["GENEL"]
    
    comment_lower = str(comment_text).lower()
    categories = []
    
    category_keywords = {
        "PERSONEL": [
            "personel", "Ã§alÄ±ÅŸan", "gÃ¶revli", "mÃ¼dÃ¼r", "yardÄ±msever", 
            "gÃ¼leryÃ¼zlÃ¼", "kaba", "ilgisiz", "saygÄ±lÄ±", "nazik", "kibar"
        ],
        "POMPACI": [
            "pompacÄ±", "yakÄ±t dolu", "benzin dolu", "motorin dolu",
            "cam sil", "kontrol et", "yaÄŸ kontrol", "su kontrol"
        ],
        "TEMÄ°ZLÄ°K": [
            "temiz", "kirli", "hijyen", "tuvalet", "pis", "bakÄ±m", 
            "tertip", "dÃ¼zen", "leke", "koku"
        ],
        "MARKET": [
            "market", "Ã¼rÃ¼n", "fiyat", "pahalÄ±", "ucuz", "Ã§eÅŸit", 
            "kalite", "taze", "kafe", "restoran"
        ],
        "HIZ": [
            "hÄ±zlÄ±", "yavaÅŸ", "bekleme", "kuyruk", "sÃ¼re", "geÃ§", 
            "Ã§abuk", "acele", "bekle", "zaman"
        ],
        "YAKIT": [
            "benzin", "motorin", "lpg", "yakÄ±t", "pompa", "dolum", 
            "depo", "kalite", "verim"
        ],
        "BANKA_KAMPANYA": [
            "kampanya", "indirim", "kart", "bonus", "puan", "fÄ±rsat",
            "promosyon", "taksit", "Ã¶deme"
        ],
        "GENEL": [
            "genel", "gÃ¼zel", "kÃ¶tÃ¼", "memnun", "beÄŸen", "hoÅŸ",
            "berbat", "sÃ¼per", "harika", "mÃ¼kemmel"
        ]
    }
    
    for category, keywords in category_keywords.items():
        if any(keyword in comment_lower for keyword in keywords):
            categories.append(category)
    
    return categories if categories else ["GENEL"]

# ------------------------------------------------------------
# Veri yÃ¼kleme fonksiyonlarÄ±
# ------------------------------------------------------------
def load_tlag_data(uploaded_file):
    """TLAG Excel dosyasÄ±nÄ± yÃ¼kler"""
    try:
        df = pd.read_excel(uploaded_file, sheet_name="TLAG DOKUNMA (2)", engine="openpyxl")
        df.columns = df.columns.str.strip()
        df = df.dropna(subset=["ROC", "Ä°stasyon"], how="any")
        
        # Numeric columns
        numeric_columns = ["ROC", "SKOR", "GEÃ‡EN SENE SKOR", "Fark", "TRANSACTION"]
        for col in numeric_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors="coerce")
        
        # Text columns
        text_columns = ["Ä°stasyon", "NOR", "DISTRICT", "Site Segment"]
        for col in text_columns:
            if col in df.columns:
                df[col] = df[col].astype(str).str.strip()
                df[col] = df[col].replace("nan", np.nan)
        
        # ROC normalizasyonu
        df["ROC_STR"] = df["ROC"].astype(str).str.split(".").str[0]
        df["ROC_NORMALIZED"] = df["ROC_STR"].apply(normalize_roc)
        
        return df
    except Exception as e:
        st.error(f"TLAG dosya okuma hatasÄ±: {str(e)}")
        return None

def load_comments_data(uploaded_file):
    """MÃ¼ÅŸteri yorum dosyasÄ±nÄ± yÃ¼kler"""
    try:
        df = pd.read_excel(uploaded_file, header=1, engine="openpyxl")
        
        # Ä°lk satÄ±rlarÄ± temizle
        df = df[df.iloc[:, 0] != "65000 yorum sÄ±nÄ±rÄ±nÄ± aÅŸtÄ±nÄ±z."]
        df = df[df.iloc[:, 0] != "birim"]
        df = df.dropna(subset=[df.columns[0]], how="all")
        
        # Kolon adlandÄ±rmasÄ±
        column_names = {}
        if len(df.columns) >= 9:
            column_names = {
                df.columns[0]: "station_info",
                df.columns[1]: "survey_item", 
                df.columns[2]: "comment",
                df.columns[3]: "score",
                df.columns[4]: "visit_date",
                df.columns[5]: "hospitality_score",
                df.columns[6]: "dealer",
                df.columns[7]: "territory",
                df.columns[8]: "district"
            }
        
        df = df.rename(columns=column_names)
        
        # Station code Ã§Ä±karÄ±mÄ±
        df["station_code"] = df["station_info"].apply(extract_station_code)
        df["score"] = pd.to_numeric(df["score"], errors="coerce")
        
        # GeliÅŸmiÅŸ kategorizasyon
        df["categories"] = df["comment"].apply(categorize_comment_enhanced)
        
        # 4 puan ama olumlu yorum tespiti
        df["positive_but_4star"] = df.apply(
            lambda row: (
                row["score"] == 4 and 
                isinstance(row["comment"], str) and
                any(word in str(row["comment"]).lower() for word in 
                    ["gÃ¼zel", "iyi", "memnun", "beÄŸen", "sÃ¼per", "harika"])
            ), axis=1
        )
        
        return df
    except Exception as e:
        st.error(f"Yorum dosyasÄ± okuma hatasÄ±: {str(e)}")
        return None

# ------------------------------------------------------------
# Ä°yileÅŸtirilmiÅŸ yorum birleÅŸtirme
# ------------------------------------------------------------
def merge_comments_with_tlag(comments_df, tlag_df):
    """Yorum verilerini TLAG verisi ile geliÅŸmiÅŸ birleÅŸtirme"""
    try:
        st.write("ğŸ” Yorum verileri birleÅŸtiriliyor...")
        st.write(f"ğŸ“Š TLAG veri: {len(tlag_df)} istasyon")
        st.write(f"ğŸ’¬ Yorum veri: {len(comments_df)} yorum")
        
        # ROC kodlarÄ± Ã¼zerinden birleÅŸtir
        merged = pd.merge(
            comments_df,
            tlag_df[["ROC_NORMALIZED", "ROC_STR", "Ä°stasyon", "NOR", "DISTRICT", "Site Segment"]],
            left_on="station_code",
            right_on="ROC_NORMALIZED", 
            how="left"
        )
        
        # Alternatif birleÅŸtirme - ROC_STR ile
        not_merged = merged[merged["Ä°stasyon"].isna()]
        if not not_merged.empty:
            st.write(f"âš ï¸ {len(not_merged)} yorum ROC_NORMALIZED ile eÅŸleÅŸmedi, ROC_STR deneniyor...")
            
            merged2 = pd.merge(
                not_merged[["station_code", "comment", "score", "categories", "dealer", "territory", "district", "positive_but_4star"]],
                tlag_df[["ROC_STR", "Ä°stasyon", "NOR", "DISTRICT", "Site Segment"]],
                left_on="station_code",
                right_on="ROC_STR",
                how="left"
            )
            
            # EÅŸleÅŸenleri ana veri ile birleÅŸtir
            merged_part1 = merged[merged["Ä°stasyon"].notna()]
            merged_part2 = merged2[merged2["Ä°stasyon"].notna()]
            
            if not merged_part2.empty:
                # KolonlarÄ± hizala
                merged_part2["ROC_NORMALIZED"] = merged_part2["ROC_STR"]
                merged = pd.concat([merged_part1, merged_part2], ignore_index=True)
        
        # BoÅŸ alanlarÄ± doldur
        merged["NOR_FINAL"] = merged["NOR"].fillna(merged["territory"])
        merged["DISTRICT_FINAL"] = merged["DISTRICT"].fillna(merged["district"])
        
        # BaÅŸarÄ± raporu
        successful_matches = len(merged[merged["Ä°stasyon"].notna()])
        st.success(f"âœ… {successful_matches}/{len(comments_df)} yorum baÅŸarÄ±yla eÅŸleÅŸtirildi!")
        
        if successful_matches < len(comments_df):
            st.warning(f"âš ï¸ {len(comments_df) - successful_matches} yorum eÅŸleÅŸtirilemedi")
        
        # District bazlÄ± yorum daÄŸÄ±lÄ±mÄ±
        district_comment_counts = merged.groupby("DISTRICT_FINAL").size().reset_index(columns=["Yorum_SayÄ±sÄ±"])
        st.write("ğŸ“Š District bazlÄ± yorum daÄŸÄ±lÄ±mÄ±:")
        st.dataframe(district_comment_counts, use_container_width=True)
        
        return merged
    except Exception as e:
        st.error(f"Veri birleÅŸtirme hatasÄ±: {str(e)}")
        return comments_df

# ------------------------------------------------------------
# Ä°yileÅŸtirilmiÅŸ analiz fonksiyonlarÄ±
# ------------------------------------------------------------
def analyze_comments_by_scope(comments_df, scope_col="DISTRICT"):
    """KapsamlÄ± yorum analizi - iyileÅŸtirilmiÅŸ"""
    if comments_df is None or comments_df.empty:
        return {}
    
    # Scope column belirleme
    if scope_col == "DISTRICT":
        group_col = "DISTRICT_FINAL"
    elif scope_col == "NOR":
        group_col = "NOR_FINAL"
    else:
        group_col = scope_col
        
    if group_col not in comments_df.columns:
        st.warning(f"âš ï¸ {group_col} kolonu bulunamadÄ±")
        return {}
    
    results = {}
    
    # Null olmayan gruplarÄ± al
    valid_comments = comments_df[comments_df[group_col].notna() & (comments_df[group_col] != "nan")]
    
    for name, group in valid_comments.groupby(group_col):
        if pd.isna(name) or str(name).strip() == "" or str(name).strip().lower() == "nan":
            continue
            
        total_comments = len(group)
        
        if total_comments == 0:
            continue
            
        avg_score = group["score"].mean()
        
        # Puan daÄŸÄ±lÄ±mÄ±
        score_dist = group["score"].value_counts().to_dict()
        
        # Kategori analizi
        category_counts = {}
        category_scores = {}
        
        for _, row in group.iterrows():
            if isinstance(row["categories"], list):
                for cat in row["categories"]:
                    if cat not in category_counts:
                        category_counts[cat] = 0
                        category_scores[cat] = []
                    category_counts[cat] += 1
                    category_scores[cat].append(row["score"])
        
        # Kategori ortalama puanlarÄ±
        category_avg_scores = {
            cat: np.mean(scores) for cat, scores in category_scores.items() if len(scores) > 0
        }
        
        # En problemli kategoriler (dÃ¼ÅŸÃ¼k puan + yeterli sayÄ±da yorum)
        problem_categories = {}
        for cat in category_counts:
            if cat in category_avg_scores and category_avg_scores[cat] < 4.0 and category_counts[cat] >= 2:
                problem_categories[cat] = {
                    "count": category_counts[cat],
                    "avg_score": category_avg_scores[cat],
                    "problem_level": (5 - category_avg_scores[cat]) * category_counts[cat]
                }
        
        # Olumlu ama 4 puan verenler
        positive_4star = group[group.get("positive_but_4star", False) == True]
        
        results[name] = {
            "total_comments": total_comments,
            "avg_score": avg_score,
            "score_distribution": score_dist,
            "category_counts": category_counts,
            "category_avg_scores": category_avg_scores,
            "problem_categories": sorted(
                problem_categories.items(), 
                key=lambda x: x[1]["problem_level"], 
                reverse=True
            )[:3],
            "positive_4star_count": len(positive_4star),
            "critical_issues": len(group[group["score"] <= 2])
        }
    
    return results

# ------------------------------------------------------------
# Yorum gÃ¶rÃ¼ntÃ¼leme fonksiyonu
# ------------------------------------------------------------
def display_comment_analysis_enhanced(analysis_data, title="Yorum Analizi"):
    """GeliÅŸmiÅŸ yorum analizi gÃ¶rÃ¼ntÃ¼leme"""
    if not analysis_data:
        st.info(f"ğŸ“‹ {title} iÃ§in yorum verisi bulunamadÄ±")
        return
    
    st.markdown(f"### ğŸ’¬ {title}")
    
    # Ã–zet istatistikler
    total_areas = len(analysis_data)
    total_comments = sum(data["total_comments"] for data in analysis_data.values())
    avg_score_overall = np.mean([data["avg_score"] for data in analysis_data.values()])
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Toplam Alan", total_areas)
    with col2:
        st.metric("Toplam Yorum", total_comments)
    with col3:
        st.metric("Genel Ort. Puan", f"{avg_score_overall:.1f}/5")
    
    # DetaylÄ± analiz
    for name, data in analysis_data.items():
        with st.expander(f"ğŸ“ {name} - {data['total_comments']} yorum (Ort: {data['avg_score']:.1f}/5)"):
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**ğŸ“Š Puan DaÄŸÄ±lÄ±mÄ±:**")
                if data["score_distribution"]:
                    score_df = pd.DataFrame(
                        list(data["score_distribution"].items()), 
                        columns=["Puan", "SayÄ±"]
                    ).sort_values("Puan")
                    
                    fig = px.bar(
                        score_df, x="Puan", y="SayÄ±", 
                        color="Puan", color_continuous_scale="RdYlGn",
                        title=f"{name} Puan DaÄŸÄ±lÄ±mÄ±"
                    )
                    st.plotly_chart(fig, use_container_width=True, key=f"score_{name}")
            
            with col2:
                st.markdown("**âš ï¸ Problem Kategorileri:**")
                if data["problem_categories"]:
                    for i, (cat, cat_data) in enumerate(data["problem_categories"], 1):
                        severity = "ğŸ”´" if cat_data["avg_score"] < 3.0 else "ğŸŸ¡" if cat_data["avg_score"] < 3.5 else "ğŸŸ "
                        st.markdown(f"""
                        **{i}. {cat}** {severity}
                        - Ortalama: {cat_data['avg_score']:.1f}/5
                        - Yorum: {cat_data['count']} adet
                        """)
                else:
                    st.info("Problem kategorisi bulunamadÄ±")
            
            # Kategori bazlÄ± detaylar
            if data["category_counts"]:
                st.markdown("**ğŸ“‹ TÃ¼m Kategoriler:**")
                cat_summary = []
                for cat, count in data["category_counts"].items():
                    avg_score = data["category_avg_scores"].get(cat, 0)
                    status = "ğŸ”´ Problem" if avg_score < 3.5 else "ğŸŸ¡ Dikkat" if avg_score < 4.0 else "ğŸŸ¢ Ä°yi"
                    cat_summary.append({
                        "Kategori": cat,
                        "Yorum SayÄ±sÄ±": count,
                        "Ort. Puan": f"{avg_score:.1f}",
                        "Durum": status
                    })
                
                cat_df = pd.DataFrame(cat_summary).sort_values("Ort. Puan")
                st.dataframe(cat_df, use_container_width=True)

# Geri kalan kod (UI components, main dashboard vb.) aynÄ± kalacak - sadece AI entegrasyonunu ve yorum analizini dÃ¼zelttim.
# Bu noktadan sonra Ã¶nceki kodun geri kalanÄ±nÄ± da eklemem gerekiyor...

# ------------------------------------------------------------
# Ana yardÄ±mcÄ± fonksiyonlar (devamÄ±)
# ------------------------------------------------------------
def get_opportunity_stations(df):
    """FÄ±rsat istasyonlarÄ±nÄ± bulur (My Precious/Primitive <80%)"""
    if df is None or df.empty or "SKOR" not in df.columns:
        return pd.DataFrame()
    
    opportunity_mask = (
        (df["Site Segment"].isin(["My Precious", "Primitive"])) & 
        (df["SKOR"] < 0.80)
    )
    
    return df[opportunity_mask].copy()

# ------------------------------------------------------------
# UI Components
# ------------------------------------------------------------
def create_enhanced_metric_card(col, title, value, key, click_data=None):
    """GeliÅŸmiÅŸ metrik kartlarÄ±"""
    with col:
        st.markdown(f"""
        <div class="metric-card">
            <h2>{value}</h2>
            <p>{title}</p>
            <small>ğŸ“Š Detay iÃ§in tÄ±klayÄ±n</small>
        </div>
        """, unsafe_allow_html=True)
        
        if st.button("ğŸ“Š DetaylarÄ± GÃ¶ster", key=f"btn_{key}", use_container_width=True):
            st.session_state[f"show_{key}"] = not st.session_state.get(f"show_{key}", False)
    
    # Detay gÃ¶sterimi
    if st.session_state.get(f"show_{key}", False) and click_data is not None:
        with st.expander(f"ğŸ“‹ {title} DetaylarÄ±", expanded=True):
            if key == "total_stations":
                display_station_list(click_data)
            elif key == "avg_score": 
                display_score_improvement_analysis(click_data)
            elif key.startswith("segment_"):
                segment_name = key.replace("segment_", "").replace("_", " ")
                display_segment_analysis(click_data, segment_name)
            
            if st.button("âŒ Kapat", key=f"close_{key}"):
                st.session_state[f"show_{key}"] = False
                st.rerun()

def display_station_list(df):
    """Ä°stasyon listesi gÃ¶sterimi"""
    if df is None or df.empty:
        st.info("Veri bulunamadÄ±")
        return
    
    display_cols = ["ROC_STR", "Ä°stasyon", "SKOR", "DISTRICT", "NOR", "Site Segment"]
    available_cols = [col for col in display_cols if col in df.columns]
    
    display_df = df[available_cols].copy()
    
    if "SKOR" in display_df.columns:
        display_df["SKOR_FORMATTED"] = display_df["SKOR"].apply(
            lambda x: f"{x*100:.1f}%" if pd.notna(x) else "N/A"
        )
        display_df = display_df.drop(columns=["SKOR"])
        display_df = display_df.rename(columns={"SKOR_FORMATTED": "SKOR"})
    
    # Ä°stasyon seÃ§imi iÃ§in selectbox
    st.markdown("### ğŸª Ä°stasyon SeÃ§in:")
    selected_station = st.selectbox(
        "Ä°stasyon:", 
        df["Ä°stasyon"].tolist(),
        key="station_detail_selector"
    )
    
    if selected_station:
        station_data = df[df["Ä°stasyon"] == selected_station].iloc[0]
        display_station_detail(station_data)
    
    # Tablo gÃ¶sterimi
    st.markdown("### ğŸ“Š TÃ¼m Ä°stasyonlar:")
    st.dataframe(display_df, use_container_width=True, height=400)

def display_station_detail(station_data):
    """DetaylÄ± istasyon bilgileri"""
    st.markdown(f"### ğŸª {station_data['Ä°stasyon']} DetaylarÄ±")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Mevcut Skor", f"{station_data.get('SKOR', 0)*100:.1f}%")
        st.metric("ROC Kodu", station_data.get('ROC_STR', 'N/A'))
    
    with col2:
        st.metric("District", station_data.get('DISTRICT', 'N/A'))
        st.metric("NOR", station_data.get('NOR', 'N/A'))
    
    with col3:
        st.metric("Site Segment", station_data.get('Site Segment', 'N/A'))
        if pd.notna(station_data.get('TRANSACTION')):
            st.metric("Transaction", f"{station_data['TRANSACTION']:,.0f}")
    
    # AI Analizi butonu
    if st.button(f"ğŸ¤– {station_data['Ä°stasyon']} iÃ§in AI Analizi", key=f"ai_station_detail_{station_data.get('ROC_STR')}"):
        with st.spinner("AI analizi yapÄ±lÄ±yor..."):
            station_code = station_data.get("ROC_NORMALIZED") or station_data.get("ROC_STR")
            station_comments = None
            
            if st.session_state.get("comments_data") is not None:
                station_comments = st.session_state.comments_data[
                    st.session_state.comments_data["station_code"] == str(station_code)
                ]
            
            station_df = pd.DataFrame([station_data])
            ai_result = ai_recommendations_for_scope(
                station_data['Ä°stasyon'], 
                station_df, 
                station_comments
            )
            st.markdown(ai_result)
    
    # Yorum analizi (eÄŸer varsa)
    if st.session_state.get("comments_data") is not None:
        station_code = station_data.get("ROC_NORMALIZED") or station_data.get("ROC_STR")
        station_comments = st.session_state.comments_data[
            st.session_state.comments_data["station_code"] == str(station_code)
        ]
        
        if not station_comments.empty:
            display_station_comments(station_comments)

def display_station_comments(comments_df):
    """Ä°stasyon yorumlarÄ±nÄ± gÃ¶ster"""
    st.markdown("### ğŸ’¬ MÃ¼ÅŸteri YorumlarÄ±")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric("Toplam Yorum", len(comments_df))
        st.metric("Ortalama Puan", f"{comments_df['score'].mean():.1f}")
    
    with col2:
        # Puan daÄŸÄ±lÄ±mÄ± grafiÄŸi
        score_counts = comments_df['score'].value_counts().sort_index()
        fig = px.bar(
            x=score_counts.index, 
            y=score_counts.values,
            title="Puan DaÄŸÄ±lÄ±mÄ±",
            labels={"x": "Puan", "y": "Yorum SayÄ±sÄ±"}
        )
        st.plotly_chart(fig, use_container_width=True)
    
    # Kategori analizi
    st.markdown("#### ğŸ“Š Kategori BazlÄ± Analiz")
    category_scores = {}
    
    for _, row in comments_df.iterrows():
        if isinstance(row["categories"], list):
            for cat in row["categories"]:
                if cat not in category_scores:
                    category_scores[cat] = []
                category_scores[cat].append(row["score"])
    
    # Kategori performansÄ± tablosu
    cat_data = []
    for cat, scores in category_scores.items():
        cat_data.append({
            "Kategori": cat,
            "Yorum SayÄ±sÄ±": len(scores),
            "Ortalama Puan": f"{np.mean(scores):.1f}",
            "Problem Seviyesi": "ğŸ”´ YÃ¼ksek" if np.mean(scores) < 3.5 else "ğŸŸ¡ Orta" if np.mean(scores) < 4.0 else "ğŸŸ¢ DÃ¼ÅŸÃ¼k"
        })
    
    cat_df = pd.DataFrame(cat_data).sort_values("Ortalama Puan")
    st.dataframe(cat_df, use_container_width=True)
    
    # Son yorumlar
    st.markdown("#### ğŸ’­ Son Yorumlar")
    for _, comment in comments_df.head(5).iterrows():
        with st.container():
            cats = comment["categories"] if isinstance(comment["categories"], list) else ["GENEL"]
            cat_tags = " ".join([f"`{cat}`" for cat in cats])
            
            st.markdown(f"""
            **Puan: {comment['score']}/5** | {cat_tags}
            
            _{comment['comment']}_
            
            ---
            """)

def display_score_improvement_analysis(df):
    """Skor iyileÅŸtirme analizi"""
    st.markdown("### ğŸ¯ Skor Ä°yileÅŸtirme Stratejisi")
    
    if df is None or df.empty or "SKOR" not in df.columns:
        st.info("Skor verisi bulunamadÄ±")
        return
    
    # Potansiyel impact hesaplama
    improvement_opportunities = df[df["SKOR"] < 0.80].copy()
    
    if "TRANSACTION" in improvement_opportunities.columns:
        improvement_opportunities["potential_impact"] = (
            (0.80 - improvement_opportunities["SKOR"]) * 
            improvement_opportunities["TRANSACTION"] / 1000
        )
        improvement_opportunities = improvement_opportunities.sort_values(
            "potential_impact", ascending=False
        )
    else:
        improvement_opportunities["potential_impact"] = 0.80 - improvement_opportunities["SKOR"]
        improvement_opportunities = improvement_opportunities.sort_values(
            "SKOR", ascending=True
        )
    
    st.markdown("#### ğŸ”¥ En YÃ¼ksek Impact Ä°stasyonlar (Top 10)")
    
    top_impact = improvement_opportunities.head(10)
    
    for idx, (_, row) in enumerate(top_impact.iterrows(), 1):
        current_score = row["SKOR"] * 100
        target_score = 80
        potential_gain = target_score - current_score
        
        st.markdown(f"""
        **{idx}. {row['Ä°stasyon']}**
        - Mevcut: {current_score:.1f}% â†’ Hedef: {target_score}% (+{potential_gain:.1f} puan)
        - District: {row.get('DISTRICT', 'N/A')} | Segment: {row.get('Site Segment', 'N/A')}
        """)
    
    # Segment bazlÄ± fÄ±rsatlar
    st.markdown("#### ğŸª Segment BazlÄ± FÄ±rsatlar")
    
    segment_opps = improvement_opportunities.groupby("Site Segment").agg({
        "Ä°stasyon": "count",
        "SKOR": "mean",
        "potential_impact": "sum"
    }).reset_index()
    
    segment_opps = segment_opps.sort_values("potential_impact", ascending=False)
    
    for _, row in segment_opps.iterrows():
        avg_score = row["SKOR"] * 100
        st.markdown(f"""
        **{row['Site Segment']}**: {row['Ä°stasyon']} istasyon | Ort: {avg_score:.1f}%
        """)

def display_segment_analysis(df, segment_name):
    """Segment analizi"""
    st.markdown(f"### ğŸ¯ {segment_name} Segment Analizi")
    
    if df is None or df.empty:
        st.info("Veri bulunamadÄ±")
        return
    
    segment_data = df[df["Site Segment"] == segment_name] if "Site Segment" in df.columns else df
    
    if segment_data.empty:
        st.info(f"{segment_name} segmentinde istasyon bulunamadÄ±")
        return
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Toplam Ä°stasyon", len(segment_data))
    
    with col2:
        if "SKOR" in segment_data.columns:
            avg_score = segment_data["SKOR"].mean() * 100
            st.metric("Ortalama Skor", f"{avg_score:.1f}%")
    
    with col3:
        if "DISTRICT" in segment_data.columns:
            district_count = segment_data["DISTRICT"].nunique()
            st.metric("District SayÄ±sÄ±", district_count)
    
    # En iyi ve en kÃ¶tÃ¼ istasyonlar
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### ğŸ† En Ä°yi 5 Ä°stasyon")
        if "SKOR" in segment_data.columns:
            top5 = segment_data.nlargest(5, "SKOR")[["Ä°stasyon", "SKOR", "DISTRICT"]].copy()
            top5["SKOR"] = top5["SKOR"].apply(lambda x: f"{x*100:.1f}%")
            st.dataframe(top5, use_container_width=True)
    
    with col2:
        st.markdown("#### âš ï¸ En KÃ¶tÃ¼ 5 Ä°stasyon")
        if "SKOR" in segment_data.columns:
            bottom5 = segment_data.nsmallest(5, "SKOR")[["Ä°stasyon", "SKOR", "DISTRICT"]].copy()
            bottom5["SKOR"] = bottom5["SKOR"].apply(lambda x: f"{x*100:.1f}%")
            st.dataframe(bottom5, use_container_width=True)

# ------------------------------------------------------------
# BasitleÅŸtirilmiÅŸ veri kaydetme - Session Only
# ------------------------------------------------------------
def save_data_to_supabase(df, comments_df=None, period_meta=None):
    """Veri session'da saklanÄ±yor - Supabase devre dÄ±ÅŸÄ±"""
    if not SUPABASE_ENABLED:
        st.info("â„¹ï¸ Veriler session'da saklanÄ±yor - Supabase ÅŸu anda devre dÄ±ÅŸÄ±")
        return

# CSS ve sayfa yapÄ±landÄ±rmasÄ± - Ã¶ncekiyle aynÄ±
st.set_page_config(
    page_title="TLAG Performance Analytics",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    .main-header { 
        font-size: clamp(2rem, 5vw, 3rem); 
        font-weight: bold; 
        text-align: center;
        background: linear-gradient(90deg, #FF6B6B, #4ECDC4); 
        -webkit-background-clip: text; 
        -webkit-text-fill-color: transparent; 
        margin-bottom: 2rem; 
    }
    
    .metric-card { 
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
        padding: 1.5rem; 
        border-radius: 15px; 
        color: white; 
        text-align: center; 
        margin: 0.5rem 0;
        box-shadow: 0 8px 32px rgba(0,0,0,0.1); 
        cursor: pointer; 
        transition: transform 0.3s; 
    }
    
    .metric-card:hover { 
        transform: translateY(-5px); 
    }
    
    .nav-section {
        background: linear-gradient(135deg, #4ECDC4 0%, #44A08D 100%);
        padding: 1rem;
        border-radius: 15px;
        margin: 1rem 0;
        text-align: center;
    }
    
    .opportunity-card {
        background: linear-gradient(135deg, #FFA502 0%, #FF6B6B 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Session State
if "tlag_data" not in st.session_state:
    st.session_state.tlag_data = None
if "comments_data" not in st.session_state:
    st.session_state.comments_data = None
if "analyzed_comments" not in st.session_state:
    st.session_state.analyzed_comments = None
if "current_view" not in st.session_state:
    st.session_state.current_view = "main"

# ANA UYGULAMA
def main():
    st.markdown('<h1 class="main-header">ğŸ“Š TLAG PERFORMANS ANALÄ°TÄ°K</h1>', unsafe_allow_html=True)
    
    # SIDEBAR - Veri YÃ¼kleme
    st.sidebar.markdown("## ğŸ“ VERÄ° YÃ–NETÄ°MÄ°")
    
    # TLAG dosyasÄ± yÃ¼kleme
    uploaded_tlag = st.sidebar.file_uploader(
        "TLAG Excel dosyasÄ±:", 
        type=["xlsx", "xls"], 
        help="Ä°stasyon performans verilerini iÃ§eren Excel dosyasÄ±"
    )
    
    # Yorum dosyasÄ± yÃ¼kleme
    uploaded_comments = st.sidebar.file_uploader(
        "MÃ¼ÅŸteri YorumlarÄ± Excel dosyasÄ±:", 
        type=["xlsx", "xls"], 
        key="comments_uploader",
        help="MÃ¼ÅŸteri yorum anket sonuÃ§larÄ±nÄ± iÃ§eren Excel dosyasÄ±"
    )
    
    # Demo data yÃ¼kleme
    st.sidebar.markdown("## ğŸš€ DEMO VERÄ°LERÄ°")
    
    if st.sidebar.button("â˜ï¸ Cloud Demo", use_container_width=True):
        with st.spinner("Veriler yÃ¼kleniyor..."):
            tlag_df, comments_df, message = load_demo_data_from_cloud()
            if tlag_df is not None:
                st.session_state.tlag_data = tlag_df
                st.sidebar.success("âœ… TLAG demo verisi yÃ¼klendi")
                
                if comments_df is not None:
                    # Yorum verilerini TLAG ile birleÅŸtir - iyileÅŸtirilmiÅŸ
                    merged_comments = merge_comments_with_tlag(comments_df, tlag_df)
                    st.session_state.comments_data = merged_comments
                    
                    # Yorum analizini yap - iyileÅŸtirilmiÅŸ
                    district_analysis = analyze_comments_by_scope(merged_comments, "DISTRICT")
                    nor_analysis = analyze_comments_by_scope(merged_comments, "NOR")
                    
                    st.session_state.analyzed_comments = {
                        "district": district_analysis,
                        "nor": nor_analysis
                    }
                    st.sidebar.success("âœ… Yorum demo verisi yÃ¼klendi")
                
                # Session'a kaydet
                save_data_to_supabase(tlag_df, merged_comments if comments_df is not None else None)
            else:
                st.sidebar.error(message)
    
    # Dosya yÃ¼kleme iÅŸlemi
    if uploaded_tlag is not None:
        with st.spinner("TLAG verileri iÅŸleniyor..."):
            df = load_tlag_data(uploaded_tlag)
            if df is not None:
                st.session_state.tlag_data = df
                st.sidebar.success(f"âœ… {len(df)} istasyon verisi yÃ¼klendi")
                save_data_to_supabase(df)
    
    if uploaded_comments is not None and st.session_state.tlag_data is not None:
        with st.spinner("Yorum verileri iÅŸleniyor..."):
            comments_df = load_comments_data(uploaded_comments)
            if comments_df is not None:
                merged_comments = merge_comments_with_tlag(comments_df, st.session_state.tlag_data)
                st.session_state.comments_data = merged_comments
                
                district_analysis = analyze_comments_by_scope(merged_comments, "DISTRICT")
                nor_analysis = analyze_comments_by_scope(merged_comments, "NOR")
                
                st.session_state.analyzed_comments = {
                    "district": district_analysis,
                    "nor": nor_analysis
                }
                
                st.sidebar.success(f"âœ… {len(comments_df)} yorum yÃ¼klendi ve analiz edildi")
                save_data_to_supabase(None, merged_comments)
    
    # MAIN CONTENT
    if st.session_state.current_view == "main":
        display_main_dashboard()
    elif st.session_state.current_view == "district":
        display_district_analysis()
    elif st.session_state.current_view == "nor":
        display_nor_analysis() 
    elif st.session_state.current_view == "segmentation":
        display_segmentation_analysis()

def display_main_dashboard():
    """Ana dashboard gÃ¶rÃ¼nÃ¼mÃ¼"""
    
    if st.session_state.tlag_data is None:
        st.markdown("## ğŸ¯ TLAG PERFORMANS ANALÄ°TÄ°K'E HOÅGELDÄ°NÄ°Z")
        st.info("ğŸ‘ˆ Sol panelden Excel dosyalarÄ±nÄ±zÄ± yÃ¼kleyin veya demo verilerini deneyin")
        return
    
    df = st.session_state.tlag_data
    
    # Ana metrikler
    st.markdown("## ğŸ“Š ANA METRÄ°KLER")
    col1, col2, col3, col4 = st.columns(4)
    
    create_enhanced_metric_card(
        col1, "Toplam Ä°stasyon", len(df), "total_stations", df
    )
    
    if "SKOR" in df.columns:
        avg_score = df["SKOR"].mean() * 100
        create_enhanced_metric_card(
            col2, "Ortalama Skor", f"{avg_score:.1f}%", "avg_score", df
        )
    
    if "Site Segment" in df.columns:
        segments = df["Site Segment"].value_counts()
        for idx, (segment, count) in enumerate(segments.head(2).items()):
            if idx == 0:
                create_enhanced_metric_card(
                    col3, segment, count, f"segment_{segment.replace(' ', '_')}", 
                    df[df["Site Segment"] == segment]
                )
            elif idx == 1:
                create_enhanced_metric_card(
                    col4, segment, count, f"segment_{segment.replace(' ', '_')}", 
                    df[df["Site Segment"] == segment]
                )
    
    # District performans tablosu ve yorum analizi
    if "DISTRICT" in df.columns and "SKOR" in df.columns:
        st.markdown("## ğŸ“ˆ DISTRICT PERFORMANS VE YORUM ANALÄ°ZÄ°")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.markdown("### ğŸ“Š District Performans Tablosu")
            district_performance = df.groupby("DISTRICT").agg({
                "SKOR": "mean",
                "Ä°stasyon": "count"
            }).reset_index()
            
            district_performance["SKOR_FORMATTED"] = district_performance["SKOR"].apply(
                lambda x: f"{x*100:.1f}%"
            )
            
            district_performance = district_performance.sort_values("SKOR", ascending=False)
            st.dataframe(district_performance[["DISTRICT", "Ä°stasyon", "SKOR_FORMATTED"]], use_container_width=True)
        
        with col2:
            st.markdown("### ğŸ’¬ District Yorum Analizi")
            if st.session_state.get("analyzed_comments") and st.session_state.analyzed_comments.get("district"):
                display_comment_analysis_enhanced(
                    st.session_state.analyzed_comments["district"], 
                    "District BazlÄ± Yorumlar"
                )
            else:
                st.info("Yorum verisi yÃ¼klenirken analiz edilecek")
    
    # FÄ±rsat istasyonlarÄ±
    opportunity_stations = get_opportunity_stations(df)
    if not opportunity_stations.empty:
        st.markdown("## ğŸ¯ FIRSAT Ä°STASYONLARI")
        st.markdown("*My Precious veya Primitive segment, 80% altÄ± skor*")
        
        st.markdown(f"**Toplam {len(opportunity_stations)} fÄ±rsat istasyonu tespit edildi**")
        
        # En yÃ¼ksek potansiyelli ilk 10
        if "TRANSACTION" in opportunity_stations.columns:
            opportunity_stations["potential"] = (
                (0.80 - opportunity_stations["SKOR"]) * 
                opportunity_stations["TRANSACTION"] / 1000
            )
            top_opportunities = opportunity_stations.nlargest(10, "potential")
        else:
            top_opportunities = opportunity_stations.nsmallest(10, "SKOR")
        
        for idx, (_, station) in enumerate(top_opportunities.iterrows(), 1):
            current_score = station["SKOR"] * 100
            potential_gain = 80 - current_score
            
            st.markdown(f"""
            <div class="opportunity-card">
                <strong>{idx}. {station['Ä°stasyon']}</strong><br>
                Mevcut: {current_score:.1f}% â†’ Hedef: 80% (+{potential_gain:.1f} puan)<br>
                <small>{station['DISTRICT']} | {station['Site Segment']}</small>
            </div>
            """, unsafe_allow_html=True)
    
    # Navigasyon
    st.markdown("## ğŸ¯ HANGÄ° ANALÄ°ZÄ° YAPMAK Ä°STÄ°YORSUNUZ?")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div class="nav-section">
            <h3>ğŸ¢ DISTRICT</h3>
            <p>BÃ¶lgesel performans ve AI analizi</p>
        </div>
        """, unsafe_allow_html=True)
        
        if st.button("District Analizine Git", key="nav_district", use_container_width=True, type="primary"):
            st.session_state.current_view = "district"
            st.rerun()
    
    with col2:
        st.markdown("""
        <div class="nav-section">
            <h3>ğŸ“ NOR</h3>
            <p>NOR bazlÄ± performans ve AI analizi</p>
        </div>
        """, unsafe_allow_html=True)
        
        if st.button("NOR Analizine Git", key="nav_nor", use_container_width=True, type="primary"):
            st.session_state.current_view = "nor"
            st.rerun()
    
    with col3:
        st.markdown("""
        <div class="nav-section">
            <h3>ğŸª SÄ°TE SEGMENTASYON</h3>
            <p>Segment bazlÄ± performans analizi</p>
        </div>
        """, unsafe_allow_html=True)
        
        if st.button("Segmentasyon Analizine Git", key="nav_segmentation", use_container_width=True, type="primary"):
            st.session_state.current_view = "segmentation"
            st.rerun()

def display_district_analysis():
    """District analiz sayfasÄ± - AI entegrasyonu ile"""
    if st.button("ğŸ  Ana Sayfaya DÃ¶n", key="back_from_district"):
        st.session_state.current_view = "main"
        st.rerun()
    
    st.markdown("## ğŸ¢ DISTRICT BAZLI ANALÄ°Z")
    
    df = st.session_state.tlag_data
    if df is None or "DISTRICT" not in df.columns:
        st.error("District verisi bulunamadÄ±")
        return
    
    districts = sorted(df["DISTRICT"].dropna().unique())
    selected_district = st.selectbox("District SeÃ§in:", districts, key="district_selector")
    
    if selected_district:
        district_data = df[df["DISTRICT"] == selected_district].copy()
        
        # Temel metrikler
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Ä°stasyon SayÄ±sÄ±", len(district_data))
        
        with col2:
            if "SKOR" in district_data.columns:
                avg_score = district_data["SKOR"].mean() * 100
                st.metric("Ortalama Skor", f"{avg_score:.1f}%")
        
        with col3:
            if "Site Segment" in district_data.columns:
                dominant_segment = district_data["Site Segment"].mode().iloc[0] if len(district_data["Site Segment"].mode()) > 0 else "N/A"
                st.metric("BaskÄ±n Segment", dominant_segment)
        
        with col4:
            opportunity_count = len(get_opportunity_stations(district_data))
            st.metric("FÄ±rsat Ä°stasyonu", opportunity_count)
        
        # AI Analizi
        st.markdown("### ğŸ¤– AI PERFORMANS ANALÄ°ZÄ°")
        if st.button(f"ğŸ¤– {selected_district} iÃ§in AI Analizi OluÅŸtur", key=f"ai_district_{selected_district}"):
            with st.spinner("AI analizi yapÄ±lÄ±yor..."):
                # District yorumlarÄ±nÄ± al
                district_comments_df = None
                if st.session_state.get("comments_data") is not None:
                    district_comments_df = st.session_state.comments_data[
                        st.session_state.comments_data["DISTRICT_FINAL"] == selected_district
                    ]
                
                ai_result = ai_recommendations_for_scope(
                    selected_district, 
                    district_data, 
                    district_comments_df
                )
                st.markdown(ai_result)
        
        # District yorum analizi
        if st.session_state.get("analyzed_comments") and st.session_state.analyzed_comments.get("district"):
            district_comments = st.session_state.analyzed_comments["district"]
            if selected_district in district_comments:
                display_comment_analysis_enhanced({selected_district: district_comments[selected_district]}, 
                                                f"{selected_district} MÃ¼ÅŸteri YorumlarÄ±")

def display_nor_analysis():
    """NOR analiz sayfasÄ± - AI entegrasyonu ile"""
    if st.button("ğŸ  Ana Sayfaya DÃ¶n", key="back_from_nor"):
        st.session_state.current_view = "main"
        st.rerun()
    
    st.markdown("## ğŸ“ NOR BAZLI ANALÄ°Z")
    
    df = st.session_state.tlag_data
    if df is None or "NOR" not in df.columns:
        st.error("NOR verisi bulunamadÄ±")
        return
    
    nors = sorted(df["NOR"].dropna().unique())
    selected_nor = st.selectbox("NOR SeÃ§in:", nors, key="nor_selector")
    
    if selected_nor:
        nor_data = df[df["NOR"] == selected_nor].copy()
        
        # Temel metrikler
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Ä°stasyon SayÄ±sÄ±", len(nor_data))
        
        with col2:
            if "SKOR" in nor_data.columns:
                avg_score = nor_data["SKOR"].mean() * 100
                st.metric("Ortalama Skor", f"{avg_score:.1f}%")
        
        with col3:
            if "DISTRICT" in nor_data.columns:
                district_count = nor_data["DISTRICT"].nunique()
                st.metric("District SayÄ±sÄ±", district_count)
        
        with col4:
            opportunity_count = len(get_opportunity_stations(nor_data))
            st.metric("FÄ±rsat Ä°stasyonu", opportunity_count)
        
        # AI Analizi
        st.markdown("### ğŸ¤– AI PERFORMANS ANALÄ°ZÄ°")
        if st.button(f"ğŸ¤– {selected_nor} iÃ§in AI Analizi OluÅŸtur", key=f"ai_nor_{selected_nor}"):
            with st.spinner("AI analizi yapÄ±lÄ±yor..."):
                # NOR yorumlarÄ±nÄ± al
                nor_comments_df = None
                if st.session_state.get("comments_data") is not None:
                    nor_comments_df = st.session_state.comments_data[
                        st.session_state.comments_data["NOR_FINAL"] == selected_nor
                    ]
                
                ai_result = ai_recommendations_for_scope(
                    selected_nor, 
                    nor_data, 
                    nor_comments_df
                )
                st.markdown(ai_result)
        
        # NOR yorum analizi
        if st.session_state.get("analyzed_comments") and st.session_state.analyzed_comments.get("nor"):
            nor_comments = st.session_state.analyzed_comments["nor"]
            if selected_nor in nor_comments:
                display_comment_analysis_enhanced({selected_nor: nor_comments[selected_nor]}, 
                                                f"{selected_nor} MÃ¼ÅŸteri YorumlarÄ±")

def display_segmentation_analysis():
    """Segmentasyon analiz sayfasÄ±"""
    if st.button("ğŸ  Ana Sayfaya DÃ¶n", key="back_from_segmentation"):
        st.session_state.current_view = "main"
        st.rerun()
    
    st.markdown("## ğŸª SÄ°TE SEGMENTASYON ANALÄ°ZÄ°")
    
    df = st.session_state.tlag_data
    if df is None or "Site Segment" not in df.columns:
        st.error("Site Segment verisi bulunamadÄ±")
        return
    
    # Segment genel bakÄ±ÅŸ
    st.markdown("### ğŸ“Š Segment Genel BakÄ±ÅŸ")
    
    segment_summary = df.groupby("Site Segment").agg({
        "Ä°stasyon": "count",
        "SKOR": ["mean", "min", "max"]
    }).round(3)
    
    segment_summary.columns = ["Ä°stasyon SayÄ±sÄ±", "Ort. Skor", "Min Skor", "Max Skor"]
    segment_summary["Ort. Skor %"] = (segment_summary["Ort. Skor"] * 100).round(1).astype(str) + "%"
    segment_summary["Min Skor %"] = (segment_summary["Min Skor"] * 100).round(1).astype(str) + "%"
    segment_summary["Max Skor %"] = (segment_summary["Max Skor"] * 100).round(1).astype(str) + "%"
    
    st.dataframe(segment_summary, use_container_width=True)

if __name__ == "__main__":
    main()