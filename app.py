# app.py - Enhanced TLAG Performance Analytics with AI

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
import re
import json
from datetime import datetime, date, timedelta
import calendar
import os

# ------------------------------------------------------------
# KÃ¼Ã§Ã¼k yardÄ±mcÄ±lar
# ------------------------------------------------------------
def _to_int_safe(val):
    try:
        if val is None or (isinstance(val, float) and np.isnan(val)):
            return None
        if isinstance(val, str):
            v = val.strip()
            if v == "":
                return None
            if "." in v:
                v = v.split(".")[0]
            return int(v)
        if isinstance(val, float):
            return int(round(val))
        return int(val)
    except Exception:
        return None

def _to_float_safe(val):
    try:
        if val is None or (isinstance(val, float) and np.isnan(val)):
            return None
        return float(val)
    except Exception:
        return None

def normalize_roc(val):
    """ROC deÄŸerini gÃ¼venli biÃ§imde normalize eder."""
    if val is None or (isinstance(val, float) and np.isnan(val)):
        return None
    s = str(val).strip()
    if s.endswith(".0"):
        s = s[:-2]
    m = re.search(r"#(\d{4})$", s)
    if m:
        return m.group(1)
    m = re.search(r"(\d+)", s)
    return m.group(1) if m else None

def extract_station_code(station_info):
    """Station info'dan son 4 haneli kodu Ã§Ä±karÄ±r"""
    if pd.isna(station_info):
        return None
    s = str(station_info)
    m = re.search(r"#(\d{4})$", s)
    if m:
        return m.group(1)
    m = re.search(r"(\d{4})(?=\D*$)", s)
    return m.group(1) if m else None

# ------------------------------------------------------------
# Supabase entegrasyonu
# ------------------------------------------------------------
SUPABASE_ENABLED = True

try:
    from supabase import create_client, Client
    
    def init_supabase():
        """Supabase client baÅŸlatma"""
        try:
            url = os.environ.get("SUPABASE_URL") or st.secrets.get("SUPABASE_URL", None)
            key = os.environ.get("SUPABASE_KEY") or st.secrets.get("SUPABASE_KEY", None)
            
            if url and key:
                return create_client(url, key)
            return None
        except:
            return None
    
    supabase: Client = init_supabase()
except ImportError:
    supabase = None
    SUPABASE_ENABLED = False

# ------------------------------------------------------------
# OpenAI AI Analiz FonksiyonlarÄ±
# ------------------------------------------------------------
def get_openai_api_key():
    """OpenAI API anahtarÄ±nÄ± al"""
    try:
        api_key = os.getenv("OPENAI_API_KEY")
        if api_key:
            return api_key
        if hasattr(st, 'secrets') and 'openai' in st.secrets:
            return st.secrets.openai.api_key
        return None
    except:
        return None

def ai_chat_interface(df, comments_df=None):
    """AI Chat Interface - Enter ile Ã§alÄ±ÅŸÄ±r"""
    st.markdown("### ğŸ¤– AI TLAG UZMANI")
    
    with st.container():
        st.markdown("""
        <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                    padding: 1rem; border-radius: 15px; color: white;">
            <p style="color: white; margin: 0;">SorularÄ±nÄ±zÄ± yazÄ±p Enter'a basÄ±n. Ã–rn: "Ankara GÃ¼ney'in skorunu nasÄ±l artÄ±rÄ±rÄ±m?"</p>
        </div>
        """, unsafe_allow_html=True)
        
        if "chat_history" not in st.session_state:
            st.session_state.chat_history = []
        
        # Form ile Enter desteÄŸi
        with st.form(key="ai_chat_form", clear_on_submit=True):
            user_query = st.text_input(
                "Sorunuz:",
                placeholder="Ä°stasyon, NOR veya District analizi iÃ§in soru yazÄ±n...",
                label_visibility="collapsed"
            )
            
            col1, col2 = st.columns([6, 1])
            with col1:
                submit = st.form_submit_button("ğŸš€ Analiz", use_container_width=True, type="primary")
            with col2:
                if st.form_submit_button("ğŸ—‘ï¸", use_container_width=True):
                    st.session_state.chat_history = []
                    st.rerun()
        
        if submit and user_query:
            with st.spinner("Analiz yapÄ±lÄ±yor... (5-10 saniye)"):
                response = get_ai_response(user_query, df, comments_df)
                st.session_state.chat_history.append({
                    "query": user_query,
                    "response": response,
                    "timestamp": datetime.now().strftime("%H:%M")
                })
        
        # Chat geÃ§miÅŸi
        if st.session_state.chat_history:
            for chat in reversed(st.session_state.chat_history[-3:]):  # Son 3 mesaj
                with st.container():
                    st.markdown(f"**ğŸ• {chat['timestamp']} - Soru:** {chat['query']}")
                    st.info(chat['response'])

def get_ai_response(query, df, comments_df=None):
    """AI analizi - HÄ±zlÄ± ve spesifik"""
    api_key = get_openai_api_key()
    if not api_key:
        return "âš ï¸ OpenAI API anahtarÄ± bulunamadÄ±."
    
    try:
        from openai import OpenAI
        
        # Sorgu analizi
        query_lower = query.lower()
        target_nor = None
        target_district = None
        
        if "NOR" in df.columns:
            for nor in df["NOR"].dropna().unique():
                if str(nor).lower() in query_lower:
                    target_nor = nor
                    break
        
        if "DISTRICT" in df.columns:
            for district in df["DISTRICT"].dropna().unique():
                if str(district).lower() in query_lower:
                    target_district = district
                    break
        
        # Veri filtreleme
        filtered_df = df.copy()
        filtered_comments = comments_df.copy() if comments_df is not None else pd.DataFrame()
        
        if target_nor:
            filtered_df = df[df["NOR"] == target_nor]
            if not filtered_comments.empty and "NOR_FINAL" in filtered_comments.columns:
                filtered_comments = filtered_comments[filtered_comments["NOR_FINAL"] == target_nor]
        elif target_district:
            filtered_df = df[df["DISTRICT"] == target_district]
            if not filtered_comments.empty and "DISTRICT_FINAL" in filtered_comments.columns:
                filtered_comments = filtered_comments[filtered_comments["DISTRICT_FINAL"] == target_district]
        
        # Kritik veriler
        worst_3 = filtered_df.nsmallest(3, "SKOR")[["Ä°stasyon", "SKOR"]].to_dict('records')
        avg_score = filtered_df['SKOR'].mean() * 100
        
        problem_cats = {}
        if not filtered_comments.empty:
            for _, row in filtered_comments.iterrows():
                if row.get("score", 5) <= 3 and isinstance(row.get("categories"), list):
                    for cat in row["categories"]:
                        if cat not in problem_cats:
                            problem_cats[cat] = 0
                        problem_cats[cat] += 1
        
        top_problems = sorted(problem_cats.items(), key=lambda x: x[1], reverse=True)[:3]
        
        # KÄ±sa ve Ã¶z prompt
        prompt = f"""TLAG uzmanÄ± olarak analiz et:

VERÄ°:
- {len(filtered_df)} istasyon, Ort: {avg_score:.1f}%
- En kÃ¶tÃ¼ 3: {', '.join([f"{s['Ä°stasyon']} ({s['SKOR']*100:.1f}%)" for s in worst_3])}
- Problem kategoriler: {', '.join([f"{cat}({count})" for cat, count in top_problems])}

Soru: {query}

KISA ve SOMUT yanÄ±t:
1. Hangi istasyona mÃ¼dahale?
2. Hangi kategoriye odaklan?
3. Beklenen artÄ±ÅŸ?

GerÃ§ek istasyon isimleri kullan. Max 5 cÃ¼mle."""
        
        client = OpenAI(api_key=api_key)
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0,
            max_tokens=300
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        return f"Hata: {str(e)}"
    
    try:
        import openai
        from openai import OpenAI
        
        # Sorgudan NOR/District/Ä°stasyon tespit et
        query_lower = query.lower()
        target_nor = None
        target_district = None
        target_station = None
        
        # NOR kontrolÃ¼
        if "NOR" in df.columns:
            for nor in df["NOR"].dropna().unique():
                if str(nor).lower() in query_lower:
                    target_nor = nor
                    break
        
        # District kontrolÃ¼
        if "DISTRICT" in df.columns:
            for district in df["DISTRICT"].dropna().unique():
                if str(district).lower() in query_lower:
                    target_district = district
                    break
        
        # Ä°stasyon kontrolÃ¼
        if "Ä°stasyon" in df.columns:
            for station in df["Ä°stasyon"].dropna().unique():
                if str(station).lower() in query_lower:
                    target_station = station
                    break
        
        # Hedef bÃ¶lge verilerini filtrele
        filtered_df = df.copy()
        filtered_comments = comments_df.copy() if comments_df is not None else pd.DataFrame()
        scope_name = "TÃœM TÃœRKÄ°YE"
        
        if target_station:
            filtered_df = df[df["Ä°stasyon"] == target_station]
            scope_name = f"{target_station} Ä°STASYONU"
            if not filtered_comments.empty and "Ä°stasyon" in filtered_comments.columns:
                filtered_comments = filtered_comments[filtered_comments["Ä°stasyon"] == target_station]
        elif target_nor:
            filtered_df = df[df["NOR"] == target_nor]
            scope_name = f"{target_nor} NOR BÃ–LGESÄ°"
            if not filtered_comments.empty and "NOR_FINAL" in filtered_comments.columns:
                filtered_comments = filtered_comments[filtered_comments["NOR_FINAL"] == target_nor]
        elif target_district:
            filtered_df = df[df["DISTRICT"] == target_district]
            scope_name = f"{target_district} DISTRICT BÃ–LGESÄ°"
            if not filtered_comments.empty and "DISTRICT_FINAL" in filtered_comments.columns:
                filtered_comments = filtered_comments[filtered_comments["DISTRICT_FINAL"] == target_district]
        
        # DETAYLI VERÄ° ANALÄ°ZÄ°
        detailed_analysis = f"""
===== {scope_name} DETAYLI VERÄ° ANALÄ°ZÄ° =====

ğŸ“Š Ä°STASYON VERÄ°LERÄ°:
- Toplam istasyon sayÄ±sÄ±: {len(filtered_df)}
- Ortalama TLAG skoru: {filtered_df['SKOR'].mean()*100:.2f}%
- En yÃ¼ksek TLAG skoru: {filtered_df['SKOR'].max()*100:.2f}%
- En dÃ¼ÅŸÃ¼k TLAG skoru: {filtered_df['SKOR'].min()*100:.2f}%
- Standart sapma: {filtered_df['SKOR'].std()*100:.2f}%
"""
        
        # EN DÃœÅÃœK SKORLU Ä°STASYONLAR - DETAYLI
        if "SKOR" in filtered_df.columns and len(filtered_df) > 0:
            worst_stations = filtered_df.nsmallest(min(10, len(filtered_df)), "SKOR")
            detailed_analysis += "\nğŸ”´ EN DÃœÅÃœK SKORLU Ä°STASYONLAR (Acil mÃ¼dahale gerekli):\n"
            for idx, (_, row) in enumerate(worst_stations.iterrows(), 1):
                detailed_analysis += f"{idx}. {row['Ä°stasyon']}: {row['SKOR']*100:.1f}% "
                if "Site Segment" in row:
                    detailed_analysis += f"(Segment: {row['Site Segment']})"
                if "TRANSACTION" in row and pd.notna(row['TRANSACTION']):
                    detailed_analysis += f" [Transaction: {row['TRANSACTION']:.0f}]"
                improvement_potential = (0.80 - row['SKOR']) * 100
                if improvement_potential > 0:
                    detailed_analysis += f" â†’ Ä°yileÅŸtirme potansiyeli: +{improvement_potential:.1f} puan"
                detailed_analysis += "\n"
        
        # EN YÃœKSEK SKORLU Ä°STASYONLAR
        if "SKOR" in filtered_df.columns and len(filtered_df) > 3:
            best_stations = filtered_df.nlargest(min(5, len(filtered_df)), "SKOR")
            detailed_analysis += "\nâœ… EN YÃœKSEK SKORLU Ä°STASYONLAR (BaÅŸarÄ± Ã¶rnekleri):\n"
            for idx, (_, row) in enumerate(best_stations.iterrows(), 1):
                detailed_analysis += f"{idx}. {row['Ä°stasyon']}: {row['SKOR']*100:.1f}%\n"
        
        # SEGMENT ANALÄ°ZÄ°
        if "Site Segment" in filtered_df.columns:
            segment_analysis = filtered_df.groupby("Site Segment").agg({
                "Ä°stasyon": "count",
                "SKOR": ["mean", "min", "max"]
            })
            detailed_analysis += "\nğŸ“ˆ SEGMENT BAZLI ANALÄ°Z:\n"
            for segment in segment_analysis.index:
                count = segment_analysis.loc[segment, ("Ä°stasyon", "count")]
                avg_score = segment_analysis.loc[segment, ("SKOR", "mean")] * 100
                min_score = segment_analysis.loc[segment, ("SKOR", "min")] * 100
                max_score = segment_analysis.loc[segment, ("SKOR", "max")] * 100
                detailed_analysis += f"- {segment}: {count} istasyon, Ortalama: {avg_score:.1f}%, Min: {min_score:.1f}%, Max: {max_score:.1f}%\n"
        
        # FIRSAT Ä°STASYONLARI
        if "Site Segment" in filtered_df.columns:
            opportunity = filtered_df[
                (filtered_df["Site Segment"].isin(["My Precious", "Primitive"])) & 
                (filtered_df["SKOR"] < 0.80)
            ]
            if not opportunity.empty:
                detailed_analysis += f"\nğŸ’ FIRSAT Ä°STASYONLARI: {len(opportunity)} adet\n"
                for _, row in opportunity.head(5).iterrows():
                    detailed_analysis += f"- {row['Ä°stasyon']}: {row['SKOR']*100:.1f}% â†’ Hedef: 80% (Potansiyel: +{(0.80-row['SKOR'])*100:.1f} puan)\n"
        
        # MÃœÅTERÄ° YORUMLARI ANALÄ°ZÄ°
        if not filtered_comments.empty and "score" in filtered_comments.columns:
            detailed_analysis += f"""

ğŸ’¬ MÃœÅTERÄ° YORUMLARI ANALÄ°ZÄ°:
- Toplam yorum sayÄ±sÄ±: {len(filtered_comments)}
- Ortalama mÃ¼ÅŸteri puanÄ±: {filtered_comments['score'].mean():.2f}/5
- 5 puan veren mÃ¼ÅŸteri sayÄ±sÄ±: {len(filtered_comments[filtered_comments['score'] == 5])} ({len(filtered_comments[filtered_comments['score'] == 5])/len(filtered_comments)*100:.1f}%)
- 4 puan veren mÃ¼ÅŸteri sayÄ±sÄ±: {len(filtered_comments[filtered_comments['score'] == 4])} ({len(filtered_comments[filtered_comments['score'] == 4])/len(filtered_comments)*100:.1f}%)
- 3 puan veren mÃ¼ÅŸteri sayÄ±sÄ±: {len(filtered_comments[filtered_comments['score'] == 3])} ({len(filtered_comments[filtered_comments['score'] == 3])/len(filtered_comments)*100:.1f}%)
- 1-2 puan veren (kritik) mÃ¼ÅŸteri sayÄ±sÄ±: {len(filtered_comments[filtered_comments['score'] <= 2])} ({len(filtered_comments[filtered_comments['score'] <= 2])/len(filtered_comments)*100:.1f}%)
"""
            
            # KATEGORÄ° BAZLI DETAYLI ANALÄ°Z
            category_analysis = {}
            for _, row in filtered_comments.iterrows():
                if isinstance(row.get("categories"), list):
                    for cat in row["categories"]:
                        if cat not in category_analysis:
                            category_analysis[cat] = {
                                "scores": [],
                                "comments": [],
                                "stations": []
                            }
                        category_analysis[cat]["scores"].append(row["score"])
                        if pd.notna(row.get("comment")):
                            category_analysis[cat]["comments"].append(str(row["comment"])[:200])
                        if pd.notna(row.get("Ä°stasyon")):
                            category_analysis[cat]["stations"].append(row["Ä°stasyon"])
            
            # Problem kategorilerini tespit et
            detailed_analysis += "\nğŸ” KATEGORÄ° BAZLI PROBLEM ANALÄ°ZÄ°:\n"
            problem_categories = []
            
            for cat, data in category_analysis.items():
                avg_score = np.mean(data["scores"])
                count = len(data["scores"])
                
                if avg_score < 4.0 and count >= 3:  # Problem kategorisi
                    problem_categories.append((cat, avg_score, count, data))
            
            # Problemleri Ã¶nem sÄ±rasÄ±na gÃ¶re sÄ±rala
            problem_categories.sort(key=lambda x: (x[1], -x[2]))  # Ã–nce dÃ¼ÅŸÃ¼k puan, sonra yÃ¼ksek sayÄ±
            
            for cat, avg_score, count, data in problem_categories[:5]:  # En problemli 5 kategori
                detailed_analysis += f"\nâš ï¸ {cat}: {count} yorum, Ortalama: {avg_score:.1f}/5\n"
                
                # Bu kategoride en Ã§ok ÅŸikayet alan istasyonlar
                if data["stations"]:
                    station_counts = pd.Series(data["stations"]).value_counts().head(3)
                    detailed_analysis += f"   En Ã§ok ÅŸikayet alan istasyonlar:\n"
                    for station, s_count in station_counts.items():
                        detailed_analysis += f"   - {station}: {s_count} ÅŸikayet\n"
                
                # DÃ¼ÅŸÃ¼k puanlÄ± yorumlardan Ã¶rnekler
                low_score_comments = [
                    (score, comment) 
                    for score, comment in zip(data["scores"], data["comments"]) 
                    if score <= 3
                ][:3]
                
                if low_score_comments:
                    detailed_analysis += f"   Ã–rnek ÅŸikayetler:\n"
                    for score, comment in low_score_comments:
                        detailed_analysis += f"   â€¢ ({score}/5 puan) \"{comment[:100]}...\"\n"
            
            # Ä°yi performans gÃ¶steren kategoriler
            good_categories = [(cat, np.mean(data["scores"]), len(data["scores"])) 
                             for cat, data in category_analysis.items() 
                             if np.mean(data["scores"]) >= 4.5 and len(data["scores"]) >= 3]
            
            if good_categories:
                detailed_analysis += "\nâœ… Ä°YÄ° PERFORMANS GÃ–STEREN KATEGORÄ°LER:\n"
                for cat, avg_score, count in good_categories[:3]:
                    detailed_analysis += f"- {cat}: {count} yorum, Ortalama: {avg_score:.1f}/5\n"
            
            # Ä°STASYON BAZLI YORUM ANALÄ°ZÄ°
            if "Ä°stasyon" in filtered_comments.columns:
                station_comments = filtered_comments.groupby("Ä°stasyon").agg({
                    "score": ["mean", "count"],
                    "comment": lambda x: list(x)[:3]  # Ä°lk 3 yorum
                })
                
                detailed_analysis += "\nğŸ“ Ä°STASYON BAZLI YORUM ANALÄ°ZÄ°:\n"
                
                # En kÃ¶tÃ¼ yorum alan istasyonlar
                worst_comment_stations = station_comments.sort_values(("score", "mean")).head(5)
                for station in worst_comment_stations.index:
                    avg = station_comments.loc[station, ("score", "mean")]
                    count = station_comments.loc[station, ("score", "count")]
                    if avg < 4.0:
                        detailed_analysis += f"- {station}: {count} yorum, Ortalama: {avg:.1f}/5 âš ï¸\n"
        
        # Ã–ZET TLAG SKORU HESAPLAMASI
        if not filtered_comments.empty and "score" in filtered_comments.columns:
            score_5_count = len(filtered_comments[filtered_comments["score"] == 5])
            total_surveys = len(filtered_comments)
            calculated_tlag = (score_5_count / total_surveys * 100) if total_surveys > 0 else 0
            detailed_analysis += f"\nğŸ“Š HESAPLANAN TLAG SKORU: {calculated_tlag:.2f}% (5 puan veren / toplam anket)\n"
        
        # AI'ya gÃ¶nderilecek prompt
        prompt = f"""Sen deneyimli bir TLAG (petrol istasyonu) performans uzmanÄ±sÄ±n. Elindeki GERÃ‡EK VERÄ°LER:

{detailed_analysis}

KullanÄ±cÄ± sorusu: {query}

GÃ–REV:
1. YukarÄ±daki VERÄ°LERÄ° DETAYLI Ä°NCELE
2. Sorulan soruya SADECE VERÄ°LERE DAYALI cevap ver
3. GERÃ‡EK Ä°STASYON Ä°SÄ°MLERÄ° kullan
4. GERÃ‡EK SKORLAR ve YÃœZDELER kullan
5. Somut, Ã¶lÃ§Ã¼lebilir Ã¶neriler sun
6. Her Ã¶neri iÃ§in TAHMÄ°NÄ° SKOR ARTIÅI belirt

Ã–NEMLÄ°:
- Genel tavsiyelerden KAÃ‡IN
- Sadece yukarÄ±daki verilerde OLAN bilgileri kullan
- Ä°stasyon isimlerini ve skorlarÄ± doÄŸru kullan
- Problem kategorilerini ve yorumlarÄ± dikkate al

TÃ¼rkÃ§e yanÄ±tla ve VERÄ°YE DAYALI Ã¶neriler sun."""
        
        # OpenAI API Ã§aÄŸrÄ±sÄ±
        client = OpenAI(api_key=api_key)
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Sen bir TLAG performans uzmanÄ±sÄ±n. SADECE sana verilen gerÃ§ek verilere dayanarak analiz yaparsÄ±n."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,  # Ã‡ok dÃ¼ÅŸÃ¼k temperature = daha tutarlÄ± ve veriye baÄŸlÄ±
            max_tokens=1500
        )
        
        return response.choices[0].message.content
        
    except ImportError:
        return "âš ï¸ OpenAI modÃ¼lÃ¼ kurulu deÄŸil. Terminal'de: pip install openai"
    except Exception as e:
        return f"âŒ AI analiz hatasÄ±: {str(e)}\n\nLÃ¼tfen OpenAI API anahtarÄ±nÄ±zÄ± kontrol edin."

def ai_recommendations_for_scope(scope_name, df_scope, comments_scope=None):
    """Belirli bir scope iÃ§in AI analizi"""
    api_key = get_openai_api_key()
    if not api_key:
        return "### ğŸ”‘ OpenAI API AnahtarÄ± Gerekli\n\n.env dosyasÄ±na OPENAI_API_KEY ekleyin."
    
    try:
        import openai
        from openai import OpenAI
        
        # Data Ã¶zeti hazÄ±rla
        station_count = len(df_scope) if df_scope is not None else 0
        avg_score = df_scope["SKOR"].mean() * 100 if df_scope is not None and "SKOR" in df_scope.columns else 0
        
        prompt = f"""Sen bir petrol istasyonu performans uzmanÄ±sÄ±n. {scope_name} iÃ§in analiz yap.

        VERÄ°:
        - Ä°stasyon sayÄ±sÄ±: {station_count}
        - Ortalama skor: {avg_score:.1f}%
        
        KÄ±sa ve net Ã¶neriler ver. TÃ¼rkÃ§e yanÄ±tla."""
        
        client = OpenAI(api_key=api_key)
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=500
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"### âŒ AI Analiz HatasÄ±\n\n{str(e)}"

# ------------------------------------------------------------
# Demo veri yÃ¼kleme
# ------------------------------------------------------------
def load_demo_data_from_cloud():
    """Cloud'dan gerÃ§ek veriler"""
    try:
        TLAG_DEMO_URL = "https://raw.githubusercontent.com/okilicarslan/tlag-cloud-data/refs/heads/main/tlag_demo.csv"
        COMMENTS_DEMO_URL = "https://raw.githubusercontent.com/okilicarslan/tlag-cloud-data/refs/heads/main/comments_demo.csv"

        import requests
        from io import StringIO

        r1 = requests.get(TLAG_DEMO_URL, timeout=30)
        r1.raise_for_status()
        tlag_df = pd.read_csv(StringIO(r1.text), low_memory=False)

        for col in ["SKOR", "GEÃ‡EN SENE SKOR", "Fark", "TRANSACTION"]:
            if col in tlag_df.columns:
                tlag_df[col] = pd.to_numeric(tlag_df[col], errors="coerce")

        if "ROC_STR" not in tlag_df.columns and "ROC" in tlag_df.columns:
            tlag_df["ROC_STR"] = tlag_df["ROC"].apply(lambda x: str(int(x)) if pd.notna(x) else str(x))
        
        # SÄ±ralama ekle
        if "SKOR" in tlag_df.columns:
            valid_scores = tlag_df["SKOR"].notna()
            tlag_df.loc[valid_scores, "SIRALAMA"] = tlag_df.loc[valid_scores, "SKOR"].rank(ascending=False, method="min")
            tlag_df["SIRALAMA"] = tlag_df["SIRALAMA"].apply(lambda x: int(x) if pd.notna(x) else None)

        r2 = requests.get(COMMENTS_DEMO_URL, timeout=60)
        r2.raise_for_status()
        comments_df = pd.read_csv(
            StringIO(r2.text),
            low_memory=False,
            dtype={"station_code": "string"}
        )

        if "categories" in comments_df.columns:
            def _to_list(x):
                if isinstance(x, str) and x.strip().startswith("["):
                    try:
                        return json.loads(x)
                    except Exception:
                        return ["GENEL"]
                return [x] if pd.notna(x) else ["GENEL"]
            comments_df["categories"] = comments_df["categories"].apply(_to_list)

        return tlag_df, comments_df, "Cloud verileri baÅŸarÄ±yla yÃ¼klendi!"
    except Exception as e:
        return None, None, f"Cloud veri yÃ¼kleme hatasÄ±: {str(e)}"

# ------------------------------------------------------------
# Yorum kategorileri
# ------------------------------------------------------------
def categorize_comment_enhanced(comment_text):
    """GeliÅŸmiÅŸ yorum kategorileme"""
    if pd.isna(comment_text):
        return ["GENEL"]
    
    comment_lower = str(comment_text).lower()
    categories = []
    
    category_keywords = {
        "PERSONEL": [
            "personel", "Ã§alÄ±ÅŸan", "gÃ¶revli", "mÃ¼dÃ¼r", "yardÄ±msever", 
            "gÃ¼leryÃ¼zlÃ¼", "kaba", "ilgisiz", "saygÄ±lÄ±", "nazik", "kibar"
        ],
        "POMPACI": [
            "pompacÄ±", "yakÄ±t dolu", "benzin dolu", "motorin dolu",
            "cam sil", "kontrol et", "yaÄŸ kontrol", "su kontrol"
        ],
        "TEMÄ°ZLÄ°K": [
            "temiz", "kirli", "hijyen", "tuvalet", "pis", "bakÄ±m", 
            "tertip", "dÃ¼zen", "leke", "koku"
        ],
        "MARKET": [
            "market", "Ã¼rÃ¼n", "fiyat", "pahalÄ±", "ucuz", "Ã§eÅŸit", 
            "kalite", "taze", "kafe", "restoran"
        ],
        "HIZ": [
            "hÄ±zlÄ±", "yavaÅŸ", "bekleme", "kuyruk", "sÃ¼re", "geÃ§", 
            "Ã§abuk", "acele", "bekle", "zaman"
        ],
        "YAKIT": [
            "benzin", "motorin", "lpg", "yakÄ±t", "pompa", "dolum", 
            "depo", "kalite", "verim"
        ],
        "BANKA_KAMPANYA": [
            "kampanya", "indirim", "kart", "bonus", "puan", "fÄ±rsat",
            "promosyon", "taksit", "Ã¶deme"
        ],
        "GENEL": [
            "genel", "gÃ¼zel", "kÃ¶tÃ¼", "memnun", "beÄŸen", "hoÅŸ",
            "berbat", "sÃ¼per", "harika", "mÃ¼kemmel"
        ]
    }
    
    for category, keywords in category_keywords.items():
        if any(keyword in comment_lower for keyword in keywords):
            categories.append(category)
    
    return categories if categories else ["GENEL"]

# ------------------------------------------------------------
# TLAG SKOR HESAPLAMA
# ------------------------------------------------------------
def calculate_tlag_score(df):
    """TLAG skorunu hesaplar: 5 puan verilen anket sayÄ±sÄ± / toplam anket sayÄ±sÄ±"""
    if "score_5_count" in df.columns and "total_surveys" in df.columns:
        df["TLAG_CALCULATED"] = df["score_5_count"] / df["total_surveys"]
        if "SKOR" not in df.columns:
            df["SKOR"] = df["TLAG_CALCULATED"]
    return df

# ------------------------------------------------------------
# Veri yÃ¼kleme fonksiyonlarÄ±
# ------------------------------------------------------------
def load_tlag_data(uploaded_file):
    """TLAG Excel dosyasÄ±nÄ± yÃ¼kler"""
    try:
        xls = pd.ExcelFile(uploaded_file, engine="openpyxl")
        available_sheets = xls.sheet_names
        
        target_sheet = None
        for sheet in available_sheets:
            if "TLAG" in sheet.upper():
                target_sheet = sheet
                break
        
        if target_sheet is None:
            target_sheet = available_sheets[0]
            st.info(f"TLAG sheet bulunamadÄ±, '{target_sheet}' kullanÄ±lÄ±yor")
        
        df = pd.read_excel(uploaded_file, sheet_name=target_sheet, engine="openpyxl")
        df.columns = df.columns.str.strip()
        
        # Kolon kontrolÃ¼
        required_cols = ["ROC", "Ä°stasyon"]
        if not all(col in df.columns for col in required_cols):
            st.error(f"Gerekli kolonlar bulunamadÄ±. Mevcut: {df.columns.tolist()}")
            return None
        
        df = df.dropna(subset=["ROC", "Ä°stasyon"], how="any")
        
        # Numeric columns
        numeric_columns = ["ROC", "SKOR", "GEÃ‡EN SENE SKOR", "Fark", "TRANSACTION"]
        for col in numeric_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors="coerce")
        
        # Text columns
        text_columns = ["Ä°stasyon", "NOR", "DISTRICT", "Site Segment"]
        for col in text_columns:
            if col in df.columns:
                df[col] = df[col].astype(str).str.strip()
                df[col] = df[col].replace("nan", np.nan)
        
        # ROC normalizasyonu
        df["ROC_STR"] = df["ROC"].apply(lambda x: str(int(x)) if pd.notna(x) else None)
        df["ROC_NORMALIZED"] = df["ROC_STR"].apply(normalize_roc)
        
        # SÄ±ralama ekle
        if "SKOR" in df.columns:
            valid_scores = df["SKOR"].notna()
            df.loc[valid_scores, "SIRALAMA"] = df.loc[valid_scores, "SKOR"].rank(ascending=False, method="min")
            df["SIRALAMA"] = df["SIRALAMA"].apply(lambda x: int(x) if pd.notna(x) else None)
        
        df = calculate_tlag_score(df)
        
        return df
    except Exception as e:
        st.error(f"TLAG dosya okuma hatasÄ±: {str(e)}")
        return None

def load_comments_data(uploaded_file):
    """MÃ¼ÅŸteri yorum dosyasÄ±nÄ± yÃ¼kler"""
    try:
        df = pd.read_excel(uploaded_file, header=1, engine="openpyxl")
        
        df = df[df.iloc[:, 0] != "65000 yorum sÄ±nÄ±rÄ±nÄ± aÅŸtÄ±nÄ±z."]
        df = df[df.iloc[:, 0] != "birim"]
        df = df.dropna(subset=[df.columns[0]], how="all")
        
        column_names = {}
        if len(df.columns) >= 9:
            column_names = {
                df.columns[0]: "station_info",
                df.columns[1]: "survey_item", 
                df.columns[2]: "comment",
                df.columns[3]: "score",
                df.columns[4]: "visit_date",
                df.columns[5]: "hospitality_score",
                df.columns[6]: "dealer",
                df.columns[7]: "territory",
                df.columns[8]: "district"
            }
        
        df = df.rename(columns=column_names)
        
        df["station_code"] = df["station_info"].apply(extract_station_code)
        df["score"] = pd.to_numeric(df["score"], errors="coerce")
        df["categories"] = df["comment"].apply(categorize_comment_enhanced)
        
        df["positive_but_4star"] = df.apply(
            lambda row: (
                row["score"] == 4 and 
                isinstance(row["comment"], str) and
                any(word in str(row["comment"]).lower() for word in 
                    ["gÃ¼zel", "iyi", "memnun", "beÄŸen", "sÃ¼per", "harika"])
            ), axis=1
        )
        
        return df
    except Exception as e:
        st.error(f"Yorum dosyasÄ± okuma hatasÄ±: {str(e)}")
        return None

# ------------------------------------------------------------
# Yorum birleÅŸtirme
# ------------------------------------------------------------
def merge_comments_with_tlag(comments_df, tlag_df):
    """Yorum verilerini TLAG verisi ile birleÅŸtir"""
    try:
        st.write("ğŸ” Yorum verileri birleÅŸtiriliyor...")
        
        merged = pd.merge(
            comments_df,
            tlag_df[["ROC_NORMALIZED", "ROC_STR", "Ä°stasyon", "NOR", "DISTRICT", "Site Segment"]],
            left_on="station_code",
            right_on="ROC_NORMALIZED", 
            how="left"
        )
        
        not_merged = merged[merged["Ä°stasyon"].isna()]
        if not not_merged.empty:
            merged2 = pd.merge(
                not_merged[comments_df.columns],
                tlag_df[["ROC_STR", "Ä°stasyon", "NOR", "DISTRICT", "Site Segment"]],
                left_on="station_code",
                right_on="ROC_STR",
                how="left"
            )
            
            merged_part1 = merged[merged["Ä°stasyon"].notna()]
            merged_part2 = merged2[merged2["Ä°stasyon"].notna()]
            
            if not merged_part2.empty:
                merged_part2["ROC_NORMALIZED"] = merged_part2["ROC_STR"]
                merged = pd.concat([merged_part1, merged_part2], ignore_index=True)
        
        merged["NOR_FINAL"] = merged["NOR"].fillna(merged.get("territory", ""))
        merged["DISTRICT_FINAL"] = merged["DISTRICT"].fillna(merged.get("district", ""))
        
        successful_matches = len(merged[merged["Ä°stasyon"].notna()])
        st.success(f"âœ… {successful_matches}/{len(comments_df)} yorum eÅŸleÅŸtirildi!")
        
        return merged
    except Exception as e:
        st.error(f"Veri birleÅŸtirme hatasÄ±: {str(e)}")
        return comments_df

# ------------------------------------------------------------
# Analiz fonksiyonlarÄ±
# ------------------------------------------------------------
def analyze_comments_by_scope(comments_df, scope_col="DISTRICT"):
    """Yorum analizi"""
    if comments_df is None or comments_df.empty:
        return {}
    
    if scope_col == "DISTRICT":
        group_col = "DISTRICT_FINAL"
    elif scope_col == "NOR":
        group_col = "NOR_FINAL"
    else:
        group_col = scope_col
        
    if group_col not in comments_df.columns:
        return {}
    
    results = {}
    valid_comments = comments_df[comments_df[group_col].notna()]
    
    for name, group in valid_comments.groupby(group_col):
        if pd.isna(name) or str(name).strip() == "":
            continue
            
        total_comments = len(group)
        if total_comments == 0:
            continue
            
        avg_score = group["score"].mean()
        score_dist = group["score"].value_counts().to_dict()
        
        category_counts = {}
        category_scores = {}
        
        for _, row in group.iterrows():
            if isinstance(row.get("categories"), list):
                for cat in row["categories"]:
                    if cat not in category_counts:
                        category_counts[cat] = 0
                        category_scores[cat] = []
                    category_counts[cat] += 1
                    category_scores[cat].append(row["score"])
        
        category_avg_scores = {
            cat: np.mean(scores) for cat, scores in category_scores.items()
        }
        
        problem_categories = {}
        for cat in category_counts:
            if cat in category_avg_scores and category_avg_scores[cat] < 4.0:
                problem_categories[cat] = {
                    "count": category_counts[cat],
                    "avg_score": category_avg_scores[cat]
                }
        
        results[name] = {
            "total_comments": total_comments,
            "avg_score": avg_score,
            "score_distribution": score_dist,
            "category_counts": category_counts,
            "category_avg_scores": category_avg_scores,
            "problem_categories": problem_categories
        }
    
    return results

# ------------------------------------------------------------
# UI FonksiyonlarÄ±
# ------------------------------------------------------------
def display_top_5_lists(df, comments_df=None, scope="Genel"):
    """Top 5 listeler"""
    st.markdown(f"### ğŸ† {scope} - TOP 5 LÄ°STELER")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("#### ğŸ”´ En Ã‡ok Åikayet")
        if comments_df is not None and not comments_df.empty and "Ä°stasyon" in comments_df.columns:
            valid_comments = comments_df[comments_df["Ä°stasyon"].notna()]
            if not valid_comments.empty:
                complaint_counts = valid_comments[valid_comments["score"] <= 3].groupby("Ä°stasyon").size()
                if not complaint_counts.empty:
                    for idx, (station, count) in enumerate(complaint_counts.nlargest(5).items(), 1):
                        st.write(f"{idx}. {station}: **{count}**")
                else:
                    st.info("Åikayet yok")
            else:
                st.info("Veri yok")
        else:
            st.info("Yorum yok")
    
    with col2:
        st.markdown("#### âš ï¸ En KÃ¶tÃ¼ Skor")
        if "SKOR" in df.columns:
            worst = df.nsmallest(5, "SKOR")[["Ä°stasyon", "SKOR"]]
            for idx, (_, row) in enumerate(worst.iterrows(), 1):
                st.write(f"{idx}. {row['Ä°stasyon']}: **{row['SKOR']*100:.1f}%**")
    
    with col3:
        st.markdown("#### âœ… En Ä°yi Skor")
        if "SKOR" in df.columns:
            best = df.nlargest(5, "SKOR")[["Ä°stasyon", "SKOR"]]
            for idx, (_, row) in enumerate(best.iterrows(), 1):
                st.write(f"{idx}. {row['Ä°stasyon']}: **{row['SKOR']*100:.1f}%**")

def display_segment_pie_charts(df):
    """Segment daÄŸÄ±lÄ±mÄ±"""
    st.markdown("### ğŸª SEGMENT DAÄILIMI")
    
    tab1, tab2, tab3 = st.tabs(["ğŸ“Š Genel", "ğŸ¢ District", "ğŸ“ NOR"])
    
    with tab1:
        segment_counts = df["Site Segment"].value_counts()
        fig = px.pie(values=segment_counts.values, names=segment_counts.index,
                    title="Genel Segment DaÄŸÄ±lÄ±mÄ±", hole=0.3)
        st.plotly_chart(fig, use_container_width=True)
        
        selected_segment = st.selectbox("Detay iÃ§in seÃ§in:", segment_counts.index)
        if selected_segment:
            segment_data = df[df["Site Segment"] == selected_segment]
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Ä°stasyon", len(segment_data))
            with col2:
                st.metric("Ort. Skor", f"{segment_data['SKOR'].mean()*100:.1f}%")
            with col3:
                st.metric("Min-Max", f"{segment_data['SKOR'].min()*100:.0f}%-{segment_data['SKOR'].max()*100:.0f}%")
    
    with tab2:
        if "DISTRICT" in df.columns:
            districts = sorted(df["DISTRICT"].dropna().unique())
            selected_district = st.selectbox("District:", districts)
            if selected_district:
                district_data = df[df["DISTRICT"] == selected_district]
                segment_counts = district_data["Site Segment"].value_counts()
                fig = px.pie(values=segment_counts.values, names=segment_counts.index,
                            title=f"{selected_district} Segment DaÄŸÄ±lÄ±mÄ±", hole=0.3)
                st.plotly_chart(fig, use_container_width=True)
    
    with tab3:
        if "NOR" in df.columns:
            nors = sorted(df["NOR"].dropna().unique())
            selected_nor = st.selectbox("NOR:", nors)
            if selected_nor:
                nor_data = df[df["NOR"] == selected_nor]
                segment_counts = nor_data["Site Segment"].value_counts()
                fig = px.pie(values=segment_counts.values, names=segment_counts.index,
                            title=f"{selected_nor} Segment DaÄŸÄ±lÄ±mÄ±", hole=0.3)
                st.plotly_chart(fig, use_container_width=True)

def display_nor_interactive_chart(nor_data, comments_data=None):
    """NOR puan daÄŸÄ±lÄ±mÄ±"""
    st.markdown("### ğŸ“Š PUAN DAÄILIMI")
    
    if comments_data is not None and not comments_data.empty:
        score_counts = comments_data["score"].value_counts().sort_index()
        
        fig = go.Figure()
        colors = {5: '#28a745', 4: '#90EE90', 3: '#ffc107', 2: '#fd7e14', 1: '#dc3545'}
        
        for score in score_counts.index:
            fig.add_trace(go.Bar(
                x=[str(score)],
                y=[score_counts[score]],
                name=f'{score} Puan',
                marker_color=colors.get(score, '#6c757d'),
                text=[f"{score_counts[score]} anket"],
                textposition='auto'
            ))
        
        fig.update_layout(
            title="Puan DaÄŸÄ±lÄ±mÄ±",
            xaxis_title="Puan",
            yaxis_title="Anket SayÄ±sÄ±",
            showlegend=True,
            height=400
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        selected_score = st.selectbox("YorumlarÄ± gÃ¶rmek iÃ§in puan seÃ§in:", [5, 4, 3, 2, 1])
        
        score_comments = comments_data[comments_data["score"] == selected_score]
        if not score_comments.empty:
            st.markdown(f"#### {selected_score} Puan YorumlarÄ± ({len(score_comments)} adet)")
            
            for idx, row in score_comments.head(5).iterrows():
                categories_str = ", ".join(row["categories"]) if isinstance(row.get("categories"), list) else "GENEL"
                st.markdown(f"""
                **Kategoriler:** {categories_str}
                _{row['comment']}_
                ---
                """)

def display_comment_analysis_enhanced(analysis_data, title="Yorum Analizi"):
    """Yorum analizi gÃ¶rÃ¼ntÃ¼leme"""
    if not analysis_data:
        st.info(f"ğŸ“‹ {title} iÃ§in yorum verisi bulunamadÄ±")
        return
    
    st.markdown(f"### ğŸ’¬ {title}")
    
    total_areas = len(analysis_data)
    total_comments = sum(data["total_comments"] for data in analysis_data.values())
    avg_score_overall = np.mean([data["avg_score"] for data in analysis_data.values()])
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Toplam Alan", total_areas)
    with col2:
        st.metric("Toplam Yorum", total_comments)
    with col3:
        st.metric("Ort. Puan", f"{avg_score_overall:.1f}/5")

def get_opportunity_stations(df):
    """FÄ±rsat istasyonlarÄ±"""
    if df is None or df.empty or "SKOR" not in df.columns or "Site Segment" not in df.columns:
        return pd.DataFrame()
    
    return df[(df["Site Segment"].isin(["My Precious", "Primitive"])) & (df["SKOR"] < 0.80)].copy()

def create_enhanced_metric_card(col, title, value, key, click_data=None):
    """Metrik kartÄ±"""
    with col:
        st.markdown(f"""
        <div class="metric-card">
            <h2>{value}</h2>
            <p>{title}</p>
            <small>ğŸ“Š Detay iÃ§in tÄ±klayÄ±n</small>
        </div>
        """, unsafe_allow_html=True)
        
        if st.button("ğŸ“Š Detay", key=f"btn_{key}", use_container_width=True):
            st.session_state[f"show_{key}"] = not st.session_state.get(f"show_{key}", False)

def display_all_stations_detail(df):
    """TÃ¼m istasyonlar detayÄ±"""
    st.markdown("### ğŸ“Š TÃœM Ä°STASYONLAR")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        district_filter = st.selectbox("District:", ["TÃ¼mÃ¼"] + sorted(df["DISTRICT"].dropna().unique().tolist()) if "DISTRICT" in df.columns else ["TÃ¼mÃ¼"])
    with col2:
        nor_filter = st.selectbox("NOR:", ["TÃ¼mÃ¼"] + sorted(df["NOR"].dropna().unique().tolist()) if "NOR" in df.columns else ["TÃ¼mÃ¼"])
    with col3:
        segment_filter = st.selectbox("Segment:", ["TÃ¼mÃ¼"] + sorted(df["Site Segment"].dropna().unique().tolist()) if "Site Segment" in df.columns else ["TÃ¼mÃ¼"])
    
    filtered_df = df.copy()
    if district_filter != "TÃ¼mÃ¼" and "DISTRICT" in df.columns:
        filtered_df = filtered_df[filtered_df["DISTRICT"] == district_filter]
    if nor_filter != "TÃ¼mÃ¼" and "NOR" in df.columns:
        filtered_df = filtered_df[filtered_df["NOR"] == nor_filter]
    if segment_filter != "TÃ¼mÃ¼" and "Site Segment" in df.columns:
        filtered_df = filtered_df[filtered_df["Site Segment"] == segment_filter]
    
    st.metric("FiltrelenmiÅŸ Ä°stasyon SayÄ±sÄ±", len(filtered_df))
    
    display_cols = ["ROC_STR", "Ä°stasyon", "SKOR", "SIRALAMA", "DISTRICT", "NOR", "Site Segment"]
    available_cols = [col for col in display_cols if col in filtered_df.columns]
    
    display_df = filtered_df[available_cols].copy()
    if "SKOR" in display_df.columns:
        display_df["SKOR"] = (display_df["SKOR"] * 100).round(1).astype(str) + "%"
    
    st.dataframe(display_df, use_container_width=True, height=400)

def display_score_improvement_detail(df):
    """Skor iyileÅŸtirme detayÄ±"""
    st.markdown("### ğŸ¯ SKOR Ä°YÄ°LEÅTÄ°RME")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### ğŸ† En YÃ¼ksek Skor")
        if "SKOR" in df.columns:
            top = df.nlargest(5, "SKOR")[["Ä°stasyon", "SKOR"]]
            top["SKOR"] = (top["SKOR"] * 100).round(1).astype(str) + "%"
            st.dataframe(top)
    
    with col2:
        st.markdown("#### âš ï¸ En DÃ¼ÅŸÃ¼k Skor")
        if "SKOR" in df.columns:
            bottom = df.nsmallest(5, "SKOR")[["Ä°stasyon", "SKOR"]]
            bottom["SKOR"] = (bottom["SKOR"] * 100).round(1).astype(str) + "%"
            st.dataframe(bottom)

def save_data_to_supabase(df, comments_df=None):
    """Supabase'e kaydet"""
    if not SUPABASE_ENABLED or supabase is None:
        return False
    
    try:
        if df is not None:
            df_save = df.copy()
            for col in df_save.columns:
                if df_save[col].dtype == 'object':
                    df_save[col] = df_save[col].astype(str)
            
            data = df_save.to_dict('records')
            response = supabase.table('tlag_data').upsert(data).execute()
            st.success("âœ… TLAG verileri kaydedildi")
        
        if comments_df is not None:
            comments_save = comments_df.copy()
            if 'categories' in comments_save.columns:
                comments_save['categories'] = comments_save['categories'].apply(json.dumps)
            
            for col in comments_save.columns:
                if comments_save[col].dtype == 'object':
                    comments_save[col] = comments_save[col].astype(str)
            
            data = comments_save.to_dict('records')
            response = supabase.table('customer_comments').upsert(data).execute()
            st.success("âœ… Yorum verileri kaydedildi")
        
        return True
    except Exception as e:
        st.error(f"KayÄ±t hatasÄ±: {str(e)}")
        return False

def load_data_from_supabase():
    """Supabase'den yÃ¼kle"""
    if not SUPABASE_ENABLED or supabase is None:
        return None, None
    
    try:
        response = supabase.table('tlag_data').select("*").execute()
        tlag_df = pd.DataFrame(response.data) if response.data else None
        
        response = supabase.table('customer_comments').select("*").execute()
        comments_df = pd.DataFrame(response.data) if response.data else None
        
        if comments_df is not None and 'categories' in comments_df.columns:
            comments_df['categories'] = comments_df['categories'].apply(
                lambda x: json.loads(x) if isinstance(x, str) else x
            )
        
        return tlag_df, comments_df
    except Exception as e:
        st.error(f"YÃ¼kleme hatasÄ±: {str(e)}")
        return None, None

# ------------------------------------------------------------
# Sayfa yapÄ±landÄ±rmasÄ±
# ------------------------------------------------------------
st.set_page_config(
    page_title="TLAG Performance Analytics",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    .main-header { 
        font-size: 2.5rem; 
        font-weight: bold; 
        text-align: center;
        background: linear-gradient(90deg, #FF6B6B, #4ECDC4); 
        -webkit-background-clip: text; 
        -webkit-text-fill-color: transparent; 
        margin-bottom: 2rem; 
    }
    .metric-card { 
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
        padding: 1.5rem; 
        border-radius: 15px; 
        color: white; 
        text-align: center; 
        margin: 0.5rem 0;
        box-shadow: 0 8px 32px rgba(0,0,0,0.1); 
        cursor: pointer; 
        transition: transform 0.3s; 
    }
    .metric-card:hover { 
        transform: translateY(-5px); 
    }
    .nav-section {
        background: linear-gradient(135deg, #4ECDC4 0%, #44A08D 100%);
        padding: 1rem;
        border-radius: 15px;
        margin: 1rem 0;
        text-align: center;
    }
    .opportunity-card {
        background: linear-gradient(135deg, #FFA502 0%, #FF6B6B 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Session State
if "tlag_data" not in st.session_state:
    st.session_state.tlag_data = None
if "comments_data" not in st.session_state:
    st.session_state.comments_data = None
if "analyzed_comments" not in st.session_state:
    st.session_state.analyzed_comments = None
if "current_view" not in st.session_state:
    st.session_state.current_view = "main"

# ------------------------------------------------------------
# ANA UYGULAMA
# ------------------------------------------------------------
def main():
    st.markdown('<h1 class="main-header">ğŸ“Š TLAG PERFORMANS ANALÄ°TÄ°K SÄ°STEMÄ°</h1>', unsafe_allow_html=True)
    
    # SAYFA AÃ‡ILDIÄINDA OTOMATÄ°K VERÄ° YÃœKLE
    if "data_loaded" not in st.session_state:
        st.session_state.data_loaded = False
    
    if not st.session_state.data_loaded:
        with st.spinner("Veriler yÃ¼kleniyor..."):
            # Ã–nce Supabase'den dene
            if SUPABASE_ENABLED and supabase:
                tlag_df, comments_df = load_data_from_supabase()
                if tlag_df is not None:
                    st.session_state.tlag_data = tlag_df
                    if comments_df is not None:
                        st.session_state.comments_data = comments_df
                        # Analiz et
                        district_analysis = analyze_comments_by_scope(comments_df, "DISTRICT")
                        nor_analysis = analyze_comments_by_scope(comments_df, "NOR")
                        st.session_state.analyzed_comments = {
                            "district": district_analysis,
                            "nor": nor_analysis
                        }
                    st.session_state.data_loaded = True
            
            # Supabase'de veri yoksa demo yÃ¼kle
            if not st.session_state.data_loaded:
                tlag_df, comments_df, _ = load_demo_data_from_cloud()
                if tlag_df is not None:
                    st.session_state.tlag_data = tlag_df
                    if comments_df is not None:
                        merged_comments = merge_comments_with_tlag(comments_df, tlag_df)
                        st.session_state.comments_data = merged_comments
                        district_analysis = analyze_comments_by_scope(merged_comments, "DISTRICT")
                        nor_analysis = analyze_comments_by_scope(merged_comments, "NOR")
                        st.session_state.analyzed_comments = {
                            "district": district_analysis,
                            "nor": nor_analysis
                        }
                    st.session_state.data_loaded = True
                    # Demo veriyi Supabase'e kaydet
                    if SUPABASE_ENABLED and supabase:
                        save_data_to_supabase(tlag_df, st.session_state.comments_data)
    
    # SIDEBAR - VERÄ° YÃ–NETÄ°MÄ° (GÄ°ZLENEBÄ°LÄ°R)
    with st.sidebar:
        with st.expander("ğŸ” Veri YÃ¶netimi (Admin)", expanded=False):
            st.markdown("### ğŸ“ VERÄ° GÃœNCELLEME")
            
            # Manuel veri yÃ¼kleme
            uploaded_tlag = st.file_uploader("TLAG Excel:", type=["xlsx", "xls"], key="tlag_upload")
            uploaded_comments = st.file_uploader("Yorumlar Excel:", type=["xlsx", "xls"], key="comments_upload")
            
            if uploaded_tlag:
                with st.spinner("TLAG verileri iÅŸleniyor..."):
                    df = load_tlag_data(uploaded_tlag)
                    if df is not None:
                        st.session_state.tlag_data = df
                        st.success(f"âœ… {len(df)} istasyon")
                        save_data_to_supabase(df, None)
            
            if uploaded_comments and st.session_state.tlag_data is not None:
                with st.spinner("Yorumlar iÅŸleniyor..."):
                    comments_df = load_comments_data(uploaded_comments)
                    if comments_df is not None:
                        merged = merge_comments_with_tlag(comments_df, st.session_state.tlag_data)
                        st.session_state.comments_data = merged
                        district_analysis = analyze_comments_by_scope(merged, "DISTRICT")
                        nor_analysis = analyze_comments_by_scope(merged, "NOR")
                        st.session_state.analyzed_comments = {
                            "district": district_analysis,
                            "nor": nor_analysis
                        }
                        st.success(f"âœ… {len(comments_df)} yorum")
                        save_data_to_supabase(None, merged)
            
            # Demo veri butonu
            if st.button("ğŸ”„ Demo Veri YÃ¼kle", use_container_width=True):
                with st.spinner("Demo veriler yÃ¼kleniyor..."):
                    tlag_df, comments_df, message = load_demo_data_from_cloud()
                    if tlag_df is not None:
                        st.session_state.tlag_data = tlag_df
                        if comments_df is not None:
                            merged = merge_comments_with_tlag(comments_df, tlag_df)
                            st.session_state.comments_data = merged
                            district_analysis = analyze_comments_by_scope(merged, "DISTRICT")
                            nor_analysis = analyze_comments_by_scope(merged, "NOR")
                            st.session_state.analyzed_comments = {
                                "district": district_analysis,
                                "nor": nor_analysis
                            }
                        save_data_to_supabase(tlag_df, st.session_state.comments_data)
                        st.success("âœ… Demo veriler yÃ¼klendi")
                        st.rerun()
        
        # KullanÄ±cÄ± bilgisi
        st.markdown("---")
        if st.session_state.get("tlag_data") is not None:
            df = st.session_state.tlag_data
            st.metric("ğŸ“Š Toplam Ä°stasyon", len(df))
            if "SKOR" in df.columns:
                st.metric("ğŸ“ˆ Ort. TLAG", f"{df['SKOR'].mean()*100:.1f}%")
            if st.session_state.get("comments_data") is not None:
                st.metric("ğŸ’¬ Toplam Yorum", len(st.session_state.comments_data))
        
        st.markdown("---")
        st.caption("TLAG Analytics v2.0")
        st.caption("Â© 2024")
    
    # Ana iÃ§erik
    if st.session_state.current_view == "main":
        display_main_dashboard()
    elif st.session_state.current_view == "district":
        display_district_analysis()
    elif st.session_state.current_view == "nor":
        display_nor_analysis()
    elif st.session_state.current_view == "segmentation":
        display_segmentation_analysis()

def display_main_dashboard():
    """Ana dashboard"""
    if st.session_state.tlag_data is None:
        st.markdown("## ğŸ¯ TLAG PERFORMANS ANALÄ°TÄ°K'E HOÅGELDÄ°NÄ°Z")
        st.info("ğŸ‘ˆ Sol panelden Excel dosyalarÄ±nÄ±zÄ± yÃ¼kleyin veya demo verilerini deneyin")
        return
    
    df = st.session_state.tlag_data
    
    # AI Chat Box
    ai_chat_interface(df, st.session_state.get("comments_data"))
    
    # Ana metrikler
    st.markdown("## ğŸ“Š ANA METRÄ°KLER")
    col1, col2, col3, col4 = st.columns(4)
    
    create_enhanced_metric_card(col1, "Toplam Ä°stasyon", len(df), "total_stations", df)
    
    if "SKOR" in df.columns:
        avg_score = df["SKOR"].mean() * 100
        create_enhanced_metric_card(col2, "Ortalama Skor", f"{avg_score:.1f}%", "avg_score", df)
    
    if "Site Segment" in df.columns:
        segments = df["Site Segment"].value_counts()
        with col3:
            if len(segments) > 0:
                st.metric(segments.index[0], segments.iloc[0])
        with col4:
            if len(segments) > 1:
                st.metric(segments.index[1], segments.iloc[1])
    
    # Detay gÃ¶sterimleri
    if st.session_state.get("show_total_stations", False):
        display_all_stations_detail(df)
    
    if st.session_state.get("show_avg_score", False):
        display_score_improvement_detail(df)
    
    # Segment pie chart
    if "Site Segment" in df.columns:
        display_segment_pie_charts(df)
    
    # District performans
    if "DISTRICT" in df.columns and "SKOR" in df.columns:
        st.markdown("## ğŸ“ˆ DISTRICT PERFORMANS")
        
        district_performance = df.groupby("DISTRICT").agg({
            "SKOR": "mean",
            "Ä°stasyon": "count"
        }).reset_index()
        
        district_performance["SKOR_FORMAT"] = (district_performance["SKOR"] * 100).round(1).astype(str) + "%"
        district_performance = district_performance.sort_values("SKOR", ascending=False)
        
        fig = px.bar(district_performance, x="DISTRICT", y="Ä°stasyon",
                    text="SKOR_FORMAT", title="District PerformanslarÄ±")
        fig.update_traces(textposition='outside')
        st.plotly_chart(fig, use_container_width=True)
    
    # Top 5 listeler
    display_top_5_lists(df, st.session_state.get("comments_data"))
    
    # FÄ±rsat istasyonlarÄ±
    opportunity_stations = get_opportunity_stations(df)
    if not opportunity_stations.empty:
        st.markdown("## ğŸ¯ FIRSAT Ä°STASYONLARI")
        st.markdown(f"**{len(opportunity_stations)} fÄ±rsat istasyonu** (My Precious/Primitive, <80% skor)")
        
        for idx, (_, station) in enumerate(opportunity_stations.head(5).iterrows(), 1):
            current_score = station["SKOR"] * 100
            st.markdown(f"""
            <div class="opportunity-card">
                <strong>{idx}. {station['Ä°stasyon']}</strong><br>
                Mevcut: {current_score:.1f}% â†’ Hedef: 80%<br>
                <small>{station.get('DISTRICT', '')} | {station['Site Segment']}</small>
            </div>
            """, unsafe_allow_html=True)
    
    # Navigasyon
    st.markdown("## ğŸ¯ ANALÄ°Z SEÃ‡ENEKLERÄ°")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown('<div class="nav-section"><h3>ğŸ¢ DISTRICT</h3></div>', unsafe_allow_html=True)
        if st.button("District Analizi", key="nav_district", use_container_width=True):
            st.session_state.current_view = "district"
            st.rerun()
    
    with col2:
        st.markdown('<div class="nav-section"><h3>ğŸ“ NOR</h3></div>', unsafe_allow_html=True)
        if st.button("NOR Analizi", key="nav_nor", use_container_width=True):
            st.session_state.current_view = "nor"
            st.rerun()
    
    with col3:
        st.markdown('<div class="nav-section"><h3>ğŸª SEGMENTASYON</h3></div>', unsafe_allow_html=True)
        if st.button("Segmentasyon", key="nav_segmentation", use_container_width=True):
            st.session_state.current_view = "segmentation"
            st.rerun()

def display_district_analysis():
    """District analizi"""
    if st.button("ğŸ  Ana Sayfa"):
        st.session_state.current_view = "main"
        st.rerun()
    
    st.markdown("## ğŸ¢ DISTRICT ANALÄ°ZÄ°")
    
    df = st.session_state.tlag_data
    if df is None or "DISTRICT" not in df.columns:
        st.error("District verisi yok")
        return
    
    districts = sorted(df["DISTRICT"].dropna().unique())
    selected_district = st.selectbox("District:", districts)
    
    if selected_district:
        district_data = df[df["DISTRICT"] == selected_district].copy()
        
        # District yorumlarÄ± filtrele
        district_comments = None
        if st.session_state.get("comments_data") is not None:
            district_comments = st.session_state.comments_data[
                st.session_state.comments_data.get("DISTRICT_FINAL", "") == selected_district
            ] if "DISTRICT_FINAL" in st.session_state.comments_data.columns else None
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Ä°stasyon", len(district_data))
        with col2:
            if "SKOR" in district_data.columns:
                st.metric("Ort. Skor", f"{district_data['SKOR'].mean()*100:.1f}%")
        with col3:
            if "Site Segment" in district_data.columns:
                st.metric("Segment", district_data["Site Segment"].nunique())
        with col4:
            opportunity_count = len(get_opportunity_stations(district_data))
            st.metric("FÄ±rsat", opportunity_count)
        
        display_top_5_lists(district_data, district_comments, selected_district)
        
        # AI Ã–neriler - GeliÅŸtirilmiÅŸ
        st.markdown("### ğŸ¤– AI ANALÄ°ZÄ° VE Ã–NERÄ°LER")
        
        col1, col2 = st.columns([3, 1])
        with col1:
            ai_query = st.text_input(
                "Analiz sorunuz:",
                placeholder=f"{selected_district} iÃ§in Ã¶zel soru yazÄ±n veya hazÄ±r konulardan seÃ§in",
                key="district_ai_query"
            )
        
        with col2:
            ai_topics = [
                "TLAG skorunu hÄ±zlÄ± artÄ±rma",
                "En dÃ¼ÅŸÃ¼k skorlu istasyonlar",
                "MÃ¼ÅŸteri ÅŸikayetleri analizi",
                "Personel performansÄ±",
                "Temizlik standartlarÄ±",
                "Market optimizasyonu"
            ]
            selected_topic = st.selectbox("HazÄ±r konular:", [""] + ai_topics, key="district_topic")
        
        if st.button(f"ğŸ¤– Analiz Et", key="district_ai_btn"):
            # EÄŸer hazÄ±r konu seÃ§ildiyse onu kullan, yoksa custom query
            final_query = ai_query if ai_query else f"{selected_district} bÃ¶lgesi iÃ§in {selected_topic}"
            
            if final_query and final_query != f"{selected_district} bÃ¶lgesi iÃ§in ":
                with st.spinner("Veriler analiz ediliyor..."):
                    # GerÃ§ek veri ile AI analizi
                    result = get_ai_response(
                        f"{selected_district} district {final_query}",
                        district_data,
                        district_comments
                    )
                    
                    # Sonucu gÃ¶ster
                    st.markdown("#### ğŸ“Š AI Analiz Sonucu:")
                    st.info(result)
                    
                    # Analiz edilen veri Ã¶zeti
                    with st.expander("ğŸ“ˆ Analiz Edilen Veri DetaylarÄ±"):
                        st.write(f"- Ä°stasyon sayÄ±sÄ±: {len(district_data)}")
                        st.write(f"- Ortalama skor: {district_data['SKOR'].mean()*100:.2f}%")
                        if district_comments is not None:
                            st.write(f"- Yorum sayÄ±sÄ±: {len(district_comments)}")
                            st.write(f"- Ortalama yorum puanÄ±: {district_comments['score'].mean():.2f}/5")
            else:
                st.warning("LÃ¼tfen bir soru yazÄ±n veya konu seÃ§in")

def display_nor_analysis():
    """NOR analizi"""
    if st.button("ğŸ  Ana Sayfa"):
        st.session_state.current_view = "main"
        st.rerun()
    
    st.markdown("## ğŸ“ NOR ANALÄ°ZÄ°")
    
    df = st.session_state.tlag_data
    if df is None or "NOR" not in df.columns:
        st.error("NOR verisi yok")
        return
    
    nors = sorted(df["NOR"].dropna().unique())
    selected_nor = st.selectbox("NOR:", nors)
    
    if selected_nor:
        nor_data = df[df["NOR"] == selected_nor].copy()
        
        # NOR yorumlarÄ± filtrele
        nor_comments = None
        if st.session_state.get("comments_data") is not None:
            nor_comments = st.session_state.comments_data[
                st.session_state.comments_data.get("NOR_FINAL", "") == selected_nor
            ] if "NOR_FINAL" in st.session_state.comments_data.columns else None
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Ä°stasyon", len(nor_data))
        with col2:
            if "SKOR" in nor_data.columns:
                st.metric("Ort. Skor", f"{nor_data['SKOR'].mean()*100:.1f}%")
        with col3:
            if nor_comments is not None:
                st.metric("Yorum", len(nor_comments))
            else:
                st.metric("Yorum", 0)
        with col4:
            opportunity_count = len(get_opportunity_stations(nor_data))
            st.metric("FÄ±rsat", opportunity_count)
        
        # Ä°nteraktif chart
        if nor_comments is not None:
            display_nor_interactive_chart(nor_data, nor_comments)
        
        # Top 5 listeler
        display_top_5_lists(nor_data, nor_comments, selected_nor)
        
        # Ä°stasyon detayÄ±
        st.markdown("### ğŸ“Š Ä°STASYON DETAYI")
        selected_station = st.selectbox("Ä°stasyon:", nor_data["Ä°stasyon"].tolist())
        
        if selected_station:
            station_data = nor_data[nor_data["Ä°stasyon"] == selected_station].iloc[0]
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Skor", f"{station_data['SKOR']*100:.1f}%")
                if "SIRALAMA" in station_data and pd.notna(station_data["SIRALAMA"]):
                    st.markdown(f"### ğŸ† Genel SÄ±ralama: **{int(station_data['SIRALAMA'])}**")
            with col2:
                st.metric("Segment", station_data.get("Site Segment", "N/A"))
            with col3:
                if "TRANSACTION" in station_data and pd.notna(station_data["TRANSACTION"]):
                    st.metric("Transaction", f"{station_data['TRANSACTION']:,.0f}")
            
            # Ä°stasyon yorumlarÄ±
            if nor_comments is not None:
                station_code = station_data.get("ROC_NORMALIZED") or station_data.get("ROC_STR")
                station_comments = nor_comments[nor_comments.get("station_code", "") == str(station_code)]
                
                if not station_comments.empty:
                    st.markdown("#### ğŸ’¬ Ä°stasyon YorumlarÄ±")
                    st.write(f"Toplam {len(station_comments)} yorum, Ortalama: {station_comments['score'].mean():.1f}/5")
                    
                    # Kategori Ã¶zeti
                    category_summary = {}
                    for _, row in station_comments.iterrows():
                        if isinstance(row.get("categories"), list):
                            for cat in row["categories"]:
                                if cat not in category_summary:
                                    category_summary[cat] = {"count": 0, "total": 0}
                                category_summary[cat]["count"] += 1
                                category_summary[cat]["total"] += row["score"]
                    
                    if category_summary:
                        st.write("**Problem Kategorileri:**")
                        for cat, data in sorted(category_summary.items(), 
                                               key=lambda x: x[1]["total"]/x[1]["count"]):
                            avg = data["total"] / data["count"]
                            if avg < 4.0:
                                st.write(f"- {cat}: {data['count']} yorum, Ort: {avg:.1f}/5 âš ï¸")
        
        # AI Ã–neriler - GeliÅŸtirilmiÅŸ
        st.markdown("### ğŸ¤– AI ANALÄ°ZÄ° VE Ã–NERÄ°LER")
        
        col1, col2 = st.columns([3, 1])
        with col1:
            ai_query = st.text_input(
                "Analiz sorunuz:",
                placeholder=f"{selected_nor} iÃ§in Ã¶zel soru yazÄ±n veya hazÄ±r konulardan seÃ§in",
                key="nor_ai_query"
            )
        
        with col2:
            ai_topics = [
                "TLAG skorunu en hÄ±zlÄ± artÄ±rma yollarÄ±",
                "En problemli istasyonlar ve Ã§Ã¶zÃ¼mler",
                "MÃ¼ÅŸteri ÅŸikayetleri analizi",
                "Kategori bazlÄ± iyileÅŸtirmeler",
                "FÄ±rsat istasyonlarÄ± stratejisi"
            ]
            selected_topic = st.selectbox("HazÄ±r konular:", [""] + ai_topics, key="nor_topic")
        
        if st.button(f"ğŸ¤– Analiz Et", key="nor_ai_btn"):
            # EÄŸer hazÄ±r konu seÃ§ildiyse onu kullan, yoksa custom query
            final_query = ai_query if ai_query else f"{selected_nor} iÃ§in {selected_topic}"
            
            if final_query and final_query != f"{selected_nor} iÃ§in ":
                with st.spinner("GerÃ§ek veriler analiz ediliyor..."):
                    # GerÃ§ek veri ile AI analizi
                    result = get_ai_response(
                        f"{selected_nor} NOR {final_query}",
                        nor_data,
                        nor_comments
                    )
                    
                    # Sonucu gÃ¶ster
                    st.markdown("#### ğŸ“Š AI Analiz Sonucu:")
                    st.success(result)
                    
                    # Analiz edilen veri Ã¶zeti
                    with st.expander("ğŸ“ˆ Analiz Edilen Veri DetaylarÄ±"):
                        col1, col2 = st.columns(2)
                        with col1:
                            st.write(f"**Ä°stasyon Verileri:**")
                            st.write(f"- Toplam: {len(nor_data)} istasyon")
                            st.write(f"- Ort. skor: {nor_data['SKOR'].mean()*100:.2f}%")
                            st.write(f"- Min skor: {nor_data['SKOR'].min()*100:.2f}%")
                            st.write(f"- Max skor: {nor_data['SKOR'].max()*100:.2f}%")
                        with col2:
                            if nor_comments is not None:
                                st.write(f"**Yorum Verileri:**")
                                st.write(f"- Toplam: {len(nor_comments)} yorum")
                                st.write(f"- Ort. puan: {nor_comments['score'].mean():.2f}/5")
                                st.write(f"- 5 puan: {len(nor_comments[nor_comments['score']==5])}")
                                st.write(f"- 1-2 puan: {len(nor_comments[nor_comments['score']<=2])}")
            else:
                st.warning("LÃ¼tfen bir soru yazÄ±n veya konu seÃ§in")

def display_segmentation_analysis():
    """Segmentasyon analizi"""
    if st.button("ğŸ  Ana Sayfa"):
        st.session_state.current_view = "main"
        st.rerun()
    
    st.markdown("## ğŸª SEGMENTASYON ANALÄ°ZÄ°")
    
    df = st.session_state.tlag_data
    if df is None or "Site Segment" not in df.columns:
        st.error("Segment verisi yok")
        return
    
    segment_summary = df.groupby("Site Segment").agg({
        "Ä°stasyon": "count",
        "SKOR": ["mean", "min", "max"] if "SKOR" in df.columns else ["count"]
    }).round(3)
    
    st.dataframe(segment_summary, use_container_width=True)
    
    selected_segment = st.selectbox("Segment:", df["Site Segment"].unique())
    
    if selected_segment:
        segment_data = df[df["Site Segment"] == selected_segment]
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### ğŸ† En Ä°yi 5")
            if "SKOR" in segment_data.columns:
                top5 = segment_data.nlargest(5, "SKOR")[["Ä°stasyon", "SKOR"]]
                top5["SKOR"] = (top5["SKOR"] * 100).round(1).astype(str) + "%"
                st.dataframe(top5)
        
        with col2:
            st.markdown("#### âš ï¸ En KÃ¶tÃ¼ 5")
            if "SKOR" in segment_data.columns:
                bottom5 = segment_data.nsmallest(5, "SKOR")[["Ä°stasyon", "SKOR"]]
                bottom5["SKOR"] = (bottom5["SKOR"] * 100).round(1).astype(str) + "%"
                st.dataframe(bottom5)

if __name__ == "__main__":
    main()