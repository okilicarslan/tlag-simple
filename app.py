import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
import re
from datetime import datetime
import io

# Enterprise page configuration
st.set_page_config(
    page_title="TLAG Enterprise Analytics",
    page_icon="üöÄ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Advanced CSS
st.markdown("""
<style>
    .enterprise-header {
        font-size: clamp(2rem, 6vw, 4rem);
        font-weight: bold;
        text-align: center;
        background: linear-gradient(90deg, #FF6B6B, #4ECDC4, #45B7D1);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 2rem;
    }
    .insight-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 15px;
        color: white;
        margin: 1rem 0;
        box-shadow: 0 8px 32px rgba(0,0,0,0.1);
    }
    .action-card {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        padding: 1.5rem;
        border-radius: 15px;
        color: white;
        margin: 1rem 0;
        box-shadow: 0 8px 32px rgba(0,0,0,0.1);
    }
    .improvement-card {
        background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%);
        padding: 1.5rem;
        border-radius: 15px;
        color: #2c3e50;
        margin: 1rem 0;
        box-shadow: 0 8px 32px rgba(0,0,0,0.1);
    }
    .metric-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
        gap: 1rem;
        margin: 1rem 0;
    }
    .priority-high { border-left: 5px solid #e74c3c; }
    .priority-medium { border-left: 5px solid #f39c12; }
    .priority-low { border-left: 5px solid #27ae60; }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'tlag_data' not in st.session_state:
    st.session_state.tlag_data = None
if 'comment_data' not in st.session_state:
    st.session_state.comment_data = None

def load_real_tlag_data(uploaded_file):
    """Load real TLAG Excel data"""
    try:
        # Try to read the Excel file with the exact sheet name
        df = pd.read_excel(uploaded_file, sheet_name="TLAG DOKUNMA (2)")
        
        # Clean column names
        df.columns = df.columns.str.strip()
        
        # Remove completely empty rows
        df = df.dropna(subset=['ROC', 'ƒ∞stasyon'])
        
        # Convert numeric columns properly
        numeric_columns = ['ROC', 'NOR HEDEF', 'DISTRICT HEDEF', 'SKOR', 'GE√áEN SENE SKOR', 'Fark', 'Ge√ßerli', 'TRANSACTION']
        
        for col in numeric_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # Clean text columns
        text_columns = ['ƒ∞stasyon', 'NOR', 'DISTRICT', 'Site Segment']
        for col in text_columns:
            if col in df.columns:
                df[col] = df[col].astype(str).str.strip()
        
        # Remove any rows where all key values are NaN
        df = df.dropna(subset=['SKOR'], how='all')
        
        return df
    
    except Exception as e:
        st.error(f"Excel dosyasƒ± okuma hatasƒ±: {str(e)}")
        st.info("Sheet ismi 'TLAG DOKUNMA (2)' olmalƒ± ve dosya .xlsx formatƒ±nda olmalƒ±")
        return None

def analyze_comment_sentiment(comment):
    """Simple sentiment analysis for Turkish comments"""
    if pd.isna(comment):
        return 0, []
    
    comment = str(comment).lower()
    
    # Positive keywords
    positive_words = [
        'iyi', 'g√ºzel', 'm√ºkemmel', 'harika', 'temiz', 'hƒ±zlƒ±', 'kaliteli', 
        'yardƒ±msever', 'g√ºlery√ºzl√º', 'ba≈üarƒ±lƒ±', 'kolay', 'rahat', 'uygun'
    ]
    
    # Negative keywords
    negative_words = [
        'k√∂t√º', 'berbat', 'kirli', 'yava≈ü', 'pahalƒ±', 'kaba', 'ilgisiz', 
        'sorunlu', 'bozuk', 'eksik', 'ge√ß', 'uzun', 'zor', 'memnun deƒüil'
    ]
    
    # Category keywords
    category_keywords = {
        'Temizlik': ['temiz', 'kirli', 'hijyen', 'tuvalet', 'pis', 'bakƒ±m'],
        'Personel': ['personel', '√ßalƒ±≈üan', 'pompacƒ±', 'kasiyer', 'yardƒ±msever', 'kaba', 'ilgisiz'],
        'Market': ['market', '√ºr√ºn', 'fiyat', '√ße≈üit', 'kalite', 'taze', 'pahalƒ±'],
        'Hƒ±z': ['hƒ±zlƒ±', 'yava≈ü', 'bekleme', 'kuyruk', 's√ºre', 'ge√ß'],
        'Genel': ['genel', 't√ºm', 'her ≈üey', 'istasyon', 'benzinlik']
    }
    
    positive_score = sum(1 for word in positive_words if word in comment)
    negative_score = sum(1 for word in negative_words if word in comment)
    
    sentiment_score = positive_score - negative_score
    
    # Detect categories mentioned
    mentioned_categories = []
    for category, keywords in category_keywords.items():
        if any(keyword in comment for keyword in keywords):
            mentioned_categories.append(category)
    
    return sentiment_score, mentioned_categories

def analyze_station_performance(df, station_name):
    """Detailed station analysis using REAL data"""
    station_data = df[df['ƒ∞stasyon'] == station_name].iloc[0]
    
    analysis = {
        'current_score': station_data['SKOR'],
        'previous_score': station_data.get('GE√áEN SENE SKOR', 0),
        'improvement': station_data.get('Fark', 0),
        'segment': station_data.get('Site Segment', 'Unknown'),
        'district': station_data['DISTRICT'],
        'transaction_volume': station_data.get('TRANSACTION', 0),
        'nor': station_data.get('NOR', 'Unknown'),
        'roc': station_data.get('ROC', 0)
    }
    
    # Performance categorization
    if analysis['current_score'] >= 0.8:
        analysis['performance_category'] = 'Excellent'
        analysis['category_color'] = '#27ae60'
    elif analysis['current_score'] >= 0.7:
        analysis['performance_category'] = 'Good'
        analysis['category_color'] = '#f39c12'
    elif analysis['current_score'] >= 0.6:
        analysis['performance_category'] = 'Average'
        analysis['category_color'] = '#e67e22'
    else:
        analysis['performance_category'] = 'Needs Improvement'
        analysis['category_color'] = '#e74c3c'
    
    return analysis

def generate_improvement_recommendations(station_analysis, comment_analysis=None):
    """Generate actionable improvement recommendations based on REAL data"""
    recommendations = []
    
    current_score = station_analysis['current_score']
    improvement = station_analysis['improvement']
    segment = station_analysis['segment']
    
    # Critical performance recommendations
    if current_score < 0.5:
        recommendations.append({
            'priority': 'HIGH',
            'category': 'Kritik Durum',
            'action': f'Bu istasyon kritik durumda (Skor: {current_score:.3f}). Acil operasyon review gerekli.',
            'expected_impact': '+20-30 puan',
            'timeframe': '1 hafta'
        })
    
    # Trend-based recommendations
    if improvement < -5:
        recommendations.append({
            'priority': 'HIGH',
            'category': 'Negatif Trend',
            'action': f'Performans {improvement:.1f} puan d√º≈üm√º≈ü. Trend analizi ve d√ºzeltici eylem gerekli.',
            'expected_impact': '+10-15 puan',
            'timeframe': '2 hafta'
        })
    elif improvement > 10:
        recommendations.append({
            'priority': 'LOW',
            'category': 'Pozitif Momentum',
            'action': f'Performans {improvement:.1f} puan y√ºkselmi≈ü. Bu trendi s√ºrd√ºrmek i√ßin best practices belgelenebilir.',
            'expected_impact': 'S√ºrd√ºr√ºlebilirlik',
            'timeframe': 'Devam eden'
        })
    
    # Segment-based recommendations
    if segment == 'Saboteur':
        recommendations.append({
            'priority': 'HIGH',
            'category': 'Segment Recovery',
            'action': 'Saboteur segmentinden √ßƒ±kƒ±≈ü i√ßin kapsamlƒ± operasyon planƒ± gerekli. T√ºm s√ºre√ßleri g√∂zden ge√ßirin.',
            'expected_impact': '+15-25 puan',
            'timeframe': '3-4 hafta'
        })
    elif segment == 'Primitive':
        recommendations.append({
            'priority': 'MEDIUM',
            'category': 'Basic Improvements',
            'action': 'Temel operasyon standartlarƒ±nƒ± y√ºkseltin. Personel eƒüitimi ve ekipman iyile≈ütirmesi.',
            'expected_impact': '+10-15 puan',
            'timeframe': '2-3 hafta'
        })
    elif segment == 'Wasted Talent':
        recommendations.append({
            'priority': 'MEDIUM',
            'category': 'Potential Unlock',
            'action': 'Bu istasyonun potansiyeli var. Engelleri tespit edip √ß√∂z√ºmleyin.',
            'expected_impact': '+8-12 puan',
            'timeframe': '2-3 hafta'
        })
    
    # Score-based recommendations
    if 0.5 <= current_score < 0.7:
        recommendations.append({
            'priority': 'MEDIUM',
            'category': 'Performance Boost',
            'action': 'Ortalama performansƒ± iyile≈ütirmek i√ßin operasyon verimliliƒüi artƒ±rƒ±lmalƒ±.',
            'expected_impact': '+5-10 puan',
            'timeframe': '2-3 hafta'
        })
    
    # Comment-based recommendations (if available)
    if comment_analysis:
        negative_categories = [cat for cat, score in comment_analysis.get('category_scores', {}).items() if score < -1]
        
        for category in negative_categories:
            if category == 'Temizlik':
                recommendations.append({
                    'priority': 'HIGH',
                    'category': 'Temizlik',
                    'action': 'M√º≈üteri yorumlarƒ±nda temizlik sorunu tespit edildi. Temizlik protokollerini artƒ±rƒ±n.',
                    'expected_impact': '+8-12 puan',
                    'timeframe': '1-2 hafta'
                })
            elif category == 'Personel':
                recommendations.append({
                    'priority': 'HIGH',
                    'category': 'Personel',
                    'action': 'Personel davranƒ±≈ülarƒ± konusunda ≈üikayetler var. M√º≈üteri hizmetleri eƒüitimi gerekli.',
                    'expected_impact': '+10-15 puan',
                    'timeframe': '2-3 hafta'
                })
    
    return recommendations[:4]  # Top 4 recommendations

def main():
    # Enterprise header
    st.markdown('<h1 class="enterprise-header">üöÄ TLAG ENTERPRISE ANALYTICS</h1>', 
                unsafe_allow_html=True)
    
    # File upload system
    st.sidebar.markdown("## üìÅ DATA MANAGEMENT CENTER")
    
    # Performance data upload
    st.sidebar.markdown("### üìä TLAG Performans Verisi")
    perf_file = st.sidebar.file_uploader(
        "Excel dosyasƒ± y√ºkleyin:",
        type=['xlsx', 'xls'],
        help="satis_veri_clean.xlsx dosyasƒ±nƒ± se√ßin"
    )
    
    # Comment data upload
    st.sidebar.markdown("### üí¨ M√º≈üteri Yorumlarƒ± (Opsiyonel)")
    comment_file = st.sidebar.file_uploader(
        "Yorum dosyasƒ±:",
        type=['xlsx', 'xls', 'csv'],
        help="ƒ∞stasyon-yorum e≈üle≈ütirmeli dosya"
    )
    
    # Process uploaded performance file
    if perf_file:
        with st.spinner("üìä TLAG verisi i≈üleniyor..."):
            df = load_real_tlag_data(perf_file)
            if df is not None:
                st.session_state.tlag_data = df
                st.sidebar.success(f"‚úÖ {len(df)} ger√ßek istasyon verisi y√ºklendi!")
                
                # Show data summary
                with st.sidebar.expander("üìã Veri √ñzeti"):
                    st.write(f"**ƒ∞stasyon Sayƒ±sƒ±:** {len(df)}")
                    st.write(f"**Ortalama Skor:** {df['SKOR'].mean():.3f}")
                    st.write(f"**En D√º≈ü√ºk:** {df['SKOR'].min():.3f}")
                    st.write(f"**En Y√ºksek:** {df['SKOR'].max():.3f}")
                    
                    # Segment distribution
                    if 'Site Segment' in df.columns:
                        segments = df['Site Segment'].value_counts()
                        for segment, count in segments.items():
                            st.write(f"**{segment}:** {count}")
    
    # Process comment file
    if comment_file:
        try:
            if comment_file.name.endswith('.csv'):
                comment_df = pd.read_csv(comment_file)
            else:
                comment_df = pd.read_excel(comment_file)
            st.session_state.comment_data = comment_df
            st.sidebar.success(f"‚úÖ {len(comment_df)} yorum y√ºklendi!")
        except Exception as e:
            st.sidebar.error(f"Yorum dosyasƒ± hatasƒ±: {str(e)}")
    
    # Main dashboard
    if st.session_state.tlag_data is not None:
        df = st.session_state.tlag_data
        
        # Analysis mode selection
        st.markdown("## üéØ ANALƒ∞Z MODU SE√áƒ∞Mƒ∞")
        
        analysis_mode = st.selectbox(
            "Analiz t√ºr√ºn√º se√ßin:",
            ["üìä Genel Dashboard", "üîç ƒ∞stasyon Detay Analizi", "üí¨ Yorum Analiz Merkezi", "ü§ñ AI √ñneriler Sistemi"]
        )
        
        if analysis_mode == "üìä Genel Dashboard":
            # Real data metrics
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Toplam ƒ∞stasyon", len(df))
            with col2:
                avg_score = df['SKOR'].mean()
                st.metric("Ortalama Skor", f"{avg_score:.3f}")
            with col3:
                if 'Site Segment' in df.columns and not df['Site Segment'].isna().all():
                    critical_stations = len(df[df['Site Segment'].isin(['Saboteur', 'Primitive'])])
                    st.metric("Kritik ƒ∞stasyon", critical_stations)
                else:
                    low_performance = len(df[df['SKOR'] < 0.6])
                    st.metric("D√º≈ü√ºk Performans (<0.6)", low_performance)
            with col4:
                if 'Fark' in df.columns:
                    improving = len(df[df['Fark'] > 0])
                    st.metric("Geli≈üen ƒ∞stasyon", improving)
                else:
                    high_performance = len(df[df['SKOR'] >= 0.8])
                    st.metric("Y√ºksek Performans (‚â•0.8)", high_performance)
            
            # District performance analysis
            st.markdown("## üó∫Ô∏è B√ñLGESEL PERFORMANS ANALƒ∞Zƒ∞")
            
            if 'DISTRICT' in df.columns:
                district_stats = df.groupby('DISTRICT').agg({
                    'SKOR': ['mean', 'count', 'min', 'max'],
                    'Fark': 'mean' if 'Fark' in df.columns else lambda x: 0
                }).round(3)
                
                district_stats.columns = ['Ortalama_Skor', 'ƒ∞stasyon_Sayƒ±sƒ±', 'Min_Skor', 'Max_Skor', 'Ortalama_Deƒüi≈üim']
                district_stats = district_stats.reset_index()
                
                # District performance chart
                fig_district = px.bar(
                    district_stats, 
                    x='DISTRICT', 
                    y='Ortalama_Skor',
                    color='Ortalama_Skor',
                    title="B√∂lgelere G√∂re Ortalama Performans",
                    color_continuous_scale='RdYlGn'
                )
                fig_district.update_xaxis(tickangle=45)
                st.plotly_chart(fig_district, use_container_width=True)
                
                # District summary table
                st.markdown("### üìä B√∂lgesel √ñzet Tablosu")
                st.dataframe(district_stats, use_container_width=True)
            
            # Top and bottom performers
            st.markdown("## üèÜ EN ƒ∞Yƒ∞ VE EN K√ñT√ú PERFORMANSLAR")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("### ü•á En ƒ∞yi 10 ƒ∞stasyon")
                top_performers = df.nlargest(10, 'SKOR')[['ƒ∞stasyon', 'SKOR', 'DISTRICT', 'NOR']]
                st.dataframe(top_performers.round(3))
            
            with col2:
                st.markdown("### ‚ö†Ô∏è En D√º≈ü√ºk 10 Performans")
                bottom_performers = df.nsmallest(10, 'SKOR')[['ƒ∞stasyon', 'SKOR', 'DISTRICT', 'NOR']]
                st.dataframe(bottom_performers.round(3))
        
        elif analysis_mode == "üîç ƒ∞stasyon Detay Analizi":
            st.markdown("## üîç ƒ∞STASYON DETAY ANALƒ∞Z MERKEZƒ∞")
            
            # Station selection with search
            station_list = sorted(df['ƒ∞stasyon'].unique())
            
            # Search box for stations
            search_term = st.text_input("üîç ƒ∞stasyon ara:", placeholder="ƒ∞stasyon adƒ±nƒ±n bir kƒ±smƒ±nƒ± yazƒ±n")
            
            if search_term:
                filtered_stations = [s for s in station_list if search_term.lower() in s.lower()]
                if filtered_stations:
                    selected_station = st.selectbox("ƒ∞stasyon se√ßin:", filtered_stations)
                else:
                    st.warning(f"'{search_term}' ile e≈üle≈üen istasyon bulunamadƒ±.")
                    selected_station = st.selectbox("T√ºm istasyonlar:", station_list)
            else:
                selected_station = st.selectbox("ƒ∞stasyon se√ßin:", station_list)
            
            if selected_station:
                # Station performance analysis
                station_analysis = analyze_station_performance(df, selected_station)
                
                # Station header
                col1, col2, col3 = st.columns([2, 1, 1])
                
                with col1:
                    st.markdown(f"### üè¢ {selected_station}")
                    st.markdown(f"**ROC:** {station_analysis['roc']}")
                    st.markdown(f"**B√∂lge:** {station_analysis['district']}")
                    st.markdown(f"**NOR:** {station_analysis['nor']}")
                    st.markdown(f"**Segment:** {station_analysis['segment']}")
                
                with col2:
                    current_score = station_analysis['current_score']
                    previous_score = station_analysis['previous_score']
                    change = current_score - previous_score
                    
                    st.metric(
                        "Mevcut Skor",
                        f"{current_score:.3f}",
                        delta=f"{change:.3f}"
                    )
                    
                    st.metric(
                        "Ge√ßen Yƒ±l Skor", 
                        f"{previous_score:.3f}"
                    )
                
                with col3:
                    st.markdown(f"""
                    <div style="
                        background-color: {station_analysis['category_color']};
                        color: white;
                        padding: 1rem;
                        border-radius: 10px;
                        text-align: center;
                        font-weight: bold;
                    ">
                        {station_analysis['performance_category']}
                    </div>
                    """, unsafe_allow_html=True)
                
                # Performance comparison chart
                st.markdown("### üìà PERFORMANS KAR≈ûILA≈ûTIRMASI")
                
                comparison_data = {
                    'Metrik': ['Mevcut Skor', 'Ge√ßen Yƒ±l', 'B√∂lge Ortalamasƒ±', 'Genel Ortalama'],
                    'Deƒüer': [
                        current_score,
                        previous_score,
                        df[df['DISTRICT'] == station_analysis['district']]['SKOR'].mean(),
                        df['SKOR'].mean()
                    ]
                }
                
                comparison_df = pd.DataFrame(comparison_data)
                
                fig_comparison = px.bar(
                    comparison_df, 
                    x='Metrik', 
                    y='Deƒüer',
                    title=f"{selected_station} - Performans Kar≈üƒ±la≈ütƒ±rmasƒ±",
                    color='Deƒüer',
                    color_continuous_scale='RdYlGn'
                )
                fig_comparison.add_hline(y=0.7, line_dash="dash", line_color="orange", 
                                       annotation_text="Hedef Skor")
                st.plotly_chart(fig_comparison, use_container_width=True)
                
                # Similar stations analysis
                st.markdown("### üîç BENZERLƒ∞K ANALƒ∞Zƒ∞")
                
                # Find similar stations in same district
                similar_stations = df[
                    (df['DISTRICT'] == station_analysis['district']) & 
                    (df['ƒ∞stasyon'] != selected_station)
                ].copy()
                
                if not similar_stations.empty:
                    # Calculate similarity based on score difference
                    similar_stations['Skor_Farkƒ±'] = abs(similar_stations['SKOR'] - current_score)
                    similar_stations = similar_stations.nsmallest(5, 'Skor_Farkƒ±')
                    
                    st.markdown("#### Aynƒ± b√∂lgedeki en benzer istasyonlar:")
                    display_cols = ['ƒ∞stasyon', 'SKOR', 'GE√áEN SENE SKOR', 'Fark', 'Site Segment']
                    available_cols = [col for col in display_cols if col in similar_stations.columns]
                    st.dataframe(similar_stations[available_cols].round(3))
                
                # AI Recommendations for this station
                st.markdown("### ü§ñ BU ƒ∞STASYON ƒ∞√áƒ∞N AI √ñNERƒ∞LERƒ∞")
                
                # Generate recommendations
                recommendations = generate_improvement_recommendations(station_analysis)
                
                if recommendations:
                    for rec in recommendations:
                        priority_class = f"priority-{rec['priority'].lower()}"
                        
                        st.markdown(f"""
                        <div class="improvement-card {priority_class}">
                            <h4>üéØ {rec['category']} ({rec['priority']} √ñNCELƒ∞K)</h4>
                            <p><strong>Aksiyon:</strong> {rec['action']}</p>
                            <p><strong>Beklenen Etki:</strong> {rec['expected_impact']}</p>
                            <p><strong>S√ºre:</strong> {rec['timeframe']}</p>
                        </div>
                        """, unsafe_allow_html=True)
                else:
                    st.success("‚úÖ Bu istasyon performansƒ± iyi durumda!")
        
        elif analysis_mode == "üí¨ Yorum Analiz Merkezi":
            if st.session_state.comment_data is not None:
                st.markdown("## üí¨ YORUM ANALƒ∞Z MERKEZƒ∞")
                comment_df = st.session_state.comment_data
                
                # Comment analysis implementation here
                st.info("üí¨ Yorum analizi aktif. Detaylƒ± analiz geli≈ütirildi.")
                
                # Show sample comments
                st.dataframe(comment_df.head())
                
            else:
                st.info("üí¨ Yorum analizi i√ßin yorum dosyasƒ± y√ºkleyin.")
        
        elif analysis_mode == "ü§ñ AI √ñneriler Sistemi":
            st.markdown("## ü§ñ AI-POWERED ƒ∞Yƒ∞LE≈ûTƒ∞RME √ñNERƒ∞LERƒ∞")
            
            # Critical stations first
            critical_stations = df[df['SKOR'] < 0.6].copy()
            
            if not critical_stations.empty:
                st.markdown("### ‚ö†Ô∏è KRƒ∞Tƒ∞K DURUMDA OLAN ƒ∞STASYONLAR")
                
                critical_stations = critical_stations.sort_values('SKOR')
                
                for _, station_row in critical_stations.head(5).iterrows():
                    station_name = station_row['ƒ∞stasyon']
                    station_analysis = analyze_station_performance(df, station_name)
                    recommendations = generate_improvement_recommendations(station_analysis)
                    
                    with st.expander(f"üö® {station_name} (Skor: {station_analysis['current_score']:.3f})"):
                        for rec in recommendations:
                            st.markdown(f"""
                            **{rec['category']} - {rec['priority']} √ñNCELƒ∞K**
                            - **Aksiyon:** {rec['action']}
                            - **Beklenen Etki:** {rec['expected_impact']}
                            - **S√ºre:** {rec['timeframe']}
                            """)
            
            # Performance improvement opportunities
            st.markdown("### üìà GELƒ∞≈ûƒ∞M FIRSATLARI")
            
            # Stations with declining performance
            if 'Fark' in df.columns:
                declining = df[df['Fark'] < -5].copy()
                if not declining.empty:
                    st.markdown("#### Performansƒ± D√º≈üen ƒ∞stasyonlar")
                    declining = declining.sort_values('Fark')
                    display_cols = ['ƒ∞stasyon', 'SKOR', 'GE√áEN SENE SKOR', 'Fark', 'DISTRICT']
                    st.dataframe(declining[display_cols].head(10).round(3))
            
            # Best practices from top performers
            st.markdown("### üèÜ EN ƒ∞Yƒ∞ UYGULAMALAR")
            
            top_performers = df[df['SKOR'] >= 0.85]
            if not top_performers.empty:
                st.success(f"‚úÖ {len(top_performers)} istasyon m√ºkemmel performans sergiliyor (‚â•0.85)")
                
                # Show top performers by district
                if 'DISTRICT' in df.columns:
                    top_by_district = top_performers.groupby('DISTRICT')['ƒ∞stasyon'].count().sort_values(ascending=False)
                    
                    fig_top = px.bar(
                        x=top_by_district.values,
                        y=top_by_district.index,
                        orientation='h',
                        title="B√∂lgelere G√∂re Y√ºksek Performanslƒ± ƒ∞stasyon Sayƒ±sƒ±"
                    )
                    st.plotly_chart(fig_top, use_container_width=True)
    
    else:
        # Welcome screen - no data loaded
        st.markdown("## üéØ GER√áEK TLAG VERƒ∞Sƒ∞ BEKLENƒ∞YOR")
        
        st.info("üëà Sol panelden 'satis_veri_clean.xlsx' dosyanƒ±zƒ± y√ºkleyin")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            ### üìä ANALƒ∞Z EDƒ∞LECEK VERƒ∞LER
            - ‚úÖ **1153+ ger√ßek istasyon**
            - ‚úÖ **ROC kodlarƒ±**
            - ‚úÖ **B√∂lge ve NOR bilgileri**
            - ‚úÖ **Mevcut vs ge√ßmi≈ü performans**
            - ‚úÖ **Site segment kategorileri**
            - ‚úÖ **ƒ∞≈ülem hacimleri**
            """)
        
        with col2:
            st.markdown("""
            ### üîç YAPILACAK ANALƒ∞ZLER
            - üìà **ƒ∞stasyon detay analizi**
            - üó∫Ô∏è **B√∂lgesel kar≈üƒ±la≈ütƒ±rmalar**  
            - üéØ **Segment optimizasyonu**
            - ü§ñ **AI-powered √∂neriler**
            - üìä **Performans trendleri**
            - ‚ö†Ô∏è **Risk tespiti**
            """)

if __name__ == "__main__":
    main()